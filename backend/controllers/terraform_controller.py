import os
import logging
import traceback
import json
import requests
import base64
import re
import uuid
import threading
import subprocess
import time
from datetime import datetime
from flask import request, jsonify, current_app, send_file, Response
from werkzeug.utils import safe_join
from models.aideployment_model import AIDeploymentModel
from utils.ai_client_factory import AIClientFactory
from utils.auth import get_current_user
from db.db import get_db
import docker
from typing import Optional
from prompts.cloud_terraform_prompts import CloudTerraformPrompts

# è·å–å½“å‰ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))

# å®šä¹‰éƒ¨ç½²ç›®å½•
DEPLOYMENTS_DIR = os.path.join(current_dir, '..', 'aideployments')

# ç¡®ä¿éƒ¨ç½²ç›®å½•å­˜åœ¨
if not os.path.exists(DEPLOYMENTS_DIR):
    os.makedirs(DEPLOYMENTS_DIR)

# å®šä¹‰éƒ¨ç½²çŠ¶æ€
DEPLOYMENT_STATUS = {
    'PENDING': 'pending',
    'RUNNING': 'running',
    'SUCCESS': 'success',
    'FAILED': 'failed'
}

class TerraformController:
    def __init__(self, config=None):
        """åˆå§‹åŒ–Terraformæ§åˆ¶å™¨"""
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.deployments_dir = DEPLOYMENTS_DIR
        self.deployment_model = AIDeploymentModel()  # ç§»é™¤configå‚æ•°
        
        # è®°å½•æ­£åœ¨è¿è¡Œçš„éƒ¨ç½²è¿›ç¨‹ï¼Œç”¨äºæ”¯æŒåœæ­¢éƒ¨ç½²åŠŸèƒ½
        self.active_deployments = {}  # deploy_id -> {"process": process, "thread": thread}
        
        # åˆ›å»ºAIå®¢æˆ·ç«¯
        if config:
            self.ai_client_factory = AIClientFactory(config)
            self.ai_client = self.ai_client_factory.create_client()
            self.logger.info(f"TerraformControllerä½¿ç”¨AIæ¨¡å‹æä¾›å•†: {config.ai_model_provider}")
        else:
            # å…¼å®¹æ—§ä»£ç ï¼Œå¦‚æœæ²¡æœ‰configï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
            self.openai_api_key = os.environ.get('OPENAI_API_KEY', '')
            self.openai_api_base_url = os.environ.get('OPENAI_API_BASE_URL', 'https://api.openai.com/v1')
            self.openai_api_model = os.environ.get('OPENAI_API_MODEL', 'gpt-4o')
            self.ai_client = None
        
        # Initialize MCP server configuration
        self.enable_mcp = os.environ.get('ENABLE_TERRAFORM_MCP', 'false').lower() == 'true'
        self.mcp_server_url = os.environ.get('TERRAFORM_MCP_SERVER_URL', 'http://localhost:8080')
        self.mcp_server_version = os.environ.get('TERRAFORM_MCP_SERVER_VERSION', '0.1.0')
        
        # MCP Docker container configuration
        self.mcp_container_name = "terraform-mcp-server"
        self.mcp_server_path = "/bin/terraform-mcp-server"  # é»˜è®¤è·¯å¾„
        
        # Initialize Docker client for MCP server if enabled
        if self.enable_mcp:
            try:
                self.docker_client = docker.from_env()
                self._ensure_mcp_server()
                self.logger.info("MCP server with Docker client initialized successfully")
            except Exception as e:
                self.logger.warning(f"MCPåŠŸèƒ½ä¸å¯ç”¨ - Docker clientåˆå§‹åŒ–å¤±è´¥: {str(e)}")
                self.logger.info("MCPåŠŸèƒ½å·²ç¦ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»ŸTerraformç”Ÿæˆæ¨¡å¼")
                self.enable_mcp = False
        else:
            self.logger.info("MCPåŠŸèƒ½å·²ç¦ç”¨ï¼Œä½¿ç”¨ä¼ ç»ŸTerraformç”Ÿæˆæ¨¡å¼")

    def _ensure_mcp_server(self):
        """Ensures the Terraform MCP server is running"""
        try:
            self.logger.info("å¼€å§‹æ£€æŸ¥å¹¶å¯åŠ¨Terraform MCP server")
            self.logger.info(f"MCP serveré…ç½®:")
            self.logger.info(f"- å¯ç”¨MCP: {self.enable_mcp}")
            self.logger.info(f"- MCP server URL: {self.mcp_server_url}")
            self.logger.info(f"- MCP serverç‰ˆæœ¬: {self.mcp_server_version}")
            
            if not self.enable_mcp:
                self.logger.info("MCP serverå·²ç¦ç”¨ï¼Œè·³è¿‡å¯åŠ¨")
                return
            
            # Pull the latest MCP server image
            image_name = f"hashicorp/terraform-mcp-server:{self.mcp_server_version}"
            self.logger.info(f"æ­£åœ¨æ‹‰å–MCP serveré•œåƒ: {image_name}")
            
            try:
                image = self.docker_client.images.pull(image_name)
                self.logger.info(f"æˆåŠŸæ‹‰å–MCP serveré•œåƒ: {image.id}")
            except Exception as pull_error:
                self.logger.error(f"æ‹‰å–MCP serveré•œåƒå¤±è´¥: {str(pull_error)}")
                raise
            
            # Check if container is already running
            self.logger.info("æ£€æŸ¥æ˜¯å¦å·²æœ‰è¿è¡Œä¸­çš„MCP serverå®¹å™¨")
            containers = self.docker_client.containers.list(
                filters={"name": "terraform-mcp-server"}
            )
            
            if containers:
                container = containers[0]
                self.logger.info(f"å‘ç°å·²è¿è¡Œçš„MCP serverå®¹å™¨: {container.id}")
                self.logger.info(f"å®¹å™¨çŠ¶æ€: {container.status}")
                self.logger.info(f"å®¹å™¨ç«¯å£: {container.ports}")
                
                # æ£€æŸ¥å®¹å™¨æ˜¯å¦å¥åº·
                if container.status == 'running':
                    self.logger.info("MCP serverå®¹å™¨æ­£åœ¨æ­£å¸¸è¿è¡Œ")
                    
                    # ä½¿ç”¨stdioæ–¹å¼è¿›è¡Œå¥åº·æ£€æŸ¥ï¼ˆè€Œä¸æ˜¯HTTPï¼‰
                    health_ok = self._test_mcp_server_connection()
                    if health_ok:
                        self.logger.info("MCP serverå¥åº·æ£€æŸ¥é€šè¿‡")
                    else:
                        self.logger.warning("MCP serverå¥åº·æ£€æŸ¥å¤±è´¥ï¼Œä½†å®¹å™¨ä»åœ¨è¿è¡Œ")
                else:
                    self.logger.warning(f"MCP serverå®¹å™¨çŠ¶æ€å¼‚å¸¸: {container.status}ï¼Œå°†é‡å¯å®¹å™¨")
                    container.stop()
                    container.remove()
                    self._start_new_mcp_container(image_name)
            else:
                self.logger.info("æœªå‘ç°è¿è¡Œä¸­çš„MCP serverå®¹å™¨ï¼Œå°†å¯åŠ¨æ–°å®¹å™¨")
                self._start_new_mcp_container(image_name)
                
        except Exception as e:
            self.logger.error(f"å¯åŠ¨Terraform MCP serverå¤±è´¥: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            self.enable_mcp = False
            
    def _start_new_mcp_container(self, image_name):
        """å¯åŠ¨æ–°çš„MCP serverå®¹å™¨"""
        try:
            self.logger.info(f"æ­£åœ¨å¯åŠ¨æ–°çš„MCP serverå®¹å™¨: {image_name}")
            
            # å…ˆæ¸…ç†å¯èƒ½å­˜åœ¨çš„åŒåå®¹å™¨
            try:
                existing_containers = self.docker_client.containers.list(
                    all=True, filters={"name": "terraform-mcp-server"}
                )
                for container in existing_containers:
                    self.logger.info(f"æ¸…ç†ç°æœ‰å®¹å™¨: {container.id}")
                    try:
                        container.stop(timeout=5)
                    except:
                        pass
                    try:
                        container.remove(force=True)
                    except:
                        pass
            except Exception as cleanup_error:
                self.logger.warning(f"æ¸…ç†ç°æœ‰å®¹å™¨æ—¶å‡ºé”™: {str(cleanup_error)}")
            
            # å¯åŠ¨æ–°å®¹å™¨
            self.logger.info("å¯åŠ¨å®¹å™¨å‚æ•°:")
            self.logger.info(f"- é•œåƒ: {image_name}")
            self.logger.info(f"- ç«¯å£æ˜ å°„: 8080:8080")
            self.logger.info(f"- ç¯å¢ƒå˜é‡: LOG_LEVEL=DEBUG")
            
            # é¦–å…ˆæ£€æŸ¥é•œåƒæ˜¯å¦æœ‰é—®é¢˜ï¼Œå°è¯•è¿è¡Œä¸€ä¸ªç®€å•çš„å‘½ä»¤æ¥æµ‹è¯•
            try:
                self.logger.info("æµ‹è¯•é•œåƒæ˜¯å¦èƒ½æ­£å¸¸è¿è¡Œ...")
                test_container = self.docker_client.containers.run(
                    image_name,
                    command="--help",  # è¿è¡Œhelpå‘½ä»¤çœ‹çœ‹é•œåƒæ˜¯å¦æ­£å¸¸
                    remove=True,
                    detach=False
                )
                self.logger.info("é•œåƒæµ‹è¯•è¿è¡ŒæˆåŠŸ")
            except Exception as test_error:
                self.logger.error(f"é•œåƒæµ‹è¯•è¿è¡Œå¤±è´¥: {str(test_error)}")
                # ç»§ç»­å°è¯•æ­£å¸¸å¯åŠ¨
            
            # MCP server éœ€è¦è¿è¡Œåœ¨ stdio æ¨¡å¼ï¼Œä½†å®¹å™¨æœ¬èº«è¦è¿è¡Œä¸€ä¸ªä¿æŒæ´»è·ƒçš„è¿›ç¨‹
            container = self.docker_client.containers.run(
                image_name,
                name="terraform-mcp-server",
                command=["sh", "-c", "while true; do sleep 3600; done"],  # ä¿æŒå®¹å™¨è¿è¡Œ
                detach=True,
                stdin_open=True,  # ä¿æŒ stdin å¼€æ”¾
                tty=True,         # åˆ†é…ä¼ªç»ˆç«¯
                environment={
                    'LOG_LEVEL': 'DEBUG'  # å¯ç”¨è¯¦ç»†æ—¥å¿—
                }
                # æ³¨æ„ï¼šMCP serveré€šè¿‡stdioé€šä¿¡ï¼Œæ¯æ¬¡æŸ¥è¯¢æ—¶åŠ¨æ€å¯åŠ¨terraform-mcp-server stdio
            )
            
            self.logger.info(f"å®¹å™¨åˆ›å»ºæˆåŠŸ: {container.id}")
            
            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©å®¹å™¨æœ‰æ—¶é—´å¯åŠ¨
            import time
            self.logger.info("ç­‰å¾…å®¹å™¨å¯åŠ¨...")
            time.sleep(2)
            
            # è·å–å®¹å™¨å¯åŠ¨æ—¥å¿—ï¼ˆåœ¨çŠ¶æ€æ£€æŸ¥ä¹‹å‰ï¼‰
            try:
                logs = container.logs().decode('utf-8')
                if logs:
                    self.logger.info(f"å®¹å™¨å¯åŠ¨æ—¥å¿—: {logs}")
                else:
                    self.logger.info("å®¹å™¨æ—¥å¿—ä¸ºç©º")
            except Exception as log_error:
                self.logger.warning(f"è·å–å®¹å™¨æ—¥å¿—å¤±è´¥: {str(log_error)}")
            
            # æ£€æŸ¥å®¹å™¨çŠ¶æ€ - ä½¿ç”¨ç®€å•çš„æ–¹å¼
            try:
                # ç›´æ¥æŸ¥è¯¢æ‰€æœ‰å®¹å™¨ï¼Œé¿å…ä½¿ç”¨å¯èƒ½æœ‰é—®é¢˜çš„reload
                containers = self.docker_client.containers.list(all=True)
                mcp_container = None
                
                for c in containers:
                    if c.name == "terraform-mcp-server":
                        mcp_container = c
                        break
                
                if mcp_container is None:
                    self.logger.error("æ‰¾ä¸åˆ°MCP serverå®¹å™¨")
                    return
                
                self.logger.info(f"å®¹å™¨å½“å‰çŠ¶æ€: {mcp_container.status}")
                self.logger.info(f"å®¹å™¨ç«¯å£æ˜ å°„: {mcp_container.ports}")
                
                if mcp_container.status == 'running':
                    self.logger.info("MCP serverå®¹å™¨æ­£åœ¨è¿è¡Œ")
                    # å°è¯•è¿æ¥æµ‹è¯•
                    self._test_mcp_server_connection()
                elif mcp_container.status == 'exited':
                    self.logger.error("å®¹å™¨å·²é€€å‡º")
                    
                    # è·å–è¯¦ç»†çš„å®¹å™¨ä¿¡æ¯
                    try:
                        container_info = self.docker_client.api.inspect_container(mcp_container.id)
                        exit_code = container_info.get('State', {}).get('ExitCode', 'unknown')
                        error_msg = container_info.get('State', {}).get('Error', 'no error message')
                        self.logger.error(f"å®¹å™¨é€€å‡ºä»£ç : {exit_code}")
                        self.logger.error(f"å®¹å™¨é”™è¯¯ä¿¡æ¯: {error_msg}")
                        
                        # è·å–æ›´è¯¦ç»†çš„æ—¥å¿—
                        logs = mcp_container.logs().decode('utf-8')
                        if logs:
                            self.logger.error(f"å®¹å™¨å®Œæ•´æ—¥å¿—: {logs}")
                    except Exception as info_error:
                        self.logger.error(f"è·å–å®¹å™¨è¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(info_error)}")
                else:
                    self.logger.warning(f"å®¹å™¨çŠ¶æ€å¼‚å¸¸: {mcp_container.status}")
                    
            except Exception as status_error:
                self.logger.error(f"æ£€æŸ¥å®¹å™¨çŠ¶æ€æ—¶å‡ºé”™: {str(status_error)}")
                self.logger.error(f"çŠ¶æ€æ£€æŸ¥é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                
        except Exception as e:
            self.logger.error(f"å¯åŠ¨MCP serverå®¹å™¨æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"å¯åŠ¨é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            raise
            
    def _test_mcp_server_connection(self):
        """æµ‹è¯•MCP serverè¿æ¥ï¼ˆé€šè¿‡stdioï¼‰"""
        try:
            self.logger.info("æ­£åœ¨æµ‹è¯•MCP serverè¿æ¥ï¼ˆstdioæ–¹å¼ï¼‰")
            
            # æ‰¾åˆ°MCP serverå®¹å™¨
            containers = self.docker_client.containers.list()
            mcp_container = None
            for container in containers:
                if container.name == "terraform-mcp-server":
                    mcp_container = container
                    break
            
            if not mcp_container:
                self.logger.error("æ‰¾ä¸åˆ°MCP serverå®¹å™¨")
                return False
            
            # å‘é€ä¸€ä¸ªç®€å•çš„tools/listè¯·æ±‚æ¥æµ‹è¯•MCP serveræ˜¯å¦æ­£ç¡®è¿è¡Œåœ¨stdioæ¨¡å¼
            import json
            import subprocess
            
            # ä½¿ç”¨æ ‡å‡†çš„tools/listè¯·æ±‚
            test_request = {
                "jsonrpc": "2.0",
                "id": 1,
                "method": "tools/list",
                "params": {}
            }
            
            for i in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
                try:
                    # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„MCP server stdioæ¨¡å¼æµ‹è¯•
                    mcp_command = [
                        "docker", "exec", "-i", self.mcp_container_name,
                        self.mcp_server_path, "stdio"
                    ]
                    
                    # æ·»åŠ æ¢è¡Œç¬¦ï¼ŒMCPåè®®éœ€è¦
                    request_data = json.dumps(test_request) + "\n"
                    
                    exec_result = subprocess.run(
                        mcp_command,
                        input=request_data,
                        capture_output=True,
                        text=True,
                        timeout=10
                    )
                    
                    self.logger.info(f"MCP serverè¿æ¥æµ‹è¯•æ‰§è¡Œç»“æœé€€å‡ºç : {exec_result.returncode}")
                    
                    if exec_result.returncode == 0:
                        output = exec_result.stdout if exec_result.stdout else ""
                        self.logger.info(f"MCP serverè¿æ¥æµ‹è¯•å“åº”: {output[:300]}{'...' if len(output) > 300 else ''}")
                        
                        # æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„JSON-RPCæ ¼å¼
                        if '"jsonrpc"' in output and '"result"' in output:
                            self.logger.info("âœ… MCP serverè¿æ¥æµ‹è¯•æˆåŠŸ - è¿”å›æœ‰æ•ˆJSON-RPCå“åº”")
                            return True
                        elif "terraform-mcp-server [command]" in output:
                            self.logger.error("âŒ MCP serverè¿”å›å¸®åŠ©ä¿¡æ¯è€ŒéJSON-RPCå“åº”ï¼Œå¯èƒ½é…ç½®é”™è¯¯")
                            return False
                        else:
                            self.logger.warning(f"âš ï¸ MCP serverå“åº”æ ¼å¼å¼‚å¸¸ï¼Œé‡è¯• {i+1}/3")
                    else:
                        self.logger.warning(f"âŒ MCP serverè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œé€€å‡ºç : {exec_result.returncode}ï¼Œé‡è¯• {i+1}/3")
                        if exec_result.stderr:
                            self.logger.warning(f"é”™è¯¯è¾“å‡º: {exec_result.stderr[:200]}")
                            
                except Exception as test_error:
                    self.logger.warning(f"MCP serverè¿æ¥æµ‹è¯•å‡ºé”™ï¼Œé‡è¯• {i+1}/3: {str(test_error)}")
                    
                if i < 2:  # æœ€åä¸€æ¬¡ä¸ç­‰å¾…
                    import time
                    time.sleep(2)
            
            self.logger.error("MCP serverè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
            return False
            
        except Exception as e:
            self.logger.error(f"MCP serverè¿æ¥æµ‹è¯•å‡ºé”™: {str(e)}")
            return False

    def _diagnose_mcp_server(self):
        """è¯Šæ–­MCP serveræ”¯æŒçš„å·¥å…·å’Œproviders"""
        try:
            self.logger.info("ğŸ” å¼€å§‹è¯Šæ–­MCP serveræ”¯æŒæƒ…å†µ")
            
            # å…ˆæ£€æŸ¥å®¹å™¨å†…çš„æ–‡ä»¶å’Œè¿›ç¨‹
            self._check_mcp_container_status()
            
            # ä¿®å¤ï¼šMCP serverå¿…é¡»è¿è¡Œåœ¨stdioæ¨¡å¼ä¸‹
            mcp_command = [
                "docker", "exec", "-i", self.mcp_container_name,
                self.mcp_server_path, "stdio"  # æ˜ç¡®æŒ‡å®šstdioæ¨¡å¼
            ]
            
            # æŸ¥è¯¢æ”¯æŒçš„å·¥å…·åˆ—è¡¨
            tools_request = {
                "jsonrpc": "2.0",
                "id": 99,
                "method": "tools/list"
            }
            
            # æ·»åŠ æ¢è¡Œç¬¦ï¼ŒMCPåè®®éœ€è¦
            request_data = json.dumps(tools_request) + "\n"
            
            result = subprocess.run(
                mcp_command,
                input=request_data,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                self.logger.info(f"ğŸ“‹ MCP serverå·¥å…·åˆ—è¡¨å“åº”: {result.stdout}")
                
                # å°è¯•ä¸€ä¸ªç®€å•çš„AWSæŸ¥è¯¢ä½œä¸ºåŸºå‡†æµ‹è¯•
                aws_test = {
                    "jsonrpc": "2.0",
                    "id": 98,
                    "method": "tools/call",
                    "params": {
                        "name": "resolveProviderDocID",
                        "arguments": {
                            "providerName": "aws",
                            "providerNamespace": "hashicorp",
                            "serviceSlug": "vpc",
                            "providerDataType": "resources",
                            "providerVersion": "latest"
                        }
                    }
                }
                
                # AWSæµ‹è¯•æŸ¥è¯¢ä¹Ÿè¦ä½¿ç”¨ç›¸åŒçš„å‘½ä»¤ï¼Œæ·»åŠ æ¢è¡Œç¬¦
                aws_request_data = json.dumps(aws_test) + "\n"
                
                aws_result = subprocess.run(
                    mcp_command,  # ä½¿ç”¨ç›¸åŒçš„ä¿®å¤åå‘½ä»¤
                    input=aws_request_data,
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                if aws_result.returncode == 0:
                    self.logger.info(f"âœ… AWSæµ‹è¯•æŸ¥è¯¢æˆåŠŸ: {aws_result.stdout[:300]}...")
                else:
                    self.logger.warning(f"âŒ AWSæµ‹è¯•æŸ¥è¯¢å¤±è´¥: {aws_result.stderr}")
                    
            else:
                self.logger.error(f"âŒ MCP serverå·¥å…·åˆ—è¡¨æŸ¥è¯¢å¤±è´¥: {result.stderr}")
                
        except Exception as e:
            self.logger.error(f"MCP serverè¯Šæ–­å¤±è´¥: {str(e)}")
            
    def _check_mcp_container_status(self):
        """æ£€æŸ¥MCPå®¹å™¨çš„è¯¦ç»†çŠ¶æ€"""
        try:
            self.logger.info("ğŸ” æ£€æŸ¥MCPå®¹å™¨å†…éƒ¨çŠ¶æ€")
            
            # 1. æ£€æŸ¥terraform-mcp-serveræ–‡ä»¶æ˜¯å¦å­˜åœ¨
            check_file_cmd = ["docker", "exec", self.mcp_container_name, "ls", "-la", self.mcp_server_path]
            result = subprocess.run(check_file_cmd, capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                self.logger.info(f"âœ… MCP serveræ–‡ä»¶å­˜åœ¨: {result.stdout.strip()}")
            else:
                self.logger.error(f"âŒ MCP serveræ–‡ä»¶ä¸å­˜åœ¨: {result.stderr}")
                return
            
            # 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯æ‰§è¡Œ
            check_exec_cmd = ["docker", "exec", self.mcp_container_name, "file", self.mcp_server_path]
            result = subprocess.run(check_exec_cmd, capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                self.logger.info(f"ğŸ“‹ æ–‡ä»¶ç±»å‹: {result.stdout.strip()}")
            
            # 3. å°è¯•æ‰§è¡Œhelpå‘½ä»¤
            help_cmd = ["docker", "exec", self.mcp_container_name, self.mcp_server_path, "--help"]
            result = subprocess.run(help_cmd, capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                self.logger.info(f"âœ… Helpå‘½ä»¤æˆåŠŸ: {result.stdout[:200]}...")
            else:
                self.logger.error(f"âŒ Helpå‘½ä»¤å¤±è´¥: {result.stderr}")
            
            # 4. æ£€æŸ¥å®¹å™¨è¿›ç¨‹
            ps_cmd = ["docker", "exec", self.mcp_container_name, "ps", "aux"]
            result = subprocess.run(ps_cmd, capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                self.logger.info(f"ğŸ“‹ å®¹å™¨è¿›ç¨‹: {result.stdout}")
            
            # 5. æµ‹è¯•ç®€å•çš„JSON-RPCå“åº”
            self._test_simple_jsonrpc()
            
        except Exception as e:
            self.logger.error(f"å®¹å™¨çŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}")
    
    def _test_simple_jsonrpc(self):
        """æµ‹è¯•ç®€å•çš„JSON-RPCé€šä¿¡"""
        try:
            self.logger.info("ğŸ” æµ‹è¯•ç®€å•JSON-RPCé€šä¿¡")
            
            # ä½¿ç”¨æ ‡å‡†çš„MCPåˆå§‹åŒ–è¯·æ±‚
            simple_request = {
                "jsonrpc": "2.0",
                "id": 1,
                "method": "initialize",
                "params": {
                    "capabilities": {},
                    "clientInfo": {
                        "name": "mcdp-terraform-client",
                        "version": "1.0.0"
                    }
                }
            }
            
            mcp_command = [
                "docker", "exec", "-i", self.mcp_container_name,
                self.mcp_server_path, "stdio"
            ]
            
            # æ·»åŠ æ¢è¡Œç¬¦ï¼ŒæŸäº›JSON-RPCå®ç°éœ€è¦
            request_data = json.dumps(simple_request) + "\n"
            
            result = subprocess.run(
                mcp_command,
                input=request_data,
                capture_output=True,
                text=True,
                timeout=15
            )
            
            self.logger.info(f"ç®€å•JSON-RPCæµ‹è¯•é€€å‡ºç : {result.returncode}")
            self.logger.info(f"ç®€å•JSON-RPCæµ‹è¯•stdout: '{result.stdout}'")
            self.logger.info(f"ç®€å•JSON-RPCæµ‹è¯•stderr: '{result.stderr}'")
            
            if result.stdout.strip():
                self.logger.info("âœ… æœ‰stdoutè¾“å‡ºï¼Œå¯èƒ½è¡¨ç¤ºé€šä¿¡æ­£å¸¸")
            else:
                self.logger.warning("âš ï¸ æ²¡æœ‰stdoutè¾“å‡º")
                
            if result.stderr.strip():
                self.logger.info(f"ğŸ“‹ stderrå†…å®¹: {result.stderr}")
            
        except Exception as e:
            self.logger.error(f"ç®€å•JSON-RPCæµ‹è¯•å¤±è´¥: {str(e)}")

    def _generate_with_mcp(self, user_description, mermaid_code):
        """ä½¿ç”¨MCP serveræŸ¥è¯¢æ¨¡å—ä¿¡æ¯æ¥è¾…åŠ©ä»£ç ç”Ÿæˆ"""
        try:
            self.logger.info("å¼€å§‹ä½¿ç”¨MCP serveræŸ¥è¯¢æ¨¡å—ä¿¡æ¯")
            
            # å…ˆè¿›è¡Œè¯Šæ–­
            self._diagnose_mcp_server()
            
            # æ™ºèƒ½æ£€æµ‹äº‘å¹³å°
            detected_cloud = CloudTerraformPrompts.detect_cloud_from_description(user_description)
            self.logger.info(f"ä»ç”¨æˆ·æè¿°ä¸­æ™ºèƒ½æ£€æµ‹åˆ°äº‘å¹³å°: {detected_cloud}")
            
            # äº‘å¹³å°æ˜ å°„åˆ°MCPæ”¯æŒçš„provideråç§°
            cloud_to_provider_mapping = {
                "AWS": "aws",
                "AWS(CHINA)": "aws", 
                "AZURE": "azurerm",
                "AZURE(CHINA)": "azurerm",
                "é˜¿é‡Œäº‘": "alicloud",
                "åä¸ºäº‘": "huaweicloud", 
                "è…¾è®¯äº‘": "tencentcloud",
                "ç™¾åº¦äº‘": "baiducloud",
                "ç«å±±äº‘": "volcengine"
            }
            
            mcp_provider = cloud_to_provider_mapping.get(detected_cloud, "aws")
            self.logger.info(f"æ˜ å°„åˆ°MCP provider: {mcp_provider}")
            
            # æ™ºèƒ½è§£æç”¨æˆ·éœ€æ±‚ä¸­çš„èµ„æºç±»å‹
            resource_types = self._extract_resource_types_from_description(user_description, mcp_provider)
            self.logger.info(f"è¯†åˆ«åˆ°éœ€è¦æŸ¥è¯¢çš„èµ„æºç±»å‹: {resource_types}")
            
            # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°ä»»ä½•èµ„æºï¼Œä½¿ç”¨é»˜è®¤èµ„æº
            if not resource_types:
                self.logger.warning("æœªè¯†åˆ«åˆ°å…·ä½“èµ„æºç±»å‹ï¼Œä½¿ç”¨é»˜è®¤VPCèµ„æº")
                resource_types = ["vpc"]
            
            # åˆ†åˆ«æŸ¥è¯¢æ¯ä¸ªèµ„æºç±»å‹çš„æ–‡æ¡£
            all_docs = []
            for resource_type in resource_types:
                self.logger.info(f"å¼€å§‹æŸ¥è¯¢ {mcp_provider}_{resource_type} çš„æ–‡æ¡£")
                
                try:
                    service_slug = f"{mcp_provider}_{resource_type}"
                    docs = self._query_mcp_resource_docs(mcp_provider, service_slug, resource_type)
                    
                    if docs:
                        all_docs.append({
                            "resource_type": resource_type,
                            "service_slug": service_slug,
                            "docs": docs
                        })
                        self.logger.info(f"æˆåŠŸè·å– {service_slug} çš„æ–‡æ¡£ï¼Œé•¿åº¦: {len(docs)} å­—ç¬¦")
                    else:
                        self.logger.warning(f"æœªè·å–åˆ° {service_slug} çš„æ–‡æ¡£")
                        
                except Exception as resource_error:
                    self.logger.error(f"æŸ¥è¯¢ {service_slug} æ–‡æ¡£æ—¶å‡ºé”™: {str(resource_error)}")
                    continue
            
            # åˆå¹¶æ‰€æœ‰æ–‡æ¡£
            if all_docs:
                combined_docs = self._combine_mcp_docs(all_docs, mcp_provider, user_description)
                self.logger.info(f"æˆåŠŸåˆå¹¶æ‰€æœ‰æ–‡æ¡£ï¼Œæ€»é•¿åº¦: {len(combined_docs)} å­—ç¬¦")
                return combined_docs
            else:
                self.logger.warning("æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆçš„MCPæ–‡æ¡£")
                return None
                
        except Exception as e:
            self.logger.error(f"MCP serveræŸ¥è¯¢å¤±è´¥: {str(e)}")
            return None

    def _extract_resource_types_from_description(self, user_description, provider):
        """ä»ç”¨æˆ·æè¿°ä¸­æå–éœ€è¦æŸ¥è¯¢çš„èµ„æºç±»å‹"""
        resource_types = []
        desc_lower = user_description.lower()
        
        # åŸºäºäº‘å¹³å°çš„èµ„æºç±»å‹æ˜ å°„
        if provider == "aws":
            resource_mapping = {
                "vpc": ["vpc", "è™šæ‹Ÿç½‘ç»œ", "ç§æœ‰äº‘"],
                "instance": ["ec2", "å®ä¾‹", "æœåŠ¡å™¨", "è™šæ‹Ÿæœº", "ecs"],
                "subnet": ["subnet", "å­ç½‘"],
                "security_group": ["å®‰å…¨ç»„", "security group", "sg"],
                "db_instance": ["rds", "æ•°æ®åº“", "db", "mysql", "postgres"],
                "s3_bucket": ["s3", "å­˜å‚¨æ¡¶", "bucket", "å­˜å‚¨"],
                "lb": ["elb", "alb", "nlb", "è´Ÿè½½å‡è¡¡", "load balancer"],
                "route_table": ["è·¯ç”±è¡¨", "route table", "è·¯ç”±"],
                "internet_gateway": ["ç½‘å…³", "gateway", "igw"]
            }
        elif provider == "huaweicloud":
            resource_mapping = {
                "vpc": ["vpc", "è™šæ‹Ÿç½‘ç»œ", "ç§æœ‰äº‘"],
                "compute_instance": ["ecs", "å®ä¾‹", "æœåŠ¡å™¨", "è™šæ‹Ÿæœº"],
                "vpc_subnet": ["subnet", "å­ç½‘"],
                "vpc_security_group": ["å®‰å…¨ç»„", "security group", "sg"],
                "rds_instance": ["rds", "æ•°æ®åº“", "db", "mysql", "postgres"],
                "obs_bucket": ["obs", "å­˜å‚¨æ¡¶", "bucket", "å­˜å‚¨"],
                "elb_loadbalancer": ["elb", "è´Ÿè½½å‡è¡¡", "load balancer"]
            }
        elif provider == "alicloud":
            resource_mapping = {
                "vpc": ["vpc", "è™šæ‹Ÿç½‘ç»œ", "ç§æœ‰äº‘"],
                "instance": ["ecs", "å®ä¾‹", "æœåŠ¡å™¨", "è™šæ‹Ÿæœº"],
                "vswitch": ["vswitch", "äº¤æ¢æœº", "subnet", "å­ç½‘"],
                "security_group": ["å®‰å…¨ç»„", "security group", "sg"],
                "db_instance": ["rds", "æ•°æ®åº“", "db", "mysql", "postgres"],
                "oss_bucket": ["oss", "å­˜å‚¨æ¡¶", "bucket", "å­˜å‚¨"],
                "slb": ["slb", "è´Ÿè½½å‡è¡¡", "load balancer"]
            }
        elif provider == "tencentcloud":
            resource_mapping = {
                "vpc": ["vpc", "è™šæ‹Ÿç½‘ç»œ", "ç§æœ‰äº‘"],
                "instance": ["cvm", "å®ä¾‹", "æœåŠ¡å™¨", "è™šæ‹Ÿæœº", "ecs"],
                "subnet": ["subnet", "å­ç½‘"],
                "security_group": ["å®‰å…¨ç»„", "security group", "sg"],
                "mysql_instance": ["mysql", "æ•°æ®åº“", "db"],
                "cos_bucket": ["cos", "å­˜å‚¨æ¡¶", "bucket", "å­˜å‚¨"],
                "clb_instance": ["clb", "è´Ÿè½½å‡è¡¡", "load balancer"]
            }
        elif provider == "volcengine":
            resource_mapping = {
                "vpc": ["vpc", "è™šæ‹Ÿç½‘ç»œ", "ç§æœ‰äº‘"],
                "ecs_instance": ["ecs", "å®ä¾‹", "æœåŠ¡å™¨", "è™šæ‹Ÿæœº"],
                "subnet": ["subnet", "å­ç½‘"],
                "security_group": ["å®‰å…¨ç»„", "security group", "sg"],
                "rds_mysql_instance": ["rds", "mysql", "æ•°æ®åº“", "db"],
                "tos_bucket": ["tos", "å­˜å‚¨æ¡¶", "bucket", "å­˜å‚¨"]
            }
        elif provider == "azurerm":
            resource_mapping = {
                "virtual_network": ["vnet", "è™šæ‹Ÿç½‘ç»œ", "vpc"],
                "virtual_machine": ["vm", "å®ä¾‹", "æœåŠ¡å™¨", "è™šæ‹Ÿæœº", "ecs"],
                "subnet": ["subnet", "å­ç½‘"],
                "network_security_group": ["nsg", "å®‰å…¨ç»„", "security group"],
                "sql_database": ["sql", "æ•°æ®åº“", "db", "mysql"],
                "storage_account": ["storage", "å­˜å‚¨"],
                "lb": ["è´Ÿè½½å‡è¡¡", "load balancer"]
            }
        else:
            # é»˜è®¤AWSæ˜ å°„
            resource_mapping = {
                "vpc": ["vpc", "è™šæ‹Ÿç½‘ç»œ"],
                "instance": ["ec2", "å®ä¾‹", "ecs"],
                "subnet": ["subnet", "å­ç½‘"]
            }
        
        # æ£€æµ‹ç”¨æˆ·æè¿°ä¸­æåˆ°çš„èµ„æºç±»å‹
        mentioned_resources = []
        for resource_type, keywords in resource_mapping.items():
            for keyword in keywords:
                if keyword in desc_lower:
                    if resource_type not in mentioned_resources:
                        mentioned_resources.append(resource_type)
                    break
        
        # å¦‚æœç”¨æˆ·æåˆ°äº†ç‰¹å®šèµ„æºï¼Œæ ¹æ®æœ€ä½³å®è·µè‡ªåŠ¨æ·»åŠ ä¾èµ–èµ„æº
        if mentioned_resources:
            resource_types = list(mentioned_resources)
            
            # è‡ªåŠ¨æ·»åŠ ä¾èµ–èµ„æºçš„é€»è¾‘
            if any(r in ["instance", "compute_instance", "virtual_machine", "ecs_instance"] for r in mentioned_resources):
                # å¦‚æœæåˆ°å®ä¾‹ï¼Œè‡ªåŠ¨æ·»åŠ VPCå’Œå­ç½‘
                vpc_resource = "vpc" if provider in ["aws", "alicloud", "huaweicloud", "tencentcloud", "volcengine"] else "virtual_network"
                
                # åä¸ºäº‘ä½¿ç”¨vpc_subnetï¼Œå…¶ä»–äº‘å¹³å°çš„å­ç½‘å‘½å
                if provider == "huaweicloud":
                    subnet_resource = "vpc_subnet"
                elif provider == "alicloud":
                    subnet_resource = "vswitch"
                else:
                    subnet_resource = "subnet"
                
                if vpc_resource not in resource_types:
                    resource_types.insert(0, vpc_resource)  # VPCæ”¾åœ¨æœ€å‰é¢
                if subnet_resource not in resource_types:
                    resource_types.insert(-1, subnet_resource)  # å­ç½‘æ”¾åœ¨å®ä¾‹å‰é¢
                    
                # æ·»åŠ å®‰å…¨ç»„ - åä¸ºäº‘ä½¿ç”¨vpc_security_group
                if provider == "huaweicloud":
                    sg_resource = "vpc_security_group"
                elif provider == "azurerm":
                    sg_resource = "network_security_group"
                else:
                    sg_resource = "security_group"
                    
                if sg_resource not in resource_types:
                    resource_types.append(sg_resource)
            
            self.logger.info(f"ç”¨æˆ·æåˆ°èµ„æº: {mentioned_resources}, æ·»åŠ ä¾èµ–å: {resource_types}")
        else:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®æåˆ°èµ„æºï¼Œä½¿ç”¨VPCä½œä¸ºé»˜è®¤
            vpc_resource = "vpc" if provider != "azurerm" else "virtual_network"
            resource_types = [vpc_resource]
            self.logger.info(f"æœªè¯†åˆ«åˆ°å…·ä½“èµ„æºï¼Œä½¿ç”¨é»˜è®¤: {resource_types}")
        
        return resource_types

    def _query_mcp_resource_docs(self, provider, service_slug, resource_type):
        """æŸ¥è¯¢æŒ‡å®šèµ„æºçš„MCPæ–‡æ¡£ - ä½¿ç”¨æ··åˆæŸ¥è¯¢ç­–ç•¥"""
        try:
            self.logger.info(f"å¼€å§‹æŸ¥è¯¢ {service_slug} çš„æ–‡æ¡£ (æ··åˆç­–ç•¥)")
            
            # ç­–ç•¥1ï¼šä¼˜å…ˆä½¿ç”¨æ¨¡å—æŸ¥è¯¢
            module_docs = self._query_mcp_via_modules(provider, resource_type)
            if module_docs:
                self.logger.info(f"âœ… é€šè¿‡æ¨¡å—æŸ¥è¯¢æˆåŠŸè·å– {resource_type} æ–‡æ¡£")
                return module_docs
            
            # ç­–ç•¥2ï¼šfallbackåˆ°provideræŸ¥è¯¢ï¼Œå°è¯•ä¸åŒçš„namespace
            provider_docs = self._query_mcp_via_providers(provider, service_slug, resource_type)
            if provider_docs:
                self.logger.info(f"âœ… é€šè¿‡provideræŸ¥è¯¢æˆåŠŸè·å– {resource_type} æ–‡æ¡£")
                return provider_docs
            
            # ç­–ç•¥3ï¼šå°è¯•é€šç”¨æ¨¡å—æœç´¢
            generic_docs = self._query_mcp_generic_modules(provider, resource_type)
            if generic_docs:
                self.logger.info(f"âœ… é€šè¿‡é€šç”¨æ¨¡å—æŸ¥è¯¢æˆåŠŸè·å– {resource_type} æ–‡æ¡£")
                return generic_docs
            
            self.logger.warning(f"âŒ æ‰€æœ‰æŸ¥è¯¢ç­–ç•¥éƒ½å¤±è´¥ï¼Œæœªè·å–åˆ° {resource_type} æ–‡æ¡£")
            return None
            
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢ {service_slug} æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
            return None

    def _query_mcp_via_modules(self, provider, resource_type):
        """ç­–ç•¥1ï¼šé€šè¿‡æ¨¡å—æŸ¥è¯¢è·å–æ–‡æ¡£"""
        try:
            # æ„å»ºæ¨¡å—æœç´¢å…³é”®è¯
            module_queries = self._build_module_search_queries(provider, resource_type)
            
            for query in module_queries:
                self.logger.info(f"ğŸ” æ¨¡å—æœç´¢: '{query}'")
                
                # æœç´¢æ¨¡å—
                modules_response = self._search_modules(query)
                if not modules_response:
                    continue
                
                # è§£ææ¨¡å—åˆ—è¡¨ï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„æ¨¡å—
                module_id = self._parse_module_search_results(modules_response, provider, resource_type)
                if not module_id:
                    continue
                
                # è·å–æ¨¡å—è¯¦æƒ…
                module_details = self._get_module_details(module_id)
                if module_details:
                    return module_details
            
            return None
            
        except Exception as e:
            self.logger.error(f"æ¨¡å—æŸ¥è¯¢å¤±è´¥: {str(e)}")
            return None

    def _build_module_search_queries(self, provider, resource_type):
        """æ„å»ºæ¨¡å—æœç´¢å…³é”®è¯"""
        queries = []
        
        # äº‘å¹³å°ç‰¹å®šçš„æœç´¢è¯
        if provider == "huaweicloud":
            cloud_terms = ["huawei", "huaweicloud", "åä¸ºäº‘"]
        elif provider == "alicloud":
            cloud_terms = ["alicloud", "aliyun", "é˜¿é‡Œäº‘"]
        elif provider == "tencentcloud":
            cloud_terms = ["tencent", "tencentcloud", "è…¾è®¯äº‘"]
        elif provider == "volcengine":
            cloud_terms = ["volcengine", "bytedance", "ç«å±±äº‘"]
        elif provider == "baiducloud":
            cloud_terms = ["baidu", "baiducloud", "ç™¾åº¦äº‘"]
        else:
            cloud_terms = [provider]
        
        # èµ„æºç±»å‹æ˜ å°„åˆ°é€šç”¨æœ¯è¯­
        resource_mapping = {
            "vpc": ["vpc", "network", "virtual-network"],
            "compute_instance": ["ecs", "vm", "instance", "server", "compute"],
            "vpc_subnet": ["subnet", "subnetwork"],
            "subnet": ["subnet", "subnetwork"],
            "vpc_security_group": ["security-group", "sg", "firewall"],
            "security_group": ["security-group", "sg", "firewall"],
            "rds_instance": ["rds", "database", "db"],
            "db_instance": ["rds", "database", "db"],
            "obs_bucket": ["storage", "bucket", "object-storage"],
            "s3_bucket": ["storage", "bucket", "s3"],
            "elb_loadbalancer": ["lb", "load-balancer", "elb"],
            "lb": ["lb", "load-balancer"]
        }
        
        resource_terms = resource_mapping.get(resource_type, [resource_type])
        
        # ç»„åˆæœç´¢è¯
        for cloud_term in cloud_terms:
            for resource_term in resource_terms:
                queries.extend([
                    f"{cloud_term} {resource_term}",
                    f"{cloud_term}-{resource_term}",
                    f"{resource_term} {cloud_term}",
                    resource_term  # é€šç”¨æœç´¢
                ])
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_queries = list(dict.fromkeys(queries))[:8]  # æœ€å¤š8ä¸ªæŸ¥è¯¢
        self.logger.info(f"æ„å»ºçš„æ¨¡å—æœç´¢è¯: {unique_queries}")
        return unique_queries

    def _search_modules(self, query):
        """æ‰§è¡Œæ¨¡å—æœç´¢"""
        try:
            # ä¿®å¤ï¼šMCP serverå¿…é¡»è¿è¡Œåœ¨stdioæ¨¡å¼ä¸‹
            mcp_command = [
                "docker", "exec", "-i", self.mcp_container_name,
                self.mcp_server_path, "stdio"  # æ˜ç¡®æŒ‡å®šstdioæ¨¡å¼
            ]
            
            search_request = {
                "jsonrpc": "2.0",
                "id": 10,
                "method": "tools/call",
                "params": {
                    "name": "searchModules",
                    "arguments": {
                        "moduleQuery": query,
                        "currentOffset": 0
                    }
                }
            }
            
            # æ·»åŠ æ¢è¡Œç¬¦ï¼ŒMCPåè®®éœ€è¦
            request_data = json.dumps(search_request) + "\n"
            
            result = subprocess.run(
                mcp_command,
                input=request_data,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                # æ·»åŠ è¯¦ç»†çš„å“åº”æ—¥å¿—
                response_preview = result.stdout[:300] + "..." if len(result.stdout) > 300 else result.stdout
                self.logger.info(f"ğŸ“‹ æ¨¡å—æœç´¢'{query}'å“åº”é¢„è§ˆ: {response_preview}")
                return result.stdout
            else:
                self.logger.warning(f"âŒ æ¨¡å—æœç´¢'{query}'å¤±è´¥: {result.stderr}")
                return None
                
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œæ¨¡å—æœç´¢æ—¶å‡ºé”™: {str(e)}")
            return None

    def _parse_module_search_results(self, response, provider, resource_type):
        """è§£ææ¨¡å—æœç´¢ç»“æœï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„æ¨¡å—ID"""
        try:
            self.logger.info(f"ğŸ” è§£ææ¨¡å—æœç´¢ç»“æœï¼Œå¯»æ‰¾ {provider} {resource_type}")
            
            lines = response.strip().split('\n')
            best_module_id = None
            best_score = 0
            found_modules = []
            
            for line in lines:
                if line.startswith('{"jsonrpc"'):
                    try:
                        parsed_response = json.loads(line)
                        if "result" in parsed_response and "content" in parsed_response["result"]:
                            content = parsed_response["result"]["content"]
                            if isinstance(content, list):
                                for item in content:
                                    if isinstance(item, dict) and "text" in item:
                                        # è§£ææ¨¡å—ä¿¡æ¯
                                        module_info = self._extract_module_info(item["text"])
                                        if module_info:
                                            score = self._score_module_relevance(module_info, provider, resource_type)
                                            found_modules.append({
                                                "info": module_info,
                                                "score": score
                                            })
                                            if score > best_score:
                                                best_score = score
                                                best_module_id = module_info.get("id")
                                                self.logger.info(f"ğŸ¯ å‘ç°å€™é€‰æ¨¡å—: {best_module_id} (è¯„åˆ†: {score})")
                    except json.JSONDecodeError as e:
                        self.logger.warning(f"JSONè§£æå¤±è´¥: {str(e)}")
                        continue
                elif line.strip():  # éç©ºè¡Œä½†ä¸æ˜¯JSON
                    # å¯èƒ½æ˜¯æ™®é€šæ–‡æœ¬å“åº”ï¼Œå°è¯•ç›´æ¥è§£æ
                    module_info = self._extract_module_info(line)
                    if module_info:
                        score = self._score_module_relevance(module_info, provider, resource_type)
                        found_modules.append({
                            "info": module_info,
                            "score": score
                        })
                        if score > best_score:
                            best_score = score
                            best_module_id = module_info.get("id")
                            self.logger.info(f"ğŸ¯ å‘ç°å€™é€‰æ¨¡å—(æ–‡æœ¬): {best_module_id} (è¯„åˆ†: {score})")
            
            # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
            if found_modules:
                self.logger.info(f"âœ… æ‰¾åˆ° {len(found_modules)} ä¸ªå€™é€‰æ¨¡å—")
                for i, module in enumerate(sorted(found_modules, key=lambda x: x["score"], reverse=True)[:3]):
                    self.logger.info(f"  {i+1}. {module['info'].get('id', 'N/A')} (è¯„åˆ†: {module['score']})")
            else:
                self.logger.warning(f"âŒ æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„æ¨¡å—")
                # è¾“å‡ºå“åº”å†…å®¹ç”¨äºè°ƒè¯•
                response_preview = response[:500] + "..." if len(response) > 500 else response
                self.logger.info(f"ğŸ“‹ åŸå§‹å“åº”é¢„è§ˆ: {response_preview}")
            
            if best_module_id and best_score > 30:  # è®¾ç½®æœ€ä½åˆ†æ•°é˜ˆå€¼
                self.logger.info(f"ğŸ† é€‰æ‹©æœ€ä½³æ¨¡å—: {best_module_id} (è¯„åˆ†: {best_score})")
                return best_module_id
            else:
                self.logger.info(f"âš ï¸ æœªæ‰¾åˆ°è¶³å¤Ÿç›¸å…³çš„æ¨¡å— (æœ€é«˜åˆ†: {best_score})")
                return None
            
        except Exception as e:
            self.logger.error(f"è§£ææ¨¡å—æœç´¢ç»“æœæ—¶å‡ºé”™: {str(e)}")
            return None

    def _extract_module_info(self, text_content):
        """ä»æ–‡æœ¬ä¸­æå–æ¨¡å—ä¿¡æ¯"""
        try:
            # è§£ææ¨¡å—åˆ—è¡¨æ–‡æœ¬æ ¼å¼
            import re
            
            # æŸ¥æ‰¾æ¨¡å—IDå’Œç›¸å…³ä¿¡æ¯
            patterns = [
                r'moduleID[:\s]+([^\s\n]+)',
                r'id[:\s]+["\']([^"\']+)["\']',
                r'name[:\s]+["\']([^"\']+)["\']'
            ]
            
            module_info = {}
            for pattern in patterns:
                match = re.search(pattern, text_content, re.IGNORECASE)
                if match:
                    if "id" not in module_info:
                        module_info["id"] = match.group(1)
                    if "name" not in module_info:
                        module_info["name"] = match.group(1)
            
            # æå–æè¿°ä¿¡æ¯
            desc_match = re.search(r'description[:\s]+["\']([^"\']+)["\']', text_content, re.IGNORECASE)
            if desc_match:
                module_info["description"] = desc_match.group(1)
            
            # æå–ä¸‹è½½é‡å’ŒéªŒè¯çŠ¶æ€
            download_match = re.search(r'downloads?[:\s]+(\d+)', text_content, re.IGNORECASE)
            if download_match:
                module_info["downloads"] = int(download_match.group(1))
            
            verified_match = re.search(r'verified[:\s]+(true|false)', text_content, re.IGNORECASE)
            if verified_match:
                module_info["verified"] = verified_match.group(1).lower() == "true"
            
            return module_info if "id" in module_info else None
            
        except Exception as e:
            self.logger.error(f"æå–æ¨¡å—ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
            return None

    def _score_module_relevance(self, module_info, provider, resource_type):
        """ç»™æ¨¡å—ç›¸å…³æ€§æ‰“åˆ†"""
        score = 0
        
        text_to_check = " ".join([
            module_info.get("id", ""),
            module_info.get("name", ""),
            module_info.get("description", "")
        ]).lower()
        
        # äº‘å¹³å°åŒ¹é…
        provider_keywords = {
            "huaweicloud": ["huawei", "huaweicloud", "åä¸º"],
            "alicloud": ["ali", "aliyun", "alicloud", "é˜¿é‡Œ"],
            "tencentcloud": ["tencent", "tencentcloud", "è…¾è®¯"],
            "volcengine": ["volcengine", "bytedance", "ç«å±±"],
            "baiducloud": ["baidu", "baiducloud", "ç™¾åº¦"],
            "aws": ["aws", "amazon"],
            "azurerm": ["azure", "microsoft"]
        }
        
        if provider in provider_keywords:
            for keyword in provider_keywords[provider]:
                if keyword in text_to_check:
                    score += 50
                    break
        
        # èµ„æºç±»å‹åŒ¹é…
        resource_keywords = {
            "vpc": ["vpc", "network", "virtual"],
            "compute_instance": ["ecs", "compute", "instance", "vm", "server"],
            "subnet": ["subnet", "subnetwork"],
            "security_group": ["security", "firewall", "sg"],
            "rds_instance": ["rds", "database", "db"],
            "obs_bucket": ["storage", "bucket", "object"],
            "elb_loadbalancer": ["lb", "balancer", "elb"]
        }
        
        if resource_type in resource_keywords:
            for keyword in resource_keywords[resource_type]:
                if keyword in text_to_check:
                    score += 30
        
        # éªŒè¯çŠ¶æ€åŠ åˆ†
        if module_info.get("verified", False):
            score += 20
        
        # ä¸‹è½½é‡åŠ åˆ†
        downloads = module_info.get("downloads", 0)
        if downloads > 1000:
            score += 10
        elif downloads > 100:
            score += 5
        
        return score

    def _get_module_details(self, module_id):
        """è·å–æ¨¡å—è¯¦ç»†ä¿¡æ¯"""
        try:
            # ä¿®å¤ï¼šMCP serverå¿…é¡»è¿è¡Œåœ¨stdioæ¨¡å¼ä¸‹
            mcp_command = [
                "docker", "exec", "-i", self.mcp_container_name,
                self.mcp_server_path, "stdio"  # æ˜ç¡®æŒ‡å®šstdioæ¨¡å¼
            ]
            
            detail_request = {
                "jsonrpc": "2.0",
                "id": 11,
                "method": "tools/call",
                "params": {
                    "name": "moduleDetails",
                    "arguments": {
                        "moduleID": module_id
                    }
                }
            }
            
            # æ·»åŠ æ¢è¡Œç¬¦ï¼ŒMCPåè®®éœ€è¦
            request_data = json.dumps(detail_request) + "\n"
            
            result = subprocess.run(
                mcp_command,
                input=request_data,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                # è§£ææ¨¡å—è¯¦æƒ…å“åº”
                lines = result.stdout.strip().split('\n')
                for line in lines:
                    if line.startswith('{"jsonrpc"'):
                        try:
                            parsed_response = json.loads(line)
                            if "result" in parsed_response and "content" in parsed_response["result"]:
                                content = parsed_response["result"]["content"]
                                if isinstance(content, list) and len(content) > 0:
                                    for item in content:
                                        if isinstance(item, dict) and "text" in item:
                                            self.logger.info(f"æˆåŠŸè·å–æ¨¡å—è¯¦æƒ…ï¼Œé•¿åº¦: {len(item['text'])} å­—ç¬¦")
                                            return item["text"]
                        except json.JSONDecodeError:
                            continue
                
                self.logger.warning("æ¨¡å—è¯¦æƒ…å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆå†…å®¹")
                return None
            else:
                self.logger.error(f"è·å–æ¨¡å—è¯¦æƒ…å¤±è´¥: {result.stderr}")
                return None
                
        except Exception as e:
            self.logger.error(f"è·å–æ¨¡å—è¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")
            return None

    def _query_mcp_via_providers(self, provider, service_slug, resource_type):
        """ç­–ç•¥2ï¼šé€šè¿‡provideræŸ¥è¯¢è·å–æ–‡æ¡£ï¼ˆå°è¯•ä¸åŒnamespaceï¼‰"""
        try:
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œè°ƒæ•´åä¸ºäº‘çš„namespaceä¼˜å…ˆçº§
            if provider == "huaweicloud":
                namespaces_to_try = [
                    "huaweicloud",        # åä¸ºäº‘å®˜æ–¹namespace
                    "hashicorp",          # å¯èƒ½çš„å®˜æ–¹æ”¯æŒ
                    "terraform-providers", # ç¤¾åŒºproviders
                    "registry.terraform.io" # å®Œæ•´æ ¼å¼
                ]
            else:
                namespaces_to_try = [
                    "hashicorp",          # å¤§å¤šæ•°å®˜æ–¹provider
                    provider,             # ä½¿ç”¨provideråä½œä¸ºnamespace
                    "terraform-providers", # æ—§æ ¼å¼
                    "registry.terraform.io" # å®Œæ•´æ ¼å¼
                ]
            
            for namespace in namespaces_to_try:
                self.logger.info(f"ğŸ” å°è¯•provideræŸ¥è¯¢: {namespace}/{provider}")
                
                # ç¬¬ä¸€æ­¥ï¼šæŸ¥è¯¢æ–‡æ¡£åˆ—è¡¨
                doc_list_response = self._query_mcp_doc_list_with_namespace(provider, service_slug, namespace)
                if not doc_list_response:
                    continue
                    
                # è§£ææ–‡æ¡£åˆ—è¡¨ï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ID
                doc_id = self._parse_doc_list_for_resource(doc_list_response, resource_type)
                if not doc_id:
                    continue
                
                # ç¬¬äºŒæ­¥ï¼šæŸ¥è¯¢è¯¦ç»†æ–‡æ¡£
                detailed_docs = self._query_mcp_detailed_docs(doc_id)
                if detailed_docs:
                    return detailed_docs
            
            return None
            
        except Exception as e:
            self.logger.error(f"ProvideræŸ¥è¯¢å¤±è´¥: {str(e)}")
            return None

    def _query_mcp_doc_list_with_namespace(self, provider, service_slug, namespace):
        """ä½¿ç”¨æŒ‡å®šnamespaceæŸ¥è¯¢MCPæ–‡æ¡£åˆ—è¡¨"""
        try:
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼ŒserviceSlugåº”è¯¥æ˜¯ç®€å•çš„èµ„æºåï¼Œä¸åŒ…å«providerå‰ç¼€
            simple_service_slug = service_slug.replace(f"{provider}_", "") if service_slug.startswith(f"{provider}_") else service_slug
            
            # ä¿®å¤ï¼šMCP serverå¿…é¡»è¿è¡Œåœ¨stdioæ¨¡å¼ä¸‹
            mcp_command = [
                "docker", "exec", "-i", self.mcp_container_name,
                self.mcp_server_path, "stdio"  # æ˜ç¡®æŒ‡å®šstdioæ¨¡å¼
            ]
            
            query_request = {
                "jsonrpc": "2.0",
                "id": 2,
                "method": "tools/call",
                "params": {
                    "name": "resolveProviderDocID",
                    "arguments": {
                        "providerName": provider,
                        "providerNamespace": namespace,
                        "serviceSlug": simple_service_slug,  # ä½¿ç”¨ç®€åŒ–çš„serviceSlug
                        "providerDataType": "resources",
                        "providerVersion": "latest"
                    }
                }
            }
            
            self.logger.info(f"ğŸ” ProvideræŸ¥è¯¢è¯¦æƒ…: {namespace}/{provider}, serviceSlug='{simple_service_slug}'")
            
            # æ·»åŠ æ¢è¡Œç¬¦ï¼ŒMCPåè®®éœ€è¦
            request_data = json.dumps(query_request) + "\n"
            
            result = subprocess.run(
                mcp_command,
                input=request_data,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                # æ·»åŠ è¯¦ç»†çš„å“åº”æ—¥å¿—
                response_preview = result.stdout[:500] + "..." if len(result.stdout) > 500 else result.stdout
                self.logger.info(f"ğŸ“‹ MCPå“åº”é¢„è§ˆ: {response_preview}")
                return result.stdout
            else:
                self.logger.warning(f"âŒ ProvideræŸ¥è¯¢å¤±è´¥: {result.stderr}")
                return None
                
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢MCPæ–‡æ¡£åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
            return None

    def _query_mcp_generic_modules(self, provider, resource_type):
        """ç­–ç•¥3ï¼šé€šç”¨æ¨¡å—æœç´¢ï¼ˆä¸é™å®šäº‘å¹³å°ï¼‰"""
        try:
            # ä½¿ç”¨é€šç”¨èµ„æºæœ¯è¯­æœç´¢
            generic_terms = {
                "vpc": ["vpc", "virtual network", "network"],
                "compute_instance": ["compute", "virtual machine", "instance"],
                "subnet": ["subnet"],
                "security_group": ["security group", "firewall"],
                "rds_instance": ["database", "rds"],
                "obs_bucket": ["object storage", "storage"],
                "elb_loadbalancer": ["load balancer"]
            }
            
            terms = generic_terms.get(resource_type, [resource_type])
            
            for term in terms:
                self.logger.info(f"ğŸ” é€šç”¨æ¨¡å—æœç´¢: '{term}'")
                
                modules_response = self._search_modules(term)
                if not modules_response:
                    continue
                
                # æŸ¥æ‰¾åŒ…å«äº‘å¹³å°å…³é”®è¯çš„æ¨¡å—
                module_id = self._parse_module_search_results(modules_response, provider, resource_type)
                if not module_id:
                    continue
                
                module_details = self._get_module_details(module_id)
                if module_details:
                    return module_details
            
            return None
            
        except Exception as e:
            self.logger.error(f"é€šç”¨æ¨¡å—æœç´¢å¤±è´¥: {str(e)}")
            return None

    def _parse_doc_list_for_resource(self, response, resource_type):
        """ä»æ–‡æ¡£åˆ—è¡¨å“åº”ä¸­è§£æå‡ºç›¸å…³çš„æ–‡æ¡£IDï¼ˆç”¨äºprovideræŸ¥è¯¢ï¼‰"""
        try:
            # æ·»åŠ è¯¦ç»†çš„è§£ææ—¥å¿—
            self.logger.info(f"ğŸ” è§£ææ–‡æ¡£åˆ—è¡¨ï¼Œå¯»æ‰¾èµ„æºç±»å‹: {resource_type}")
            
            # è§£æå“åº”ï¼Œæ‰¾åˆ°åŒ…å«ç›®æ ‡èµ„æºç±»å‹çš„æ–‡æ¡£
            lines = response.strip().split('\n')
            found_docs = []
            
            for line in lines:
                if line.startswith('{"jsonrpc"'):
                    try:
                        parsed_response = json.loads(line)
                        if "result" in parsed_response and "content" in parsed_response["result"]:
                            content = parsed_response["result"]["content"]
                            if isinstance(content, list) and len(content) > 0:
                                # è§£æå†…å®¹ï¼ŒæŸ¥æ‰¾åŒ¹é…çš„èµ„æº
                                for item in content:
                                    if isinstance(item, dict) and "text" in item:
                                        text_content = item["text"]
                                        
                                        # æ›´å®½æ¾çš„åŒ¹é…ç­–ç•¥
                                        resource_variants = [
                                            resource_type.lower(),
                                            resource_type.replace("_", " "),
                                            resource_type.replace("vpc_", ""),  # åä¸ºäº‘ç‰¹æ®Šå¤„ç†
                                            resource_type.split("_")[-1]  # å–æœ€åä¸€éƒ¨åˆ†
                                        ]
                                        
                                        for variant in resource_variants:
                                            if variant in text_content.lower():
                                                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ–‡æ¡£ID
                                                import re
                                                id_patterns = [
                                                    r'"providerDocID":\s*"([^"]+)"',
                                                    r'"id":\s*"([^"]+)"',
                                                    r'providerDocID:\s*([^\s,\}]+)'
                                                ]
                                                
                                                for pattern in id_patterns:
                                                    id_match = re.search(pattern, text_content)
                                                    if id_match:
                                                        doc_id = id_match.group(1)
                                                        found_docs.append({
                                                            "id": doc_id,
                                                            "variant": variant,
                                                            "text": text_content[:200]
                                                        })
                                                        self.logger.info(f"âœ… æ‰¾åˆ°åŒ¹é…æ–‡æ¡£: ID={doc_id}, åŒ¹é…è¯='{variant}'")
                                                        break
                                                
                                                if found_docs:
                                                    break
                                        
                                        if found_docs:
                                            break
                    except json.JSONDecodeError:
                        continue
            
            if found_docs:
                # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡æ¡£ID
                best_doc = found_docs[0]
                self.logger.info(f"ğŸ¯ é€‰æ‹©æ–‡æ¡£ID: {best_doc['id']} (åŒ¹é…: {best_doc['variant']})")
                return best_doc["id"]
            else:
                self.logger.warning(f"âŒ åœ¨å“åº”ä¸­æœªæ‰¾åˆ° {resource_type} ç›¸å…³çš„æ–‡æ¡£ID")
                # è¾“å‡ºå“åº”å†…å®¹çš„å‰300å­—ç¬¦ç”¨äºè°ƒè¯•
                response_preview = response[:300] + "..." if len(response) > 300 else response
                self.logger.info(f"ğŸ“‹ å“åº”å†…å®¹é¢„è§ˆ: {response_preview}")
                return None
            
        except Exception as e:
            self.logger.error(f"è§£ææ–‡æ¡£åˆ—è¡¨å“åº”æ—¶å‡ºé”™: {str(e)}")
            return None

    def _query_mcp_detailed_docs(self, doc_id):
        """æŸ¥è¯¢æŒ‡å®šæ–‡æ¡£IDçš„è¯¦ç»†æ–‡æ¡£ï¼ˆç”¨äºprovideræŸ¥è¯¢ï¼‰"""
        try:
            # ä¿®å¤ï¼šMCP serverå¿…é¡»è¿è¡Œåœ¨stdioæ¨¡å¼ä¸‹
            mcp_command = [
                "docker", "exec", "-i", self.mcp_container_name,
                self.mcp_server_path, "stdio"  # æ˜ç¡®æŒ‡å®šstdioæ¨¡å¼
            ]
            
            # æ„å»ºè¯¦ç»†æ–‡æ¡£æŸ¥è¯¢è¯·æ±‚
            detail_request = {
                "jsonrpc": "2.0", 
                "id": 3,
                "method": "tools/call",
                "params": {
                    "name": "getProviderDocs",
                    "arguments": {
                        "providerDocID": doc_id
                    }
                }
            }
            
            self.logger.info(f"æŸ¥è¯¢providerDocID '{doc_id}' çš„è¯¦ç»†æ–‡æ¡£")
            
            # æ·»åŠ æ¢è¡Œç¬¦ï¼ŒMCPåè®®éœ€è¦
            request_data = json.dumps(detail_request) + "\n"
            
            # æ‰§è¡Œè¯¦ç»†æ–‡æ¡£æŸ¥è¯¢
            result = subprocess.run(
                mcp_command,
                input=request_data,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                self.logger.info(f"MCP serverè¯¦ç»†æ–‡æ¡£å“åº”é•¿åº¦: {len(result.stdout)} å­—ç¬¦")
                
                # è§£æè¯¦ç»†æ–‡æ¡£å“åº”
                lines = result.stdout.strip().split('\n')
                for line in lines:
                    if line.startswith('{"jsonrpc"'):
                        try:
                            parsed_response = json.loads(line)
                            if "result" in parsed_response and "content" in parsed_response["result"]:
                                content = parsed_response["result"]["content"]
                                if isinstance(content, list) and len(content) > 0:
                                    for item in content:
                                        if isinstance(item, dict) and "text" in item:
                                            doc_text = item["text"]
                                            self.logger.info(f"æˆåŠŸè·å–è¯¦ç»†æ–‡æ¡£ï¼Œé•¿åº¦: {len(doc_text)} å­—ç¬¦")
                                            return doc_text
                        except json.JSONDecodeError:
                            continue
                
                self.logger.warning("è¯¦ç»†æ–‡æ¡£å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆå†…å®¹")
                return None
            else:
                self.logger.error(f"MCP serverè¯¦ç»†æ–‡æ¡£æŸ¥è¯¢å¤±è´¥: {result.stderr}")
                return None
                
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢è¯¦ç»†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
            return None

    def _combine_mcp_docs(self, all_docs, provider, user_description):
        """åˆå¹¶æ‰€æœ‰æŸ¥è¯¢åˆ°çš„æ–‡æ¡£"""
        combined_content = f"""
# {provider.upper()} Provider Documentation

Based on your request: "{user_description}"

Here are the relevant Terraform resource documentations:

"""
        
        for doc_info in all_docs:
            resource_type = doc_info["resource_type"]
            service_slug = doc_info["service_slug"] 
            docs = doc_info["docs"]
            
            combined_content += f"""
## {service_slug} Resource Documentation

Resource Type: {resource_type}
Service Slug: {service_slug}

{docs}

---

"""
        
        combined_content += """
Please use these documentations as reference to generate accurate and complete Terraform code that includes all necessary resources and their proper configurations.
"""
        
        return combined_content

    def _enhance_terraform_code_legacy(self, user_description, mermaid_code, mcp_code, cloud_provider=None):
        """ä½¿ç”¨AIå¢å¼ºMCPç”Ÿæˆçš„Terraformä»£ç ï¼ˆlegacyæ–¹æ³•ï¼‰"""
        try:
            self.logger.info("ä½¿ç”¨AIå¢å¼ºMCPç”Ÿæˆçš„Terraformä»£ç ï¼ˆlegacyæ–¹æ³•ï¼‰")
            
            # æ„å»ºå¢å¼ºæç¤º
            system_prompt = r"""
            You are a DevOps engineer expert in Terraform. 
            Your task is to review and enhance Terraform code generated by MCP server.
            
            CRITICAL REQUIREMENTS:
            1. Review the MCP-generated code for correctness and completeness
            2. Add any missing resources or configurations
            3. Ensure the code is complete and ready to execute
            4. Include provider configuration if missing
            5. Use best practices and meaningful resource names
            6. Add helpful comments to explain key sections of the code
            7. Ensure proper resource dependencies and complete all necessary components
            8. If essential components are missing, add them to ensure the infrastructure works properly
            
            Remember: EVERY resource must have at least one output block.
            
            Only return the complete enhanced Terraform code without any additional explanations or markdown formatting.
            """
            
            user_prompt = f"""
            User request: {user_description}
            
            Mermaid diagram of the infrastructure:
            ```
            {mermaid_code}
            ```
            
            MCP Server Generated Code:
            ```
            {mcp_code}
            ```
            
            Please review and enhance the above MCP-generated Terraform code.
            Ensure it meets all requirements and is production-ready.
            """
            
            # ç¡®å®šAIæä¾›å•†å¹¶è°ƒç”¨ç›¸åº”API
            ai_provider = 'openai'  # é»˜è®¤å€¼
            if self.config:
                ai_provider = getattr(self.config, 'ai_model_provider', 'openai').lower()
            else:
                ai_provider = os.environ.get('AI_MODEL_PROVIDER', 'openai').lower()
            
            self.logger.info(f"ä½¿ç”¨AIæä¾›å•†å¢å¼ºMCPä»£ç : {ai_provider}")
            
            # æ ¹æ®AIæä¾›å•†è¿›è¡Œè°ƒç”¨
            if ai_provider == 'anthropic':
                # Anthropicé…ç½®
                api_key = None
                if self.config:
                    api_key = getattr(self.config, 'anthropic_api_key', '')
                if not api_key:
                    api_key = os.environ.get('ANTHROPIC_API_KEY', '')
                
                api_base_url = None
                if self.config:
                    api_base_url = getattr(self.config, 'anthropic_api_base_url', 'https://api.anthropic.com/v1')
                if not api_base_url:
                    api_base_url = os.environ.get('ANTHROPIC_API_BASE_URL', 'https://api.anthropic.com/v1')
                
                model_name = None
                if self.config:
                    model_name = getattr(self.config, 'anthropic_api_model', 'claude-3-5-sonnet-20241022')
                if not model_name:
                    model_name = os.environ.get('ANTHROPIC_API_MODEL', 'claude-3-5-sonnet-20241022')
                
                if not api_key:
                    self.logger.error("æœªé…ç½®Anthropic APIå¯†é’¥ï¼Œæ— æ³•å¢å¼ºTerraformä»£ç ")
                    return jsonify({
                        "success": False,
                        "error": "æœªé…ç½®Anthropic APIå¯†é’¥"
                    }), 500
                
                # ä½¿ç”¨Anthropic API
                import anthropic
                client = anthropic.Anthropic(
                    api_key=api_key,
                    base_url=api_base_url
                )
                
                self.logger.info(f"ä½¿ç”¨Anthropic APIå¢å¼ºä»£ç ï¼Œæ¨¡å‹: {model_name}")
                
                response = client.messages.create(
                    model=model_name,
                    max_tokens=4096,
                    temperature=0.4,
                    system=system_prompt,
                    messages=[
                        {
                            "role": "user",
                            "content": user_prompt
                        }
                    ]
                )
                
                enhanced_code = response.content[0].text
                
            else:
                # OpenAIé…ç½®ï¼ˆåŒ…æ‹¬å…¶ä»–å…¼å®¹çš„æä¾›å•†ï¼‰
                api_key = None
                if self.config:
                    api_key = getattr(self.config, 'openai_api_key', '')
                if not api_key:
                    api_key = os.environ.get('OPENAI_API_KEY', '')
                
                api_base_url = None
                if self.config:
                    api_base_url = getattr(self.config, 'openai_api_base_url', 'https://api.openai.com/v1')
                if not api_base_url:
                    api_base_url = os.environ.get('OPENAI_API_BASE_URL', 'https://api.openai.com/v1')
                
                model_name = None
                if self.config:
                    model_name = getattr(self.config, 'openai_api_model', 'gpt-4o')
                if not model_name:
                    model_name = os.environ.get('OPENAI_API_MODEL', 'gpt-4o')
                
                if not api_key:
                    self.logger.error("æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œæ— æ³•å¢å¼ºTerraformä»£ç ")
                    return jsonify({
                        "success": False,
                        "error": "æœªé…ç½®OpenAI APIå¯†é’¥"
                    }), 500
                
                # ä½¿ç”¨OpenAI API
                import openai
                client = openai.OpenAI(
                    api_key=api_key,
                    base_url=api_base_url
                )
                
                self.logger.info(f"ä½¿ç”¨OpenAI APIå¢å¼ºä»£ç ï¼Œæ¨¡å‹: {model_name}")
                
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.4,
                    max_tokens=4000
                )
                
                enhanced_code = response.choices[0].message.content
            
            # æ¸…ç†å’Œæ ¼å¼åŒ–ç”Ÿæˆçš„ä»£ç 
            enhanced_code = self._clean_terraform_code(enhanced_code)
            
            self.logger.info(f"AIæˆåŠŸå¢å¼ºMCPä»£ç ï¼Œæœ€ç»ˆä»£ç é•¿åº¦: {len(enhanced_code)} å­—ç¬¦")
            
            return jsonify({
                "success": True,
                "terraform_code": enhanced_code
            }), 200
            
        except Exception as e:
            self.logger.error(f"å¢å¼ºMCPä»£ç æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": f"å¢å¼ºä»£ç å¤±è´¥: {str(e)}"
            }), 500

    def generate_terraform_code(self, user_description, mermaid_code, cloud_provider=None):
        """æ ¹æ®ç”¨æˆ·æè¿°å’ŒMermaidä»£ç ç”ŸæˆTerraformä»£ç """
        try:
            # ç¡®ä¿éƒ¨ç½²ç›®å½•å­˜åœ¨
            self.logger.info(f"ç¡®ä¿éƒ¨ç½²ç›®å½•å­˜åœ¨: {self.deployments_dir}")
            os.makedirs(self.deployments_dir, exist_ok=True)
            
            # è®°å½•è¾“å…¥ä¿¡æ¯
            self.logger.info(f"å¼€å§‹ç”ŸæˆTerraformä»£ç ï¼ŒMermaidä»£ç é•¿åº¦: {len(mermaid_code)}")
            
            # æ£€æµ‹äº‘æä¾›å•†ï¼ˆå¦‚æœæœªæ˜ç¡®æŒ‡å®šï¼‰
            if not cloud_provider:
                cloud_provider = CloudTerraformPrompts.detect_cloud_from_description(user_description)
            
            self.logger.info(f"æ£€æµ‹åˆ°ç›®æ ‡äº‘æä¾›å•†: {cloud_provider}")
            
            # é¦–å…ˆå°è¯•ä½¿ç”¨MCP serverç”ŸæˆåŸºç¡€ä»£ç 
            mcp_generated_code = None
            if self.enable_mcp:
                self.logger.info("MCP serverå·²å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨MCP serverç”ŸæˆåŸºç¡€Terraformä»£ç ")
                mcp_generated_code = self._generate_with_mcp(user_description, mermaid_code)
                
                if mcp_generated_code:
                    self.logger.info(f"MCP serveræˆåŠŸè¿”å›providerä¿¡æ¯ï¼Œé•¿åº¦: {len(mcp_generated_code)} å­—ç¬¦")
                    self.logger.info("ç°åœ¨å°†MCPè¿”å›çš„providerä¿¡æ¯å‘é€ç»™AIå‚è€ƒç”Ÿæˆä»£ç ")
                else:
                    self.logger.warning("MCP serveræŸ¥è¯¢providerå¤±è´¥ï¼Œå°†ç›´æ¥ä½¿ç”¨AIç”Ÿæˆ")
            else:
                self.logger.info("MCP serveræœªå¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨AIç”Ÿæˆä»£ç ")
            
            # æ£€æŸ¥AIå®¢æˆ·ç«¯æ˜¯å¦å·²åˆå§‹åŒ–
            if not self.ai_client:
                # å¦‚æœæ²¡æœ‰AIå®¢æˆ·ç«¯ï¼Œå°è¯•ä½¿ç”¨æ—§çš„OpenAI APIæ–¹å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                if mcp_generated_code:
                    return self._enhance_terraform_code_legacy(user_description, mermaid_code, mcp_generated_code, cloud_provider)
                else:
                    return self._generate_terraform_code_legacy(user_description, mermaid_code, cloud_provider)
            
            # æ ¹æ®æ˜¯å¦æœ‰MCPç”Ÿæˆçš„ä»£ç æ¥æ„å»ºä¸åŒçš„æç¤º
            if mcp_generated_code:
                # æœ‰MCPè¿”å›çš„providerä¿¡æ¯ï¼Œè®©AIå‚è€ƒç”Ÿæˆä»£ç 
                # ä½¿ç”¨äº‘æä¾›å•†ç‰¹å®šçš„promptï¼Œä½†æ·»åŠ MCPå‚è€ƒä¿¡æ¯
                system_prompt = CloudTerraformPrompts.get_cloud_specific_prompt(cloud_provider, user_description)
                system_prompt += """

ADDITIONAL REQUIREMENTS FOR MCP REFERENCE:
1. Use the provided provider documentation as reference for correct resource syntax and configuration
2. Follow Terraform best practices from the provider documentation
3. Add necessary output variables
4. Maintain consistency with user requirements and Mermaid diagram"""
                
                user_prompt = f"""
                User Description:
                {user_description}
                
                Mermaid Diagram:
                {mermaid_code}
                
                Provider Documentation Reference:
                {mcp_generated_code}
                
                Please generate complete Terraform code for {cloud_provider} using NATIVE CLOUD RESOURCES based on the user requirements and Mermaid diagram.
                
                IMPORTANT REMINDERS:
                - Use the provider documentation as reference for correct syntax and configuration
                - Generate a complete, executable Terraform configuration for {cloud_provider}
                
                Return complete, executable Terraform code.
                """
            else:
                # æ²¡æœ‰MCPä»£ç ï¼Œç›´æ¥AIç”Ÿæˆï¼Œä½¿ç”¨äº‘æä¾›å•†ç‰¹å®šçš„prompt
                system_prompt = CloudTerraformPrompts.get_cloud_specific_prompt(cloud_provider, user_description)
                
                user_prompt_template = CloudTerraformPrompts.get_user_prompt_template()
                user_prompt = user_prompt_template.format(
                    user_description=user_description,
                    mermaid_code=mermaid_code,
                    cloud_provider=cloud_provider
                )
            
            # ä½¿ç”¨AIå®¢æˆ·ç«¯ç”Ÿæˆä»£ç 
            try:
                if hasattr(self.ai_client, 'client'):
                    # è·å–åº•å±‚å®¢æˆ·ç«¯
                    if hasattr(self.ai_client, 'model'):
                        model = self.ai_client.model
                    else:
                        model = 'gpt-4'  # é»˜è®¤æ¨¡å‹
                    
                    if mcp_generated_code:
                        self.logger.info(f"å‡†å¤‡ä½¿ç”¨AIå‚è€ƒMCP providerä¿¡æ¯ç”Ÿæˆä»£ç ï¼Œæä¾›å•†: {self.config.ai_model_provider}, æ¨¡å‹: {model}")
                        action_description = "å‚è€ƒMCP providerä¿¡æ¯ç”Ÿæˆä»£ç "
                    else:
                        self.logger.info(f"å‡†å¤‡ä½¿ç”¨AIç›´æ¥ç”ŸæˆTerraformä»£ç ï¼Œæä¾›å•†: {self.config.ai_model_provider}, æ¨¡å‹: {model}")
                        action_description = "ç›´æ¥ç”ŸæˆTerraformä»£ç "
                    
                    # æ ¹æ®ä¸åŒçš„AIæä¾›å•†è°ƒç”¨ä¸åŒçš„API
                    if self.config.ai_model_provider == 'anthropic':
                        # Anthropic API
                        response = self.ai_client.client.messages.create(
                            model=model,
                            max_tokens=4096,
                            temperature=0.4,
                            system=system_prompt,
                            messages=[
                                {
                                    "role": "user",
                                    "content": user_prompt
                                }
                            ]
                        )
                        terraform_code = response.content[0].text
                    else:
                        # OpenAI API
                        response = self.ai_client.client.chat.completions.create(
                            model=model,
                            messages=[
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": user_prompt}
                            ],
                            temperature=0.4,
                            max_tokens=4000
                        )
                        terraform_code = response.choices[0].message.content
                else:
                    # å¦‚æœæ²¡æœ‰åº•å±‚å®¢æˆ·ç«¯ï¼Œä½¿ç”¨é€šç”¨æ–¹æ³•
                    self.logger.warning("AIå®¢æˆ·ç«¯æ²¡æœ‰åº•å±‚å®¢æˆ·ç«¯ï¼Œä½¿ç”¨æ—§æ–¹æ³•")
                    return self._generate_terraform_code_legacy(user_description, mermaid_code)
                
                if mcp_generated_code:
                    self.logger.info("AIå®¢æˆ·ç«¯æˆåŠŸå‚è€ƒMCP providerä¿¡æ¯ç”ŸæˆTerraformä»£ç ")
                else:
                    self.logger.info("AIå®¢æˆ·ç«¯æˆåŠŸç”ŸæˆTerraformä»£ç ")
                
                # æ¸…ç†å’Œæ ¼å¼åŒ–ç”Ÿæˆçš„ä»£ç 
                terraform_code = self._clean_terraform_code(terraform_code)
                
                # è¿”å›ç»“æœ
                result = {
                    "success": True,
                    "terraform_code": terraform_code
                }
                
                return jsonify(result), 200
                
            except Exception as e:
                self.logger.error(f"AIç”ŸæˆTerraformä»£ç å¤±è´¥: {str(e)}")
                self.logger.error(traceback.format_exc())
                return jsonify({
                    "success": False,
                    "error": f"AIç”Ÿæˆå¤±è´¥: {str(e)}"
                }), 500
                
        except Exception as e:
            self.logger.error(f"ç”ŸæˆTerraformä»£ç æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": str(e)
            }), 500
    
    def _generate_terraform_code_legacy(self, user_description, mermaid_code, cloud_provider=None):
        """æ ¹æ®é…ç½®çš„AIæä¾›å•†ç”ŸæˆTerraformä»£ç """
        try:
            # æ£€æµ‹äº‘æä¾›å•†ï¼ˆå¦‚æœæœªæ˜ç¡®æŒ‡å®šï¼‰
            if not cloud_provider:
                cloud_provider = CloudTerraformPrompts.detect_cloud_from_description(user_description)
            
            self.logger.info(f"Legacyæ¨¡å¼ä½¿ç”¨äº‘æä¾›å•†: {cloud_provider}")
            
            # ä½¿ç”¨äº‘æä¾›å•†ç‰¹å®šçš„prompt
            system_prompt = CloudTerraformPrompts.get_cloud_specific_prompt(cloud_provider, user_description)
            
            # æ£€æŸ¥ç”¨æˆ·æè¿°æ˜¯å¦åŒæ—¶åŒ…å«EC2å’ŒLinuxå…³é”®è¯
            needs_amazon_linux_ami = "ec2" in user_description.lower() and "linux" in user_description.lower()
            
            if needs_amazon_linux_ami:
                self.logger.info("æ£€æµ‹åˆ°EC2å’ŒLinuxå…³é”®è¯ï¼Œæ·»åŠ Amazon Linux AMIæ•°æ®æºè¦æ±‚")
                system_prompt += r"""
            
            SPECIAL REQUIREMENT FOR EC2 WITH LINUX:
            You MUST include this data source for Amazon Linux AMI:
            
            data "aws_ami" "amazon_linux" {
              most_recent = true
              owners      = ["amazon"]
            
              filter {
                name   = "name"
                values = ["amzn2-ami-hvm-*-x86_64-gp2"]
              }
            }
            
            For ALL EC2 instances, use this data source as the AMI:
            ami = data.aws_ami.amazon_linux.id
            """
                
            # æ£€æŸ¥ç”¨æˆ·æè¿°æ˜¯å¦åŒ…å«ç«å±±äº‘ç›¸å…³å…³é”®è¯
            is_volcengine = any(keyword in user_description.lower() for keyword in ["ç«å±±äº‘", "ç«å±±å¼•æ“", "volcengine"])
            is_volcengine_ecs = is_volcengine and "ecs" in user_description.lower()
            
            if is_volcengine:
                self.logger.info("æ£€æµ‹åˆ°ç«å±±äº‘/ç«å±±å¼•æ“å…³é”®è¯ï¼Œä½¿ç”¨ç«å±±å¼•æ“provider")
                system_prompt += r"""
            
            SPECIAL REQUIREMENT FOR VOLCENGINE:
            You MUST include BOTH of these provider configuration blocks at the beginning of your code:
            
            terraform {
              required_providers {
                volcengine = {
                  source = "volcengine/volcengine"
                  version = "0.0.167"
                }
              }
            }
            
            provider "volcengine" {
              region = "cn-beijing"
              # access_key and secret_key will be added automatically
            }
            
            NOTE: DO NOT include access_key and secret_key in your code, they will be added automatically.
            DO NOT include any AWS provider configurations - no "provider aws" block should appear in your code.
            Create infrastructure using Volcengine resources that correspond to the requirements.
            """
                
                # å¦‚æœåŒæ—¶åŒ…å«ç«å±±äº‘å’ŒECSå…³é”®è¯ï¼Œæ·»åŠ ECSæ•°æ®æºçš„ç‰¹æ®Šè¦æ±‚
                if is_volcengine_ecs:
                    self.logger.info("æ£€æµ‹åˆ°ç«å±±äº‘/ç«å±±å¼•æ“å’ŒECSå…³é”®è¯ï¼Œæ·»åŠ ECSæ•°æ®æº")
                    system_prompt += r"""
            
            SPECIAL REQUIREMENT FOR VOLCENGINE ECS INSTANCES:
            For ANY Volcengine ECS instances, use these specific settings:
            
            Then in all volcengine_ecs_instance resources, use these settings:

instance_type   = "ecs.c3il.large"
image_id        = "image-aagd56zrw2jtdro3bnrl"
system_volume_type = "ESSD_PL0"   # Recommended system volume type
            """
            
            # æ„å»ºç”¨æˆ·æç¤ºï¼Œä½¿ç”¨äº‘æä¾›å•†ç‰¹å®šçš„æ¨¡æ¿
            user_prompt_template = CloudTerraformPrompts.get_user_prompt_template()
            user_prompt = user_prompt_template.format(
                user_description=user_description,
                mermaid_code=mermaid_code,
                cloud_provider=cloud_provider
            )
            
            # ç¡®å®šAIæä¾›å•†
            ai_provider = 'openai'  # é»˜è®¤å€¼
            if self.config:
                ai_provider = getattr(self.config, 'ai_model_provider', 'openai').lower()
            else:
                ai_provider = os.environ.get('AI_MODEL_PROVIDER', 'openai').lower()
            
            self.logger.info(f"ä½¿ç”¨AIæä¾›å•†ç”ŸæˆTerraformä»£ç : {ai_provider}")
            
            # æ ¹æ®AIæä¾›å•†è·å–ç›¸åº”çš„é…ç½®
            if ai_provider == 'anthropic':
                # Anthropicé…ç½®
                api_key = None
                if self.config:
                    api_key = getattr(self.config, 'anthropic_api_key', '')
                if not api_key:
                    api_key = os.environ.get('ANTHROPIC_API_KEY', '')
                
                api_base_url = None
                if self.config:
                    api_base_url = getattr(self.config, 'anthropic_api_base_url', 'https://api.anthropic.com/v1')
                if not api_base_url:
                    api_base_url = os.environ.get('ANTHROPIC_API_BASE_URL', 'https://api.anthropic.com/v1')
                
                model_name = None
                if self.config:
                    model_name = getattr(self.config, 'anthropic_api_model', 'claude-3-5-sonnet-20241022')
                if not model_name:
                    model_name = os.environ.get('ANTHROPIC_API_MODEL', 'claude-3-5-sonnet-20241022')
                
                if not api_key:
                    self.logger.error("æœªé…ç½®Anthropic APIå¯†é’¥ï¼Œæ— æ³•ç”ŸæˆTerraformä»£ç ")
                    return jsonify({
                        "success": False,
                        "error": "æœªé…ç½®Anthropic APIå¯†é’¥"
                    }), 500
            else:
                # OpenAIé…ç½®ï¼ˆé»˜è®¤ï¼‰
                api_key = None
                if hasattr(self, 'openai_api_key'):
                    api_key = self.openai_api_key
                elif self.config:
                    api_key = getattr(self.config, 'openai_api_key', '')
                
                if not api_key:
                    api_key = os.environ.get('OPENAI_API_KEY', '')
                
                api_base_url = None
                if hasattr(self, 'openai_api_base_url'):
                    api_base_url = self.openai_api_base_url
                elif self.config:
                    api_base_url = getattr(self.config, 'openai_api_base_url', 'https://api.openai.com/v1')
                
                if not api_base_url:
                    api_base_url = os.environ.get('OPENAI_API_BASE_URL', 'https://api.openai.com/v1')
                
                model_name = None
                if hasattr(self, 'openai_api_model'):
                    model_name = self.openai_api_model
                elif self.config:
                    model_name = getattr(self.config, 'openai_api_model', 'gpt-4o')
                
                if not model_name:
                    model_name = os.environ.get('OPENAI_API_MODEL', 'gpt-4o')
                
                if not api_key:
                    self.logger.error("æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œæ— æ³•ç”ŸæˆTerraformä»£ç ")
                    return jsonify({
                        "success": False,
                        "error": "æœªé…ç½®OpenAI APIå¯†é’¥"
                    }), 500
                
            # è®°å½•ä½¿ç”¨çš„APIè®¾ç½®
            self.logger.info(f"ä½¿ç”¨API Base URL: {api_base_url}")
            self.logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # æ ¹æ®AIæä¾›å•†åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = None
            if ai_provider == 'anthropic':
                import anthropic
                client = anthropic.Anthropic(
                    api_key=api_key,
                    base_url=api_base_url
                )
            else:
                import openai
                client = openai.OpenAI(
                    api_key=api_key,
                    base_url=api_base_url
                )
            
            # æ ¹æ®AIæä¾›å•†è°ƒç”¨ç›¸åº”çš„API
            self.logger.info(f"è°ƒç”¨{ai_provider}ç”ŸæˆTerraformä»£ç ")
            if ai_provider == 'anthropic':
                # è°ƒç”¨Anthropic API
                response = client.messages.create(
                    model=model_name,
                    max_tokens=4000,
                    temperature=0.4,
                    system=system_prompt,
                    messages=[
                        {"role": "user", "content": user_prompt}
                    ]
                )
                # è§£æå“åº”
                content = response.content[0].text
            else:
                # è°ƒç”¨OpenAI API
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.4  # é€‚ä¸­çš„æ¸©åº¦ä»¥ç¡®ä¿ä¸€è‡´æ€§
                )
                # è§£æå“åº”
                content = response.choices[0].message.content
            
            # æå–Terraformä»£ç ï¼ˆç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°ï¼‰
            terraform_code = self._clean_terraform_code(content)
            
            # ... existing code ...
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆTerraformä»£ç æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "ç”ŸæˆTerraformä»£ç æ—¶å‡ºé”™",
                "message": str(e)
            }), 500
    
    def _clean_terraform_code(self, content):
        """æ¸…ç†ä»OpenAIè·å¾—çš„Terraformä»£ç ï¼Œç§»é™¤å¯èƒ½çš„Markdownä»£ç å—æ ‡è®°"""
        # ç§»é™¤å¯èƒ½çš„Markdownä»£ç å—æ ‡è®°
        if '```terraform' in content or '```hcl' in content:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ä»£ç å—å†…å®¹
            pattern = r'```(?:terraform|hcl)\s*([\s\S]*?)```'
            matches = re.findall(pattern, content)
            if matches:
                return matches[0].strip()
            
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šçš„ä»£ç å—æ ‡è®°ï¼Œå°è¯•åŒ¹é…ä»»ä½•ä»£ç å—
        if '```' in content:
            pattern = r'```\s*([\s\S]*?)```'
            matches = re.findall(pattern, content)
            if matches:
                return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—æ ‡è®°ï¼Œç›´æ¥è¿”å›æ•´ä¸ªå†…å®¹
        return content.strip()
    
    def deploy_terraform(self):
        """å¤„ç†Terraforméƒ¨ç½²è¯·æ±‚"""
        try:
            # è·å–è¯·æ±‚æ•°æ®
            data = request.get_json()
            if not data:
                return jsonify({"error": "è¯·æ±‚æ•°æ®æ— æ•ˆ"}), 400
            
            # éªŒè¯å¿…éœ€å‚æ•°
            if 'code' not in data:
                return jsonify({"error": "ç¼ºå°‘Terraformä»£ç "}), 400
            
            # è·å–ç”¨æˆ·ID
            user = getattr(request, 'current_user', None)
            user_id = user.get('user_id', 0) if user else 0
            
            # è·å–é¡¹ç›®IDå’Œäº‘å¹³å°ID
            project_id = data.get('project_id', 0)
            project_name = data.get('project_name', 'æœªå‘½åé¡¹ç›®')
            cloud_id = data.get('cloud_id', 0)
            cloud_name = data.get('cloud_name', 'æœªçŸ¥äº‘å¹³å°')
            
            # è®°å½•æ¥æ”¶åˆ°çš„é¡¹ç›®å’Œäº‘å¹³å°ä¿¡æ¯
            self.logger.info(f"éƒ¨ç½²è¯·æ±‚æ¥æ”¶åˆ°çš„é¡¹ç›®å’Œäº‘å¹³å°ä¿¡æ¯: project_id={project_id}, project_name='{project_name}', cloud_id={cloud_id}, cloud_name='{cloud_name}'")
            
            # è·å–APIå¯†é’¥IDæˆ–ç›´æ¥çš„å‡­è¯
            api_key_id = data.get('api_key_id')
            ak = data.get('ak', '')
            sk = data.get('sk', '')
            
            # å¦‚æœæä¾›äº†APIå¯†é’¥IDï¼Œå°è¯•æŸ¥æ‰¾å¯¹åº”çš„å‡­è¯
            if api_key_id and (not ak or not sk):
                try:
                    from controllers.apikey_controller import ApiKeyController
                    apikey_controller = ApiKeyController(self.config)
                    api_key = apikey_controller.get_api_key_by_id(api_key_id)
                    
                    if not api_key:
                        self.logger.error(f"æ‰¾ä¸åˆ°æŒ‡å®šçš„APIå¯†é’¥: {api_key_id}")
                        return jsonify({"error": "æ‰¾ä¸åˆ°æŒ‡å®šçš„APIå¯†é’¥"}), 404
                    
                    # è·å–AKå’ŒSK
                    ak = api_key.get('ak', '')
                    sk = api_key.get('sk', '')
                    
                    self.logger.info(f"æˆåŠŸé€šè¿‡IDè·å–APIå¯†é’¥: {api_key.get('apikey_name')}")
                except Exception as apikey_error:
                    self.logger.error(f"è·å–APIå¯†é’¥æ—¶å‡ºé”™: {str(apikey_error)}")
                    return jsonify({"error": f"è·å–APIå¯†é’¥æ—¶å‡ºé”™: {str(apikey_error)}"}), 500
            
            # æ£€æŸ¥æ˜¯å¦æä¾›äº†å‡­è¯
            if not ak or not sk:
                return jsonify({"error": "è¯·æä¾›æœ‰æ•ˆçš„è®¿é—®å‡­è¯"}), 400
            
            # è·å–åŸå§‹Terraformä»£ç 
            original_code = data.get('code', '')
            
            # æ£€æŸ¥ä»£ç æ˜¯å¦ä¸ºç©º
            if not original_code.strip():
                return jsonify({"error": "ä¸èƒ½éƒ¨ç½²ç©ºçš„Terraformä»£ç "}), 400
            
            # ä½¿ç”¨æ™ºèƒ½å‡­è¯æ·»åŠ æ–¹æ³•ï¼Œæ ¹æ®ä»£ç ä¸­çš„äº‘å¹³å°ç±»å‹è‡ªåŠ¨æ·»åŠ ç›¸åº”å‡­è¯
            terraform_code = self._add_cloud_credentials_to_code(original_code, ak, sk)
            
            # ç”Ÿæˆéƒ¨ç½²ID (AIDPå‰ç¼€+23ä½éšæœºæ•°)
            deploy_id = f"AIDP{uuid.uuid4().hex[:19]}".upper()
            
            # åˆ›å»ºéƒ¨ç½²ç›®å½•
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            os.makedirs(deploy_dir, exist_ok=True)
            
            # åˆ›å»ºmain.tfæ–‡ä»¶
            tf_file_path = os.path.join(deploy_dir, 'main.tf')
            with open(tf_file_path, 'w') as f:
                f.write(terraform_code)
            
            # ä¿å­˜åŸå§‹ä»£ç ï¼Œç”¨äºå¯¹æ¯”å’Œæ¢å¤ï¼ˆä½¿ç”¨.bakæ‰©å±•åé¿å…Terraformè¯»å–ï¼‰
            original_code_path = os.path.join(deploy_dir, 'original.tf.bak')
            with open(original_code_path, 'w') as f:
                f.write(original_code)
            
            # åˆ›å»ºéƒ¨ç½²è®°å½•
            deploy_data = {
                'id': deploy_id,
                'user_id': user_id,
                'username': user.get('username', 'unknown'),
                'name': project_name,
                'description': f"äº‘å¹³å°: {cloud_name}, é¡¹ç›®ID: {project_id}",
                'project': project_name,
                'cloud': cloud_name,
                'status': 'pending',
                'terraform_code': terraform_code,
                'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # ä¿å­˜éƒ¨ç½²è®°å½•
            self.logger.info(f"æ­£åœ¨åˆ›å»ºéƒ¨ç½²è®°å½•: deploy_id={deploy_id}, project='{project_name}', cloud='{cloud_name}'")
            self.deployment_model.create_deployment(deploy_data)
            self.logger.info(f"éƒ¨ç½²è®°å½•å·²åˆ›å»ºå¹¶å†™å…¥æ•°æ®åº“: {deploy_id}")
            
            # å¯åŠ¨åå°ä»»åŠ¡
            deployment_thread = threading.Thread(
                target=self._run_terraform_deployment,
                args=(deploy_id, deploy_dir, user_id)
            )
            deployment_thread.start()
            
            # è®°å½•æ´»è·ƒçš„éƒ¨ç½²ä¿¡æ¯
            self.active_deployments[deploy_id] = {
                'thread': deployment_thread,
                'process': None,  # ç¨ååœ¨_run_terraform_deploymentä¸­è®¾ç½®
                'deploy_dir': deploy_dir,
                'user_id': user_id
            }
            
            return jsonify({
                "success": True,
                "deploy_id": deploy_id,
                "message": "éƒ¨ç½²ä»»åŠ¡å·²æäº¤ï¼Œæ­£åœ¨åå°æ‰§è¡Œ"
            })
            
        except Exception as e:
            self.logger.error(f"éƒ¨ç½²Terraformæ—¶å‡ºé”™: {str(e)}")
            traceback_str = traceback.format_exc()
            self.logger.error(f"è¯¦ç»†é”™è¯¯: {traceback_str}")
            return jsonify({"error": f"éƒ¨ç½²Terraformæ—¶å‡ºé”™: {str(e)}"}), 500
    
    def _add_aws_credentials_to_code(self, terraform_code, ak, sk):
        """å‘Terraformä»£ç ä¸­æ·»åŠ AWSå‡­è¯"""
        # æ£€æŸ¥ä»£ç ä¸­çš„AWS provider
        providers = []
        lines = terraform_code.split('\n')
        
        # å¯»æ‰¾å·²æœ‰çš„AWS providerå¹¶è®°å½•
        for i, line in enumerate(lines):
            if re.match(r'\s*provider\s+"aws"\s+{', line):
                provider_start = i
                provider_end = -1
                
                # æ‰¾åˆ°providerå—çš„ç»“æŸ
                for j in range(provider_start + 1, len(lines)):
                    if re.match(r'\s*}', lines[j]):
                        provider_end = j
                        break
                
                if provider_end > 0:
                    provider_lines = lines[provider_start:provider_end+1]
                    # è·å–provideråˆ«åï¼ˆå¦‚æœæœ‰ï¼‰
                    alias = None
                    for provider_line in provider_lines:
                        alias_match = re.search(r'alias\s+=\s+"([^"]+)"', provider_line)
                        if alias_match:
                            alias = alias_match.group(1)
                            break
                    
                    providers.append({
                        'start': provider_start,
                        'end': provider_end,
                        'alias': alias
                    })
        
        # ä¸ºæ¯ä¸ªprovideræ·»åŠ å‡­è¯
        offset = 0  # è¡Œåç§»é‡ï¼ˆæ·»åŠ è¡Œä¼šæ”¹å˜åç»­è¡Œå·ï¼‰
        
        for provider in providers:
            # è·å–providerå†…å®¹
            start = provider['start'] + offset
            end = provider['end'] + offset
            
            # æ£€æŸ¥providerä¸­æ˜¯å¦å·²æœ‰access_keyå’Œsecret_key
            has_credentials = False
            has_access_key = False
            has_secret_key = False
            
            for i in range(start, end):
                # æ£€æŸ¥æ˜¯å¦æœ‰éç©ºçš„access_keyè®¾ç½®ï¼ˆä¸åŒ…æ‹¬æ³¨é‡Šå’Œç©ºå€¼ï¼‰
                if re.search(r'access_key\s*=\s*".+?"', lines[i]) or re.search(r"access_key\s*=\s*'.+?'", lines[i]):
                    if not re.search(r'access_key\s*=\s*["\']\s*["\']', lines[i]):  # è·³è¿‡ç©ºå€¼
                        has_access_key = True
                        
                # æ£€æŸ¥æ˜¯å¦æœ‰éç©ºçš„secret_keyè®¾ç½®ï¼ˆä¸åŒ…æ‹¬æ³¨é‡Šå’Œç©ºå€¼ï¼‰
                if re.search(r'secret_key\s*=\s*".+?"', lines[i]) or re.search(r"secret_key\s*=\s*'.+?'", lines[i]):
                    if not re.search(r'secret_key\s*=\s*["\']\s*["\']', lines[i]):  # è·³è¿‡ç©ºå€¼
                        has_secret_key = True
                        
                # åªæœ‰ä¸¤è€…éƒ½å­˜åœ¨æ‰è§†ä¸ºæœ‰æ•ˆå‡­è¯
                if has_access_key and has_secret_key:
                    has_credentials = True
                    self.logger.info("æ£€æµ‹åˆ°ç«å±±å¼•æ“providerå·²åŒ…å«æœ‰æ•ˆçš„AK/SK")
                    break
            
            # å¦‚æœæ²¡æœ‰å‡­è¯ï¼Œåˆ™æ·»åŠ 
            if not has_credentials:
                # åœ¨providerå—ç»“æŸå‰æ·»åŠ å‡­è¯
                credentials = [
                    f"  access_key = \"{ak}\"",
                    f"  secret_key = \"{sk}\""
                ]
                
                # æ’å…¥å‡­è¯åˆ°providerå—ç»“æŸå‰
                lines.insert(end, credentials[1])
                lines.insert(end, credentials[0])
                
                # æ›´æ–°åç§»é‡
                offset += 2
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°providerï¼Œåˆ™æ·»åŠ ä¸€ä¸ªé»˜è®¤provider
        if not providers:
            default_provider = [
                "provider \"aws\" {",
                f"  access_key = \"{ak}\"",
                f"  secret_key = \"{sk}\"",
                "  region = \"us-east-1\"",
                "}"
            ]
            
            # åœ¨ä»£ç å¼€å¤´æ·»åŠ é»˜è®¤provider
            lines = default_provider + [''] + lines
        
        return '\n'.join(lines)
    
    def _add_volcengine_credentials_to_code(self, terraform_code, ak, sk):
        """å‘Terraformä»£ç ä¸­æ·»åŠ ç«å±±å¼•æ“å‡­è¯"""
        self.logger.info("æ·»åŠ ç«å±±å¼•æ“å‡­è¯åˆ°Terraformä»£ç ")
        
        # æ£€æŸ¥ä»£ç ä¸­æ˜¯å¦æœ‰ç«å±±å¼•æ“provider
        providers = []
        lines = terraform_code.split('\n')
        
        # å¯»æ‰¾å·²æœ‰çš„ç«å±±å¼•æ“providerå¹¶è®°å½•
        for i, line in enumerate(lines):
            if re.match(r'\s*provider\s+"volcengine"\s+{', line):
                provider_start = i
                provider_end = -1
                
                # æ‰¾åˆ°providerå—çš„ç»“æŸ
                for j in range(provider_start + 1, len(lines)):
                    if re.match(r'\s*}', lines[j]):
                        provider_end = j
                        break
                
                if provider_end > 0:
                    providers.append({
                        'start': provider_start,
                        'end': provider_end
                    })
        
        # ä¸ºæ¯ä¸ªprovideræ·»åŠ å‡­è¯
        offset = 0  # è¡Œåç§»é‡ï¼ˆæ·»åŠ è¡Œä¼šæ”¹å˜åç»­è¡Œå·ï¼‰
        
        for provider in providers:
            # è·å–providerå†…å®¹
            start = provider['start'] + offset
            end = provider['end'] + offset
            
            # æ£€æŸ¥providerä¸­æ˜¯å¦å·²æœ‰access_keyå’Œsecret_key
            has_credentials = False
            has_access_key = False
            has_secret_key = False
            
            for i in range(start, end):
                # æ£€æŸ¥æ˜¯å¦æœ‰éç©ºçš„access_keyè®¾ç½®ï¼ˆä¸åŒ…æ‹¬æ³¨é‡Šå’Œç©ºå€¼ï¼‰
                if re.search(r'access_key\s*=\s*".+?"', lines[i]) or re.search(r"access_key\s*=\s*'.+?'", lines[i]):
                    if not re.search(r'access_key\s*=\s*["\']\s*["\']', lines[i]):  # è·³è¿‡ç©ºå€¼
                        has_access_key = True
                        
                # æ£€æŸ¥æ˜¯å¦æœ‰éç©ºçš„secret_keyè®¾ç½®ï¼ˆä¸åŒ…æ‹¬æ³¨é‡Šå’Œç©ºå€¼ï¼‰
                if re.search(r'secret_key\s*=\s*".+?"', lines[i]) or re.search(r"secret_key\s*=\s*'.+?'", lines[i]):
                    if not re.search(r'secret_key\s*=\s*["\']\s*["\']', lines[i]):  # è·³è¿‡ç©ºå€¼
                        has_secret_key = True
                        
                # åªæœ‰ä¸¤è€…éƒ½å­˜åœ¨æ‰è§†ä¸ºæœ‰æ•ˆå‡­è¯
                if has_access_key and has_secret_key:
                    has_credentials = True
                    self.logger.info("æ£€æµ‹åˆ°ç«å±±å¼•æ“providerå·²åŒ…å«æœ‰æ•ˆçš„AK/SK")
                    break
            
            # å¦‚æœæ²¡æœ‰å‡­è¯ï¼Œåˆ™æ·»åŠ 
            if not has_credentials:
                if has_access_key and not has_secret_key:
                    self.logger.info("ç«å±±å¼•æ“providerä¸­åªæœ‰access_keyä½†ç¼ºå°‘secret_keyï¼Œæ·»åŠ å‡­è¯")
                elif has_secret_key and not has_access_key:
                    self.logger.info("ç«å±±å¼•æ“providerä¸­åªæœ‰secret_keyä½†ç¼ºå°‘access_keyï¼Œæ·»åŠ å‡­è¯")
                else:
                    self.logger.info("ç«å±±å¼•æ“providerä¸­ç¼ºå°‘å®Œæ•´çš„AK/SKå‡­è¯ï¼Œæ·»åŠ å‡­è¯")
                
                # åœ¨providerå—ç»“æŸå‰æ·»åŠ å‡­è¯
                credentials = [
                    f"  access_key = \"{ak}\"",
                    f"  secret_key = \"{sk}\""
                ]
                
                # æ’å…¥å‡­è¯åˆ°providerå—ç»“æŸå‰
                lines.insert(end, credentials[1])
                lines.insert(end, credentials[0])
                
                # æ›´æ–°åç§»é‡
                offset += 2
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°providerï¼Œåˆ™æ·»åŠ ä¸€ä¸ªé»˜è®¤provider
        if not providers:
            # æ£€æŸ¥ä»£ç ä¸­æ˜¯å¦å·²ç»åŒ…å«äº†required_providerså—
            has_required_providers = False
            for line in lines:
                if "required_providers" in line:
                    has_required_providers = True
                    break
            
            # å‡†å¤‡æ·»åŠ çš„ä»£ç å—
            provider_blocks = []
            
            # å¦‚æœæ²¡æœ‰required_providerså—ï¼Œæ·»åŠ ä¸€ä¸ª
            if not has_required_providers:
                provider_blocks.extend([
                    "terraform {",
                    "  required_providers {",
                    "    volcengine = {",
                    "      source = \"volcengine/volcengine\"",
                    "      version = \"0.0.167\"",
                    "    }",
                    "  }",
                    "}",
                    ""
                ])
            
            # æ·»åŠ providerå—
            provider_blocks.extend([
                "provider \"volcengine\" {",
                "  region = \"cn-beijing\"",
                f"  access_key = \"{ak}\"",
                f"  secret_key = \"{sk}\"",
                "}",
                ""
            ])
            
            # åœ¨ä»£ç å¼€å¤´æ·»åŠ providerå—
            lines = provider_blocks + lines
            
            self.logger.info("æ‰¾ä¸åˆ°ç«å±±å¼•æ“providerï¼Œå·²æ·»åŠ é»˜è®¤provideré…ç½®")
        
        return '\n'.join(lines)
    
    def _run_terraform_deployment(self, deploy_id, deploy_dir, user_id):
        """åœ¨åå°è¿è¡ŒTerraforméƒ¨ç½²è¿‡ç¨‹"""
        
        # å®šä¹‰æ£€æŸ¥åœæ­¢ä¿¡å·çš„è¾…åŠ©å‡½æ•°
        def should_stop_deployment():
            """æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢éƒ¨ç½²"""
            stop_file = os.path.join(deploy_dir, '.stop_deployment')
            return os.path.exists(stop_file) or deploy_id not in self.active_deployments
        
        # è®°å½•æ‰§è¡Œè¿‡ç¨‹ä¸­çš„æ‰€æœ‰é‡è¦ä¿¡æ¯ï¼Œç”¨äºåˆ›å»ºæ‘˜è¦æ—¥å¿—
        deployment_logs = {
            'deploy_id': deploy_id,
            'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'status': 'pending',
            'init_output': '',
            'plan_output': '',
            'apply_output': '',
            'init_error': '',
            'plan_error': '',
            'apply_error': '',
            'retry_count': 0,
            'error_message': '',
            'outputs': {}
        }
        
        # åˆ›å»ºæˆ–æ›´æ–°éƒ¨ç½²æ‘˜è¦æ—¥å¿—çš„è¾…åŠ©å‡½æ•°
        def create_deployment_summary(is_success=True):
            deploy_summary_log = os.path.join(deploy_dir, 'deployment_summary.log')
            with open(deploy_summary_log, 'w') as summary_file:
                summary_file.write(f"éƒ¨ç½²ID: {deploy_id}\n")
                summary_file.write(f"å¼€å§‹æ—¶é—´: {deployment_logs['start_time']}\n")
                summary_file.write(f"å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                summary_file.write(f"æ€»é‡è¯•æ¬¡æ•°: {deployment_logs['retry_count']}\n")
                summary_file.write(f"éƒ¨ç½²çŠ¶æ€: {'æˆåŠŸ' if is_success else 'å¤±è´¥'}\n")
                if not is_success:
                    summary_file.write(f"å¤±è´¥åŸå› : {deployment_logs['error_message']}\n")
                summary_file.write("\n")
                
                # æ·»åŠ åˆå§‹åŒ–ä¿¡æ¯
                if deployment_logs['init_output']:
                    summary_file.write("Terraformåˆå§‹åŒ–è¾“å‡º:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['init_output']}\n\n")
                if deployment_logs['init_error']:
                    summary_file.write("Terraformåˆå§‹åŒ–é”™è¯¯:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['init_error']}\n\n")
                
                # æ·»åŠ è§„åˆ’ä¿¡æ¯
                if deployment_logs['plan_output']:
                    summary_file.write("Terraformè§„åˆ’è¾“å‡º:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['plan_output']}\n\n")
                if deployment_logs['plan_error']:
                    summary_file.write("Terraformè§„åˆ’é”™è¯¯:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['plan_error']}\n\n")
                
                # æ·»åŠ åº”ç”¨ä¿¡æ¯
                if deployment_logs['apply_output']:
                    summary_file.write("Terraformåº”ç”¨è¾“å‡º:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['apply_output']}\n\n")
                if deployment_logs['apply_error']:
                    summary_file.write("Terraformåº”ç”¨é”™è¯¯:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['apply_error']}\n\n")
                
                # æ·»åŠ ä¿®å¤å†å²
                if deployment_logs['retry_count'] > 0:
                    summary_file.write("ä¿®å¤å†å²:\n")
                    summary_file.write("-" * 80 + "\n")
                    fix_log_path = os.path.join(deploy_dir, 'fix_attempts.log')
                    if os.path.exists(fix_log_path):
                        with open(fix_log_path, 'r') as fix_log:
                            summary_file.write(fix_log.read())
                    summary_file.write("\n")
                
                # æ·»åŠ è¾“å‡ºå˜é‡
                if is_success and deployment_logs['outputs']:
                    summary_file.write("è¾“å‡ºå˜é‡:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{json.dumps(deployment_logs['outputs'], indent=2)}\n\n")
        
        try:
            self.logger.info(f"å¼€å§‹æ‰§è¡ŒTerraforméƒ¨ç½²: {deploy_id}, ç›®å½•: {deploy_dir}")
            
            # æ£€æŸ¥terraformå‘½ä»¤æ˜¯å¦å­˜åœ¨
            try:
                terraform_version = subprocess.run(
                    ['terraform', '--version'],
                    capture_output=True,
                    text=True
                )
                self.logger.info(f"Terraformç‰ˆæœ¬: {terraform_version.stdout.strip()}")
            except FileNotFoundError:
                error_msg = "æœªæ‰¾åˆ°Terraformå‘½ä»¤ï¼Œè¯·ç¡®ä¿å·²å®‰è£…Terraformå¹¶æ·»åŠ åˆ°PATH"
                self.logger.error(error_msg)
                deployment_logs['error_message'] = error_msg
                deployment_logs['status'] = 'failed'
                create_deployment_summary(is_success=False)
                self.deployment_model.update_deployment_status(
                    deploy_id, 
                    'failed', 
                    error_message=error_msg
                )
                return
            
            # æ£€æŸ¥éƒ¨ç½²ç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(deploy_dir):
                error_msg = f"éƒ¨ç½²ç›®å½•ä¸å­˜åœ¨: {deploy_dir}"
                self.logger.error(error_msg)
                deployment_logs['error_message'] = error_msg
                deployment_logs['status'] = 'failed'
                create_deployment_summary(is_success=False)
                self.deployment_model.update_deployment_status(
                    deploy_id, 
                    'failed', 
                    error_message=error_msg
                )
                return
            
            # æ£€æŸ¥main.tfæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            tf_file_path = os.path.join(deploy_dir, 'main.tf')
            if not os.path.exists(tf_file_path):
                error_msg = f"Terraformé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {tf_file_path}"
                self.logger.error(error_msg)
                deployment_logs['error_message'] = error_msg
                deployment_logs['status'] = 'failed'
                create_deployment_summary(is_success=False)
                self.deployment_model.update_deployment_status(
                    deploy_id, 
                    'failed', 
                    error_message=error_msg
                )
                return
            
            # æœ€å¤§é‡è¯•æ¬¡æ•°
            max_retries = 20
            retry_count = 0
            
            # å¼€å§‹éƒ¨ç½²å¾ªç¯ï¼Œå¸¦é‡è¯•å’Œè‡ªåŠ¨ä¿®å¤æœºåˆ¶
            while retry_count <= max_retries:
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢éƒ¨ç½²
                if should_stop_deployment():
                    self.logger.info(f"æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œç»ˆæ­¢éƒ¨ç½²: {deploy_id}")
                    deployment_logs['error_message'] = 'ç”¨æˆ·æ‰‹åŠ¨åœæ­¢éƒ¨ç½²'
                    deployment_logs['status'] = 'stopped'
                    create_deployment_summary(is_success=False)
                    self.deployment_model.update_deployment_status(
                        deploy_id, 
                        'failed', 
                        error_message='ç”¨æˆ·æ‰‹åŠ¨åœæ­¢éƒ¨ç½²'
                    )
                    return
                
                # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œæ›´æ–°çŠ¶æ€ä¸ºé‡è¯•ä¸­
                if retry_count > 0:
                    self.logger.info(f"ç¬¬{retry_count}æ¬¡é‡è¯•éƒ¨ç½²: {deploy_id}")
                    self.deployment_model.update_deployment_status(
                        deploy_id, 
                        'planning', 
                        error_message=f"ç¬¬{retry_count}æ¬¡é‡è¯•ï¼Œæ­£åœ¨é‡æ–°ç”ŸæˆTerraformä»£ç "
                    )
                    deployment_logs['retry_count'] = retry_count
                
                # æ›´æ–°éƒ¨ç½²çŠ¶æ€ä¸º"initializing"
                self.logger.info(f"æ›´æ–°éƒ¨ç½²çŠ¶æ€ä¸ºinitializing: {deploy_id}")
                self.deployment_model.update_deployment_status(deploy_id, 'initializing')
                
                # è¿è¡Œterraform init
                self.logger.info(f"å¼€å§‹åˆå§‹åŒ–Terraform: {deploy_id}")
                try:
                    init_result = subprocess.run(
                        ['terraform', 'init'],
                        cwd=deploy_dir,
                        capture_output=True,
                        text=True
                    )
                    
                    # è®°å½•è¾“å‡º
                    deployment_logs['init_output'] = init_result.stdout
                    
                    if init_result.returncode != 0:
                        deployment_logs['init_error'] = init_result.stderr
                        if retry_count < max_retries:
                            self.logger.error(f"Terraformåˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•ä¿®å¤: {init_result.stderr}")
                            
                            # å¦‚æœå­˜åœ¨ä¹‹å‰çš„éƒ¨ç½²ï¼Œå…ˆæ‰§è¡Œterraform destroyæ¸…ç†
                            if os.path.exists(os.path.join(deploy_dir, '.terraform')):
                                self.logger.info(f"æ‰§è¡Œterraform destroyæ¸…ç†ä¹‹å‰å¯èƒ½å­˜åœ¨çš„èµ„æº: {deploy_id}")
                                try:
                                    # æ›´æ–°éƒ¨ç½²çŠ¶æ€
                                    self.deployment_model.update_deployment_status(
                                        deploy_id, 
                                        'cleaning', 
                                        error_message=f"æ¸…ç†ä¹‹å‰å¯èƒ½éƒ¨ç½²çš„èµ„æºï¼Œå‡†å¤‡é‡æ–°éƒ¨ç½²"
                                    )
                                    
                                    # æ‰§è¡Œterraform destroy
                                    destroy_result = subprocess.run(
                                        ['terraform', 'destroy', '-auto-approve'],
                                        cwd=deploy_dir,
                                        capture_output=True,
                                        text=True
                                    )
                                    
                                    # è®°å½•æ¸…ç†ç»“æœ
                                    cleanup_log_path = os.path.join(deploy_dir, 'cleanup_attempts.log')
                                    with open(cleanup_log_path, 'a') as cleanup_file:
                                        cleanup_file.write(f"\n\n{'='*80}\n")
                                        cleanup_file.write(f"åˆå§‹åŒ–é”™è¯¯æ¸…ç† - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                        cleanup_file.write(f"{'='*80}\n\n")
                                        cleanup_file.write("æ¸…ç†è¾“å‡º:\n```\n")
                                        cleanup_file.write(destroy_result.stdout)
                                        cleanup_file.write("\n```\n\n")
                                except Exception as destroy_error:
                                    self.logger.error(f"æ‰§è¡Œterraform destroyæ—¶å‡ºé”™: {str(destroy_error)}")
                            
                            # è¯»å–åŸå§‹Terraformä»£ç 
                            with open(tf_file_path, 'r') as f:
                                original_tf = f.read()
                            
                            # å°è¯•ä¿®å¤ä»£ç 
                            fixed_tf = self._fix_terraform_code(original_tf, init_result.stderr, tf_file_path)
                            if fixed_tf:
                                self.logger.info("æˆåŠŸä¿®å¤Terraformä»£ç ï¼Œå‡†å¤‡é‡æ–°éƒ¨ç½²")
                                # ä¿å­˜ä¿®å¤åçš„ä»£ç 
                                with open(tf_file_path, 'w') as f:
                                    f.write(fixed_tf)
                                
                                # åˆ›å»ºå¯¹æ¯”æ—¥å¿—ï¼Œè®°å½•ä¿®æ”¹å‰åçš„å·®å¼‚
                                diff_log_path = os.path.join(deploy_dir, 'code_diff.log')
                                with open(diff_log_path, 'a') as diff_file:
                                    diff_file.write(f"\n\n{'='*80}\n")
                                    diff_file.write(f"ç¬¬{retry_count+1}æ¬¡ä¿®å¤ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    diff_file.write(f"{'='*80}\n\n")
                                    diff_file.write("ä¿®å¤å‰:\n```terraform\n")
                                    diff_file.write(original_tf)
                                    diff_file.write("\n```\n\nä¿®å¤å:\n```terraform\n")
                                    diff_file.write(fixed_tf)
                                    diff_file.write("\n```\n")
                                
                                retry_count += 1
                                # æ›´æ–°éƒ¨ç½²çŠ¶æ€ï¼Œå‘ŠçŸ¥ç”¨æˆ·æ­£åœ¨ä¿®å¤
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'planning', 
                                    error_message=f"æ£€æµ‹åˆ°Terraformåˆå§‹åŒ–é”™è¯¯ï¼Œå·²è‡ªåŠ¨ä¿®å¤å¹¶é‡è¯• ({retry_count}/{max_retries})"
                                )
                                deployment_logs['retry_count'] = retry_count
                                self.logger.info(f"å¼€å§‹ç¬¬{retry_count}æ¬¡é‡è¯•éƒ¨ç½²")
                                continue
                            else:
                                self.logger.warning("æ— æ³•è‡ªåŠ¨ä¿®å¤Terraformä»£ç ")
                        
                        self.logger.error(f"Terraformåˆå§‹åŒ–å¤±è´¥: {init_result.stderr}")
                        
                        # æ¸…ç†å¯èƒ½å·²éƒ¨ç½²çš„èµ„æº(è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æ—¶)
                        if retry_count >= max_retries and os.path.exists(os.path.join(deploy_dir, '.terraform')):
                            self.logger.info(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œå°è¯•æ¸…ç†å¯èƒ½å­˜åœ¨çš„èµ„æº")
                            try:
                                # æ›´æ–°çŠ¶æ€ä¸ºæ¸…ç†ä¸­
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'cleaning', 
                                    error_message=f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ­£åœ¨æ¸…ç†å·²éƒ¨ç½²èµ„æº"
                                )
                                
                                # æ‰§è¡Œterraform destroy
                                destroy_result = subprocess.run(
                                    ['terraform', 'destroy', '-auto-approve'],
                                    cwd=deploy_dir,
                                    capture_output=True,
                                    text=True
                                )
                                
                                if destroy_result.returncode != 0:
                                    self.logger.warning(f"èµ„æºæ¸…ç†å¤±è´¥: {destroy_result.stderr}")
                                else:
                                    self.logger.info(f"èµ„æºæ¸…ç†æˆåŠŸ: {destroy_result.stdout}")
                                
                                # è®°å½•æ¸…ç†ç»“æœ
                                cleanup_log_path = os.path.join(deploy_dir, 'cleanup_attempts.log')
                                with open(cleanup_log_path, 'a') as cleanup_file:
                                    cleanup_file.write(f"\n\n{'='*80}\n")
                                    cleanup_file.write(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æ¸…ç† - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    cleanup_file.write(f"{'='*80}\n\n")
                                    cleanup_file.write("æ¸…ç†è¾“å‡º:\n```\n")
                                    cleanup_file.write(destroy_result.stdout)
                                    cleanup_file.write("\n```\n\n")
                                    if destroy_result.stderr:
                                        cleanup_file.write("æ¸…ç†é”™è¯¯:\n```\n")
                                        cleanup_file.write(destroy_result.stderr)
                                        cleanup_file.write("\n```\n\n")
                            except Exception as destroy_error:
                                self.logger.error(f"æ‰§è¡Œterraform destroyæ—¶å‡ºé”™: {str(destroy_error)}")
                        
                        error_msg = f"åˆå§‹åŒ–å¤±è´¥: {init_result.stderr}"
                        deployment_logs['error_message'] = error_msg
                        deployment_logs['status'] = 'failed'
                        create_deployment_summary(is_success=False)
                        self.deployment_model.update_deployment_status(
                            deploy_id, 
                            'failed', 
                            error_message=error_msg
                        )
                        return
                        
                    self.logger.info(f"Terraformåˆå§‹åŒ–æˆåŠŸ: {init_result.stdout}")
                except Exception as init_error:
                    error_msg = f"æ‰§è¡Œterraform initæ—¶å‡ºé”™: {str(init_error)}"
                    self.logger.error(error_msg)
                    deployment_logs['error_message'] = error_msg
                    deployment_logs['status'] = 'failed'
                    create_deployment_summary(is_success=False)
                    self.deployment_model.update_deployment_status(
                        deploy_id, 
                        'failed', 
                        error_message=error_msg
                    )
                    return
                
                # æ›´æ–°éƒ¨ç½²çŠ¶æ€ä¸º"planning"
                self.logger.info(f"æ›´æ–°éƒ¨ç½²çŠ¶æ€ä¸ºplanning: {deploy_id}")
                self.deployment_model.update_deployment_status(deploy_id, 'planning')
                
                # è¿è¡Œterraform plan
                self.logger.info(f"å¼€å§‹Terraformè§„åˆ’: {deploy_id}")
                try:
                    plan_result = subprocess.run(
                        ['terraform', 'plan', '-out=tfplan'],
                        cwd=deploy_dir,
                        capture_output=True,
                        text=True
                    )
                    
                    # è®°å½•è¾“å‡º
                    deployment_logs['plan_output'] = plan_result.stdout
                    
                    if plan_result.returncode != 0:
                        deployment_logs['plan_error'] = plan_result.stderr
                        if retry_count < max_retries:
                            self.logger.error(f"Terraformè§„åˆ’å¤±è´¥ï¼Œå°è¯•ä¿®å¤: {plan_result.stderr}")
                            
                            # å¦‚æœå­˜åœ¨ä¹‹å‰çš„éƒ¨ç½²ï¼Œå…ˆæ‰§è¡Œterraform destroyæ¸…ç†
                            if os.path.exists(os.path.join(deploy_dir, '.terraform')):
                                self.logger.info(f"æ‰§è¡Œterraform destroyæ¸…ç†ä¹‹å‰å¯èƒ½å­˜åœ¨çš„èµ„æº: {deploy_id}")
                                try:
                                    # æ›´æ–°éƒ¨ç½²çŠ¶æ€
                                    self.deployment_model.update_deployment_status(
                                        deploy_id, 
                                        'cleaning', 
                                        error_message=f"æ¸…ç†ä¹‹å‰å¯èƒ½éƒ¨ç½²çš„èµ„æºï¼Œå‡†å¤‡é‡æ–°éƒ¨ç½²"
                                    )
                                    
                                    # æ‰§è¡Œterraform destroy
                                    destroy_result = subprocess.run(
                                        ['terraform', 'destroy', '-auto-approve'],
                                        cwd=deploy_dir,
                                        capture_output=True,
                                        text=True
                                    )
                                    
                                    # è®°å½•æ¸…ç†ç»“æœ
                                    cleanup_log_path = os.path.join(deploy_dir, 'cleanup_attempts.log')
                                    with open(cleanup_log_path, 'a') as cleanup_file:
                                        cleanup_file.write(f"\n\n{'='*80}\n")
                                        cleanup_file.write(f"è§„åˆ’é”™è¯¯æ¸…ç† - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                        cleanup_file.write(f"{'='*80}\n\n")
                                        cleanup_file.write("æ¸…ç†è¾“å‡º:\n```\n")
                                        cleanup_file.write(destroy_result.stdout)
                                        cleanup_file.write("\n```\n\n")
                                except Exception as destroy_error:
                                    self.logger.error(f"æ‰§è¡Œterraform destroyæ—¶å‡ºé”™: {str(destroy_error)}")
                            
                            # è¯»å–åŸå§‹Terraformä»£ç 
                            with open(tf_file_path, 'r') as f:
                                original_tf = f.read()
                            
                            # å°è¯•ä¿®å¤ä»£ç 
                            fixed_tf = self._fix_terraform_code(original_tf, plan_result.stderr, tf_file_path)
                            if fixed_tf:
                                self.logger.info("æˆåŠŸä¿®å¤Terraformä»£ç ï¼Œå‡†å¤‡é‡æ–°éƒ¨ç½²")
                                # ä¿å­˜ä¿®å¤åçš„ä»£ç 
                                with open(tf_file_path, 'w') as f:
                                    f.write(fixed_tf)
                                
                                # åˆ›å»ºå¯¹æ¯”æ—¥å¿—ï¼Œè®°å½•ä¿®æ”¹å‰åçš„å·®å¼‚
                                diff_log_path = os.path.join(deploy_dir, 'code_diff.log')
                                with open(diff_log_path, 'a') as diff_file:
                                    diff_file.write(f"\n\n{'='*80}\n")
                                    diff_file.write(f"ç¬¬{retry_count+1}æ¬¡ä¿®å¤ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    diff_file.write(f"{'='*80}\n\n")
                                    diff_file.write("ä¿®å¤å‰:\n```terraform\n")
                                    diff_file.write(original_tf)
                                    diff_file.write("\n```\n\nä¿®å¤å:\n```terraform\n")
                                    diff_file.write(fixed_tf)
                                    diff_file.write("\n```\n")
                                
                                retry_count += 1
                                # æ›´æ–°éƒ¨ç½²çŠ¶æ€ï¼Œå‘ŠçŸ¥ç”¨æˆ·æ­£åœ¨ä¿®å¤
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'planning', 
                                    error_message=f"æ£€æµ‹åˆ°Terraformè§„åˆ’é”™è¯¯ï¼Œå·²è‡ªåŠ¨ä¿®å¤å¹¶é‡è¯• ({retry_count}/{max_retries})"
                                )
                                deployment_logs['retry_count'] = retry_count
                                self.logger.info(f"å¼€å§‹ç¬¬{retry_count}æ¬¡é‡è¯•éƒ¨ç½²")
                                continue
                            else:
                                self.logger.warning("æ— æ³•è‡ªåŠ¨ä¿®å¤Terraformä»£ç ")
                        
                        self.logger.error(f"Terraformè§„åˆ’å¤±è´¥: {plan_result.stderr}")
                        
                        # æ¸…ç†å¯èƒ½å·²éƒ¨ç½²çš„èµ„æº(è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æ—¶)
                        if retry_count >= max_retries and os.path.exists(os.path.join(deploy_dir, '.terraform')):
                            self.logger.info(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œå°è¯•æ¸…ç†å¯èƒ½å­˜åœ¨çš„èµ„æº")
                            try:
                                # æ›´æ–°çŠ¶æ€ä¸ºæ¸…ç†ä¸­
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'cleaning', 
                                    error_message=f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ­£åœ¨æ¸…ç†å·²éƒ¨ç½²èµ„æº"
                                )
                                
                                # æ‰§è¡Œterraform destroy
                                destroy_result = subprocess.run(
                                    ['terraform', 'destroy', '-auto-approve'],
                                    cwd=deploy_dir,
                                    capture_output=True,
                                    text=True
                                )
                                
                                if destroy_result.returncode != 0:
                                    self.logger.warning(f"èµ„æºæ¸…ç†å¤±è´¥: {destroy_result.stderr}")
                                else:
                                    self.logger.info(f"èµ„æºæ¸…ç†æˆåŠŸ: {destroy_result.stdout}")
                                
                                # è®°å½•æ¸…ç†ç»“æœ
                                cleanup_log_path = os.path.join(deploy_dir, 'cleanup_attempts.log')
                                with open(cleanup_log_path, 'a') as cleanup_file:
                                    cleanup_file.write(f"\n\n{'='*80}\n")
                                    cleanup_file.write(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æ¸…ç† - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    cleanup_file.write(f"{'='*80}\n\n")
                                    cleanup_file.write("æ¸…ç†è¾“å‡º:\n```\n")
                                    cleanup_file.write(destroy_result.stdout)
                                    cleanup_file.write("\n```\n\n")
                                    if destroy_result.stderr:
                                        cleanup_file.write("æ¸…ç†é”™è¯¯:\n```\n")
                                        cleanup_file.write(destroy_result.stderr)
                                        cleanup_file.write("\n```\n\n")
                            except Exception as destroy_error:
                                self.logger.error(f"æ‰§è¡Œterraform destroyæ—¶å‡ºé”™: {str(destroy_error)}")
                                
                        error_msg = f"è§„åˆ’å¤±è´¥: {plan_result.stderr}"
                        deployment_logs['error_message'] = error_msg
                        deployment_logs['status'] = 'failed'
                        create_deployment_summary(is_success=False)
                        self.deployment_model.update_deployment_status(
                            deploy_id, 
                            'failed', 
                            error_message=error_msg
                        )
                        return
                        
                    self.logger.info(f"Terraformè§„åˆ’æˆåŠŸ: {plan_result.stdout}")
                except Exception as plan_error:
                    error_msg = f"æ‰§è¡Œterraform planæ—¶å‡ºé”™: {str(plan_error)}"
                    self.logger.error(error_msg)
                    deployment_logs['error_message'] = error_msg
                    deployment_logs['status'] = 'failed'
                    create_deployment_summary(is_success=False)
                    self.deployment_model.update_deployment_status(
                        deploy_id, 
                        'failed', 
                        error_message=error_msg
                    )
                    return
                
                # æ›´æ–°éƒ¨ç½²çŠ¶æ€ä¸º"applying"
                self.logger.info(f"æ›´æ–°éƒ¨ç½²çŠ¶æ€ä¸ºapplying: {deploy_id}")
                self.deployment_model.update_deployment_status(deploy_id, 'applying')
                
                # è¿è¡Œterraform apply
                self.logger.info(f"å¼€å§‹åº”ç”¨Terraformé…ç½®: {deploy_id}")
                try:
                    apply_result = subprocess.run(
                        ['terraform', 'apply', '-auto-approve', 'tfplan'],
                        cwd=deploy_dir,
                        capture_output=True,
                        text=True
                    )
                    
                    # è®°å½•è¾“å‡º
                    deployment_logs['apply_output'] = apply_result.stdout
                    
                    if apply_result.returncode != 0:
                        deployment_logs['apply_error'] = apply_result.stderr
                        # è®°å½•å®Œæ•´çš„é”™è¯¯æ¶ˆæ¯åˆ°æ—¥å¿—ï¼Œä¾¿äºè¯Šæ–­
                        self.logger.error(f"Terraformåº”ç”¨å¤±è´¥ï¼Œå®Œæ•´é”™è¯¯: {apply_result.stderr}")
                        
                        if retry_count < max_retries:
                            self.logger.info(f"å°è¯•ä¿®å¤Terraformåº”ç”¨é”™è¯¯ï¼Œç¬¬{retry_count+1}æ¬¡å°è¯•")
                            
                            # å…ˆæ‰§è¡Œterraform destroyæ¸…ç†ä¹‹å‰éƒ¨ç½²çš„èµ„æº
                            self.logger.info(f"æ‰§è¡Œterraform destroyæ¸…ç†ä¹‹å‰çš„éƒ¨ç½²èµ„æº: {deploy_id}")
                            try:
                                # æ›´æ–°éƒ¨ç½²çŠ¶æ€ï¼Œå‘ŠçŸ¥ç”¨æˆ·æ­£åœ¨æ¸…ç†èµ„æº
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'cleaning', 
                                    error_message=f"æ¸…ç†ä¹‹å‰éƒ¨ç½²çš„èµ„æºï¼Œå‡†å¤‡é‡æ–°éƒ¨ç½²"
                                )
                                
                                # æ‰§è¡Œterraform destroy
                                destroy_result = subprocess.run(
                                    ['terraform', 'destroy', '-auto-approve'],
                                    cwd=deploy_dir,
                                    capture_output=True,
                                    text=True
                                )
                                
                                if destroy_result.returncode != 0:
                                    self.logger.warning(f"Terraformèµ„æºæ¸…ç†å¤±è´¥ï¼Œå¯èƒ½å­˜åœ¨æ®‹ç•™èµ„æº: {destroy_result.stderr}")
                                else:
                                    self.logger.info(f"Terraformèµ„æºæ¸…ç†æˆåŠŸ: {destroy_result.stdout}")
                                    
                                # è®°å½•æ¸…ç†ç»“æœåˆ°æ—¥å¿—
                                cleanup_log_path = os.path.join(deploy_dir, 'cleanup_attempts.log')
                                with open(cleanup_log_path, 'a') as cleanup_file:
                                    cleanup_file.write(f"\n\n{'='*80}\n")
                                    cleanup_file.write(f"ç¬¬{retry_count+1}æ¬¡æ¸…ç† - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    cleanup_file.write(f"{'='*80}\n\n")
                                    cleanup_file.write("æ¸…ç†è¾“å‡º:\n```\n")
                                    cleanup_file.write(destroy_result.stdout)
                                    cleanup_file.write("\n```\n\n")
                                    if destroy_result.stderr:
                                        cleanup_file.write("æ¸…ç†é”™è¯¯:\n```\n")
                                        cleanup_file.write(destroy_result.stderr)
                                        cleanup_file.write("\n```\n\n")
                            except Exception as destroy_error:
                                self.logger.error(f"æ‰§è¡Œterraform destroyæ—¶å‡ºé”™: {str(destroy_error)}")
                            
                            # è¯»å–åŸå§‹Terraformä»£ç 
                            with open(tf_file_path, 'r') as f:
                                original_tf = f.read()
                            
                            # å°è¯•ä¿®å¤ä»£ç  - ç›´æ¥ä¼ é€’å®Œæ•´é”™è¯¯æ¶ˆæ¯
                            fixed_tf = self._fix_terraform_code(original_tf, apply_result.stderr, tf_file_path)
                            if fixed_tf:
                                self.logger.info("æˆåŠŸä¿®å¤Terraformä»£ç ï¼Œå‡†å¤‡é‡æ–°éƒ¨ç½²")
                                # ä¿å­˜ä¿®å¤åçš„ä»£ç 
                                with open(tf_file_path, 'w') as f:
                                    f.write(fixed_tf)
                                
                                # åˆ›å»ºå¯¹æ¯”æ—¥å¿—ï¼Œè®°å½•ä¿®æ”¹å‰åçš„å·®å¼‚
                                diff_log_path = os.path.join(deploy_dir, 'code_diff.log')
                                with open(diff_log_path, 'a') as diff_file:
                                    diff_file.write(f"\n\n{'='*80}\n")
                                    diff_file.write(f"ç¬¬{retry_count+1}æ¬¡ä¿®å¤ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    diff_file.write(f"{'='*80}\n\n")
                                    diff_file.write("ä¿®å¤å‰:\n```terraform\n")
                                    diff_file.write(original_tf)
                                    diff_file.write("\n```\n\nä¿®å¤å:\n```terraform\n")
                                    diff_file.write(fixed_tf)
                                    diff_file.write("\n```\n")
                                
                                retry_count += 1
                                # æ›´æ–°éƒ¨ç½²çŠ¶æ€ï¼Œå‘ŠçŸ¥ç”¨æˆ·æ­£åœ¨ä¿®å¤
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'planning', 
                                    error_message=f"æ£€æµ‹åˆ°Terraformåº”ç”¨é”™è¯¯ï¼Œå·²è‡ªåŠ¨ä¿®å¤å¹¶é‡è¯• ({retry_count}/{max_retries})"
                                )
                                deployment_logs['retry_count'] = retry_count
                                self.logger.info(f"å¼€å§‹ç¬¬{retry_count}æ¬¡é‡è¯•éƒ¨ç½²")
                                continue
                            else:
                                self.logger.warning("æ— æ³•è‡ªåŠ¨ä¿®å¤Terraformä»£ç ")
                        
                        self.logger.error(f"Terraformåº”ç”¨å¤±è´¥: {apply_result.stderr}")
                        
                        # æ¸…ç†å·²éƒ¨ç½²çš„èµ„æº(è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æ—¶)
                        if retry_count >= max_retries and os.path.exists(os.path.join(deploy_dir, '.terraform')):
                            self.logger.info(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œæ¸…ç†å·²éƒ¨ç½²èµ„æº")
                            try:
                                # æ›´æ–°çŠ¶æ€ä¸ºæ¸…ç†ä¸­
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'cleaning', 
                                    error_message=f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ­£åœ¨æ¸…ç†å·²éƒ¨ç½²èµ„æº"
                                )
                                
                                # æ‰§è¡Œterraform destroy
                                destroy_result = subprocess.run(
                                    ['terraform', 'destroy', '-auto-approve'],
                                    cwd=deploy_dir,
                                    capture_output=True,
                                    text=True
                                )
                                
                                if destroy_result.returncode != 0:
                                    self.logger.warning(f"èµ„æºæ¸…ç†å¤±è´¥: {destroy_result.stderr}")
                                else:
                                    self.logger.info(f"èµ„æºæ¸…ç†æˆåŠŸ: {destroy_result.stdout}")
                                
                                # è®°å½•æ¸…ç†ç»“æœ
                                cleanup_log_path = os.path.join(deploy_dir, 'cleanup_attempts.log')
                                with open(cleanup_log_path, 'a') as cleanup_file:
                                    cleanup_file.write(f"\n\n{'='*80}\n")
                                    cleanup_file.write(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æ¸…ç† - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    cleanup_file.write(f"{'='*80}\n\n")
                                    cleanup_file.write("æ¸…ç†è¾“å‡º:\n```\n")
                                    cleanup_file.write(destroy_result.stdout)
                                    cleanup_file.write("\n```\n\n")
                                    if destroy_result.stderr:
                                        cleanup_file.write("æ¸…ç†é”™è¯¯:\n```\n")
                                        cleanup_file.write(destroy_result.stderr)
                                        cleanup_file.write("\n```\n\n")
                            except Exception as destroy_error:
                                self.logger.error(f"æ‰§è¡Œterraform destroyæ—¶å‡ºé”™: {str(destroy_error)}")
                                
                        error_msg = f"åº”ç”¨å¤±è´¥: {apply_result.stderr}"
                        deployment_logs['error_message'] = error_msg
                        deployment_logs['status'] = 'failed'
                        create_deployment_summary(is_success=False)
                        self.deployment_model.update_deployment_status(
                            deploy_id, 
                            'failed', 
                            error_message=error_msg
                        )
                        return
                        
                    self.logger.info(f"Terraformåº”ç”¨æˆåŠŸ: {apply_result.stdout}")
                    
                    # éƒ¨ç½²æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    break
                except Exception as apply_error:
                    error_msg = f"æ‰§è¡Œterraform applyæ—¶å‡ºé”™: {str(apply_error)}"
                    self.logger.error(error_msg)
                    deployment_logs['error_message'] = error_msg
                    deployment_logs['status'] = 'failed'
                    create_deployment_summary(is_success=False)
                    self.deployment_model.update_deployment_status(
                        deploy_id, 
                        'failed', 
                        error_message=error_msg
                    )
                    return
            
            # éƒ¨ç½²æˆåŠŸï¼Œè·å–è¾“å‡ºä¿¡æ¯
            try:
                output_result = subprocess.run(
                    ['terraform', 'output', '-json'],
                    cwd=deploy_dir,
                    capture_output=True,
                    text=True
                )
                
                outputs = {}
                if output_result.returncode == 0 and output_result.stdout:
                    try:
                        outputs = json.loads(output_result.stdout)
                        self.logger.info(f"Terraformè¾“å‡º: {outputs}")
                        deployment_logs['outputs'] = outputs
                    except json.JSONDecodeError:
                        self.logger.warning(f"æ— æ³•è§£æTerraformè¾“å‡º: {output_result.stdout}")
                
                # è®¾ç½®æœ€ç»ˆçŠ¶æ€å’Œåˆ›å»ºæˆåŠŸæ‘˜è¦
                deployment_logs['status'] = 'completed'
                create_deployment_summary(is_success=True)
                
                # æ›´æ–°éƒ¨ç½²çŠ¶æ€ä¸º"completed"
                deployment_summary = {
                    'outputs': outputs,
                    'apply_output': apply_result.stdout,
                    'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'retry_count': retry_count,
                    'auto_fixed': retry_count > 0
                }
                self.logger.info(f"æ›´æ–°éƒ¨ç½²çŠ¶æ€ä¸ºcompleted: {deploy_id}")
                self.deployment_model.update_deployment_status(
                    deploy_id, 
                    'completed',
                    deployment_summary=json.dumps(deployment_summary)
                )
                
                self.logger.info(f"Terraforméƒ¨ç½²æˆåŠŸå®Œæˆ: {deploy_id}")
                if retry_count > 0:
                    self.logger.info(f"éƒ¨ç½²ç»è¿‡ {retry_count} æ¬¡è‡ªåŠ¨ä¿®å¤åæˆåŠŸå®Œæˆ")
            except Exception as output_error:
                error_msg = f"è·å–Terraformè¾“å‡ºæ—¶å‡ºé”™: {str(output_error)}"
                self.logger.error(error_msg)
                deployment_logs['error_message'] = error_msg
                deployment_logs['status'] = 'failed'
                create_deployment_summary(is_success=False)
                self.deployment_model.update_deployment_status(
                    deploy_id, 
                    'failed', 
                    error_message=error_msg
                )
                return
            
        except Exception as e:
            self.logger.error(f"Terraforméƒ¨ç½²è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            self.logger.error(traceback.format_exc())
            
            # æ›´æ–°éƒ¨ç½²çŠ¶æ€ä¸º"failed"å¹¶åˆ›å»ºå¤±è´¥æ‘˜è¦
            error_msg = str(e)
            deployment_logs['error_message'] = error_msg
            deployment_logs['status'] = 'failed'
            create_deployment_summary(is_success=False)
            
            self.deployment_model.update_deployment_status(
                deploy_id, 
                'failed', 
                error_message=error_msg
            )
        
        finally:
            # æ¸…ç†æ´»è·ƒéƒ¨ç½²è®°å½•
            if deploy_id in self.active_deployments:
                del self.active_deployments[deploy_id]
                self.logger.info(f"å·²æ¸…ç†æ´»è·ƒéƒ¨ç½²è®°å½•: {deploy_id}")
            
            # æ¸…ç†åœæ­¢ä¿¡å·æ–‡ä»¶
            stop_file = os.path.join(deploy_dir, '.stop_deployment')
            if os.path.exists(stop_file):
                try:
                    os.remove(stop_file)
                    self.logger.info(f"å·²æ¸…ç†åœæ­¢ä¿¡å·æ–‡ä»¶: {stop_file}")
                except Exception as e:
                    self.logger.warning(f"æ¸…ç†åœæ­¢ä¿¡å·æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def _fix_terraform_code(self, original_code, error_message, tf_file_path):
        """Fix Terraform code using AI assistance"""
        try:
            self.logger.info("å¼€å§‹ä¿®å¤Terraformä»£ç ")
            self.logger.info(f"MCP serverçŠ¶æ€: {'å¯ç”¨' if self.enable_mcp else 'ç¦ç”¨'}")
            
            if self.enable_mcp:
                self.logger.info("ä¼˜å…ˆå°è¯•ä½¿ç”¨MCP serverä¿®å¤Terraformä»£ç ")
                # Try using MCP server first
                fixed_code = self._fix_with_mcp(original_code, error_message)
                if fixed_code:
                    self.logger.info("MCP serveræˆåŠŸä¿®å¤ä»£ç ï¼Œè¿”å›ä¿®å¤ç»“æœ")
                    return fixed_code
                else:
                    self.logger.info("MCP serverä¿®å¤å¤±è´¥ï¼Œåˆ‡æ¢åˆ°ä¼ ç»ŸAIä¿®å¤æ–¹æ³•")
            else:
                self.logger.info("MCP serverå·²ç¦ç”¨ï¼Œç›´æ¥ä½¿ç”¨ä¼ ç»ŸAIä¿®å¤æ–¹æ³•")
            
            # Fall back to regular AI fix if MCP fails or is disabled
            self.logger.info("å¼€å§‹ä½¿ç”¨ä¼ ç»ŸAIæ–¹æ³•ä¿®å¤Terraformä»£ç ")
            return self._fix_terraform_code_legacy(original_code, error_message, tf_file_path)
            
        except Exception as e:
            self.logger.error(f"ä¿®å¤Terraformä»£ç æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return None

    def _fix_with_mcp(self, original_code: str, error_message: str) -> Optional[str]:
        """Attempt to fix Terraform code using MCP server via stdio"""
        try:
            self.logger.info(f"å¼€å§‹ä½¿ç”¨MCP serverä¿®å¤Terraformä»£ç ")
            
            # æ£€æŸ¥MCP serverå®¹å™¨æ˜¯å¦åœ¨è¿è¡Œ
            try:
                containers = self.docker_client.containers.list()
                mcp_container = None
                for container in containers:
                    if container.name == "terraform-mcp-server":
                        mcp_container = container
                        break
                
                if not mcp_container:
                    self.logger.error("MCP serverå®¹å™¨æœªè¿è¡Œ")
                    return None
                
                self.logger.info(f"æ‰¾åˆ°è¿è¡Œä¸­çš„MCP serverå®¹å™¨: {mcp_container.id}")
                
                # è®°å½•å‘é€åˆ°MCP serverçš„è¯·æ±‚å†…å®¹
                self.logger.info(f"å‘é€åˆ°MCP serverçš„è¯·æ±‚æ•°æ®:")
                self.logger.info(f"- åŸå§‹ä»£ç é•¿åº¦: {len(original_code)} å­—ç¬¦")
                self.logger.info(f"- é”™è¯¯ä¿¡æ¯: {error_message[:200]}{'...' if len(error_message) > 200 else ''}")
                
                # æ„å»ºMCPè¯·æ±‚ï¼ˆJSON-RPCæ ¼å¼ï¼‰
                import json
                mcp_request = {
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "fix_terraform",
                        "arguments": {
                            "code": original_code,
                            "error": error_message
                        }
                    }
                }
                
                # é€šè¿‡å®¹å™¨çš„ stdin å‘é€è¯·æ±‚
                request_str = json.dumps(mcp_request) + "\n"
                self.logger.info(f"å‘MCP serverå‘é€JSON-RPCè¯·æ±‚")
                
                # æ‰§è¡Œå‘½ä»¤ä¸MCP serveräº¤äº’
                exec_result = mcp_container.exec_run(
                    cmd=["sh", "-c", f"echo '{request_str}' | cat"],
                    stdin=True,
                    stdout=True,
                    stderr=True
                )
                
                self.logger.info(f"MCP serveræ‰§è¡Œç»“æœé€€å‡ºç : {exec_result.exit_code}")
                
                if exec_result.exit_code == 0:
                    output = exec_result.output.decode('utf-8') if exec_result.output else ""
                    self.logger.info(f"MCP serverå“åº”: {output[:500]}{'...' if len(output) > 500 else ''}")
                    
                    # å°è¯•è§£æJSONå“åº”
                    try:
                        response_data = json.loads(output.strip())
                        if response_data.get("result"):
                            fixed_code = response_data["result"].get("fixed_code", "")
                            if fixed_code:
                                self.logger.info(f"MCP serveræˆåŠŸä¿®å¤ä»£ç ï¼Œä¿®å¤åä»£ç é•¿åº¦: {len(fixed_code)} å­—ç¬¦")
                                return fixed_code
                    except json.JSONDecodeError as json_error:
                        self.logger.error(f"è§£æMCP serverå“åº”JSONå¤±è´¥: {str(json_error)}")
                else:
                    self.logger.error(f"MCP serveræ‰§è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {exec_result.exit_code}")
                    if exec_result.output:
                        self.logger.error(f"é”™è¯¯è¾“å‡º: {exec_result.output.decode('utf-8')}")
                
            except Exception as container_error:
                self.logger.error(f"ä¸MCP serverå®¹å™¨äº¤äº’æ—¶å‡ºé”™: {str(container_error)}")
            
            self.logger.warning("MCP serveræ— æ³•ä¿®å¤ä»£ç ï¼Œå›é€€åˆ°ä¼ ç»ŸAIä¿®å¤æ–¹æ³•")
            return None
            
        except Exception as e:
            self.logger.error(f"ä½¿ç”¨MCP serveræ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return None
    
    def _fix_terraform_code_legacy(self, original_code, error_message, tf_file_path):
        """æ ¹æ®é…ç½®çš„AIæä¾›å•†ä¿®å¤Terraformä»£ç """
        try:
            # åˆ›å»ºä¿®å¤æ—¥å¿—æ–‡ä»¶è·¯å¾„
            deploy_id = os.path.basename(os.path.dirname(tf_file_path))
            fix_log_path = os.path.join(os.path.dirname(tf_file_path), 'fix.log')
            
            # ç¡®å®šAIæä¾›å•†
            ai_provider = 'openai'  # é»˜è®¤å€¼
            if self.config:
                ai_provider = getattr(self.config, 'ai_model_provider', 'openai').lower()
            else:
                ai_provider = os.environ.get('AI_MODEL_PROVIDER', 'openai').lower()
            
            self.logger.info(f"ä½¿ç”¨AIæä¾›å•†ä¿®å¤Terraformä»£ç : {ai_provider}")
            
            # æ ¹æ®AIæä¾›å•†è·å–ç›¸åº”çš„é…ç½®
            if ai_provider == 'anthropic':
                # Anthropicé…ç½®
                api_key = None
                if self.config:
                    api_key = getattr(self.config, 'anthropic_api_key', '')
                if not api_key:
                    api_key = os.environ.get('ANTHROPIC_API_KEY', '')
                
                api_base_url = None
                if self.config:
                    api_base_url = getattr(self.config, 'anthropic_api_base_url', 'https://api.anthropic.com/v1')
                if not api_base_url:
                    api_base_url = os.environ.get('ANTHROPIC_API_BASE_URL', 'https://api.anthropic.com/v1')
                
                model_name = None
                if self.config:
                    model_name = getattr(self.config, 'anthropic_api_model', 'claude-3-5-sonnet-20241022')
                if not model_name:
                    model_name = os.environ.get('ANTHROPIC_API_MODEL', 'claude-3-5-sonnet-20241022')
                
                if not api_key:
                    self.logger.error("æœªé…ç½®Anthropic APIå¯†é’¥ï¼Œæ— æ³•ä¿®å¤Terraformä»£ç ")
                    with open(fix_log_path, 'a') as log_file:
                        log_file.write("æœªé…ç½®Anthropic APIå¯†é’¥ï¼Œæ— æ³•ä¿®å¤Terraformä»£ç \n")
                    return None
            else:
                # OpenAIé…ç½®ï¼ˆé»˜è®¤ï¼‰
                api_key = None
                if hasattr(self, 'openai_api_key'):
                    api_key = self.openai_api_key
                elif self.config:
                    api_key = getattr(self.config, 'openai_api_key', '')
                
                if not api_key:
                    api_key = os.environ.get('OPENAI_API_KEY', '')
                    
                api_base_url = None
                if hasattr(self, 'openai_api_base_url'):
                    api_base_url = self.openai_api_base_url
                elif self.config:
                    api_base_url = getattr(self.config, 'openai_api_base_url', 'https://api.openai.com/v1')
                
                if not api_base_url:
                    api_base_url = os.environ.get('OPENAI_API_BASE_URL', 'https://api.openai.com/v1')
                
                model_name = None
                if hasattr(self, 'openai_api_model'):
                    model_name = self.openai_api_model
                elif self.config:
                    model_name = getattr(self.config, 'openai_api_model', 'gpt-4o')
                
                if not model_name:
                    model_name = os.environ.get('OPENAI_API_MODEL', 'gpt-4o')
                
                if not api_key:
                    self.logger.error("æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œæ— æ³•ä¿®å¤Terraformä»£ç ")
                    with open(fix_log_path, 'a') as log_file:
                        log_file.write("æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œæ— æ³•ä¿®å¤Terraformä»£ç \n")
                    return None
                
            # è®°å½•ä½¿ç”¨çš„APIè®¾ç½®
            self.logger.info(f"ä½¿ç”¨API Base URL: {api_base_url}")
            self.logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # æ ¹æ®AIæä¾›å•†åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = None
            if ai_provider == 'anthropic':
                import anthropic
                client = anthropic.Anthropic(
                    api_key=api_key,
                    base_url=api_base_url
                )
            else:
                import openai
                client = openai.OpenAI(
                    api_key=api_key,
                    base_url=api_base_url
                )
            
            # æå–æ‰€æœ‰åŒ…å«"Error:"çš„é”™è¯¯ä¿¡æ¯
            error_lines = []
            lines = error_message.split('\n')
            for i, line in enumerate(lines):
                if 'Error:' in line:
                    # æ”¶é›†è¿™ä¸€è¡Œä»¥åŠåé¢çš„6è¡Œä½œä¸ºä¸Šä¸‹æ–‡
                    error_block = [line.strip()]
                    for j in range(1, 7):
                        if i + j < len(lines) and lines[i + j].strip():
                            error_block.append(lines[i + j].strip())
                    
                    error_lines.append('\n'.join(error_block))
            
            if not error_lines:
                self.logger.warning("æœªæ‰¾åˆ°åŒ…å«Error:çš„é”™è¯¯ä¿¡æ¯ï¼Œæ— æ³•ä¿®å¤")
                with open(fix_log_path, 'a') as log_file:
                    log_file.write("æœªæ‰¾åˆ°Error:å¼€å¤´çš„é”™è¯¯ä¿¡æ¯ï¼Œå°è¯•ä½¿ç”¨å®Œæ•´é”™è¯¯æ¶ˆæ¯\n")
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šæ ¼å¼çš„é”™è¯¯ï¼Œä½¿ç”¨å®Œæ•´çš„é”™è¯¯æ¶ˆæ¯
                error_lines = [error_message]
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç«å±±å¼•æ“ä»£ç 
            is_volcengine = "volcengine" in original_code.lower() or "ç«å±±" in original_code
            
            # æ„å»ºä¿®å¤æç¤º
            fix_prompt = self._build_fix_prompt(original_code, error_lines, is_volcengine)
            
            # è®°å½•æç¤ºåˆ°æ—¥å¿—
            with open(fix_log_path, 'a') as log_file:
                log_file.write("æäº¤ç»™AIçš„é”™è¯¯ä¿¡æ¯:\n")
                log_file.write('\n\n'.join(error_lines))
                log_file.write("\n\n")
            
            # æ ¹æ®AIæä¾›å•†è°ƒç”¨ç›¸åº”çš„API
            if ai_provider == 'anthropic':
                # è°ƒç”¨Anthropic API
                response = client.messages.create(
                    model=model_name,
                    max_tokens=4000,
                    temperature=0.7,
                    system=fix_prompt['system'],
                    messages=[
                        {"role": "user", "content": fix_prompt['user']}
                    ]
                )
                # æå–ä¿®å¤åçš„ä»£ç 
                fixed_code = response.content[0].text
            else:
                # è°ƒç”¨OpenAI API
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": fix_prompt['system']},
                        {"role": "user", "content": fix_prompt['user']}
                    ],
                    temperature=0.7,
                    max_tokens=4000
                )
                # æå–ä¿®å¤åçš„ä»£ç 
                fixed_code = response.choices[0].message.content
            
            # æå–ä¿®å¤åçš„ä»£ç ï¼ˆç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°ï¼‰
            fixed_code = self._clean_terraform_code(fixed_code)
            
            # è®°å½•ä¿®å¤åçš„ä»£ç åˆ°æ—¥å¿—
            with open(fix_log_path, 'a') as log_file:
                log_file.write("AIä¿®å¤åçš„ä»£ç :\n")
                log_file.write(fixed_code)
                log_file.write("\n\n")
                
            # ä¿ç•™åŸå§‹å‡­è¯
            fixed_code = self._preserve_credentials(original_code, fixed_code, is_volcengine, fix_log_path)
            
            return fixed_code
            
        except Exception as e:
            self.logger.error(f"ä¿®å¤Terraformä»£ç æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(traceback.format_exc())
            with open(fix_log_path, 'a') as log_file:
                log_file.write(f"ä¿®å¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}\n")
                log_file.write(traceback.format_exc())
                log_file.write("\n")
            return None
    
    def get_deployment_status(self, deploy_id):
        """è·å–éƒ¨ç½²çŠ¶æ€"""
        try:
            if not deploy_id:
                return jsonify({"success": False, "message": "éƒ¨ç½²IDä¸ºç©º"}), 400
                
            deployment = self.deployment_model.get_deployment(deploy_id)
            if not deployment:
                return jsonify({"success": False, "message": "æœªæ‰¾åˆ°éƒ¨ç½²ä¿¡æ¯"}), 404
                
            return jsonify({
                "success": True,
                "deployment": deployment
            })
            
        except Exception as e:
            self.logger.error(f"è·å–éƒ¨ç½²çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
            return jsonify({
                "success": False,
                "error": "è·å–éƒ¨ç½²çŠ¶æ€æ—¶å‡ºé”™",
                "message": str(e)
            }), 500
    
    def deploy_terraform_init(self):
        """åˆå§‹åŒ–å¤§å‹Terraforméƒ¨ç½²ï¼ˆåˆ†æ‰¹ä¸Šä¼ ä»£ç ï¼‰"""
        try:
            # è·å–è¯·æ±‚æ•°æ®
            self.logger.info("å¼€å§‹å¤„ç†åˆ†æ‰¹Terraforméƒ¨ç½²åˆå§‹åŒ–è¯·æ±‚")
            data = request.get_json()
            if not data:
                self.logger.error("è¯·æ±‚æ•°æ®ä¸ºç©º")
                return jsonify({"success": False, "message": "è¯·æ±‚æ•°æ®ä¸ºç©º"}), 400
            
            terraform_code_part = data.get('terraform_code_part', '')
            if not terraform_code_part:
                self.logger.error("Terraformä»£ç ç‰‡æ®µä¸ºç©º")
                return jsonify({"success": False, "message": "Terraformä»£ç ç‰‡æ®µä¸ºç©º"}), 400
                
            # è·å–å¿…è¦å‚æ•°
            is_multipart = data.get('is_multipart', False)
            total_parts = data.get('total_parts', 1)
            part_index = data.get('part_index', 0)
            
            # éªŒè¯è¿™æ˜¯ç¬¬ä¸€ä¸ªç‰‡æ®µ
            if part_index != 0:
                self.logger.error("åˆå§‹åŒ–è¯·æ±‚å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ªç‰‡æ®µ")
                return jsonify({"success": False, "message": "åˆå§‹åŒ–è¯·æ±‚å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ªç‰‡æ®µ"}), 400
                
            # è·å–APIå¯†é’¥ID
            api_key_id = data.get('api_key_id')
            if not api_key_id:
                self.logger.error("æœªæä¾›APIå¯†é’¥ID")
                return jsonify({"success": False, "message": "è¯·é€‰æ‹©APIå¯†é’¥"}), 400
                
            # è·å–æè¿°å’Œéƒ¨ç½²åç§°
            description = data.get('description', 'é€šè¿‡AIç”Ÿæˆçš„éƒ¨ç½²')
            deploy_name = data.get('deploy_name', '')
            
            # è·å–é¡¹ç›®å’Œäº‘å¹³å°ä¿¡æ¯
            project_id = data.get('project_id', 0)
            project_name = data.get('project_name', 'æœªå‘½åé¡¹ç›®')
            cloud_id = data.get('cloud_id', 0)
            cloud_name = data.get('cloud_name', 'æœªçŸ¥äº‘å¹³å°')
            
            self.logger.info(f"åˆ†æ‰¹éƒ¨ç½²åˆå§‹åŒ–: éƒ¨ç½²åç§°: {deploy_name}, æè¿°é•¿åº¦: {len(description)}, æ€»åˆ†ç‰‡: {total_parts}")
            self.logger.info(f"åˆ†æ‰¹éƒ¨ç½²æ¥æ”¶åˆ°çš„é¡¹ç›®å’Œäº‘å¹³å°ä¿¡æ¯: project_id={project_id}, project_name='{project_name}', cloud_id={cloud_id}, cloud_name='{cloud_name}'")
            
            # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
            try:
                current_user = get_current_user(request)
                if not current_user:
                    self.logger.error("æœªæ‰¾åˆ°ç”¨æˆ·ä¿¡æ¯")
                    return jsonify({"success": False, "message": "æœªæ‰¾åˆ°ç”¨æˆ·ä¿¡æ¯"}), 401
                    
                user_id = current_user.get('user_id')
                username = current_user.get('username')
                self.logger.info(f"ç”¨æˆ·ID: {user_id}, ç”¨æˆ·å: {username}")
            except Exception as user_error:
                self.logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å‡ºé”™: {str(user_error)}")
                return jsonify({"success": False, "message": f"è·å–ç”¨æˆ·ä¿¡æ¯å‡ºé”™: {str(user_error)}"}), 500
            
            # ç”Ÿæˆå”¯ä¸€çš„éƒ¨ç½²ID
            deploy_id = f"AIDP{uuid.uuid4().hex[:19]}".upper()
            self.logger.info(f"ç”Ÿæˆéƒ¨ç½²ID: {deploy_id}")
            
            # åˆ›å»ºéƒ¨ç½²ç›®å½•
            try:
                deploy_dir = os.path.join(self.deployments_dir, deploy_id)
                self.logger.info(f"åˆ›å»ºéƒ¨ç½²ç›®å½•: {deploy_dir}")
                os.makedirs(deploy_dir, exist_ok=True)
                
                # åˆ›å»ºä¸´æ—¶ä»£ç ç‰‡æ®µå­˜å‚¨ç›®å½•
                parts_dir = os.path.join(deploy_dir, 'parts')
                os.makedirs(parts_dir, exist_ok=True)
                
                # ä¿å­˜ç¬¬ä¸€ä¸ªä»£ç ç‰‡æ®µ
                part_file_path = os.path.join(parts_dir, f"part_{part_index:03d}.tf")
                with open(part_file_path, 'w') as f:
                    f.write(terraform_code_part)
            except Exception as dir_error:
                self.logger.error(f"åˆ›å»ºéƒ¨ç½²ç›®å½•æ—¶å‡ºé”™: {str(dir_error)}")
                return jsonify({"success": False, "message": f"åˆ›å»ºéƒ¨ç½²ç›®å½•æ—¶å‡ºé”™: {str(dir_error)}"}), 500
            
            # åˆ›å»ºéƒ¨ç½²è®°å½•ï¼Œä½†æ ‡è®°ä¸ºdraftçŠ¶æ€
            try:
                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                deployment_data = {
                    'id': deploy_id,
                    'user_id': user_id,
                    'username': username,
                    'name': deploy_name or description[:50],
                    'description': description,
                    'project': project_name,
                    'cloud': cloud_name,
                    'status': 'draft',  # ä½¿ç”¨draftçŠ¶æ€è¡¨ç¤ºæ­£åœ¨ä¸Šä¼ ä¸­
                    'created_at': current_time,
                    'updated_at': current_time,
                    'terraform_code': terraform_code_part  # æš‚æ—¶åªä¿å­˜ç¬¬ä¸€éƒ¨åˆ†
                }
                
                # ä¿å­˜éƒ¨ç½²è®°å½•åˆ°æ•°æ®åº“
                self.logger.info(f"ä¿å­˜éƒ¨ç½²è‰ç¨¿è®°å½•åˆ°æ•°æ®åº“: deploy_id={deploy_id}, project='{project_name}', cloud='{cloud_name}'")
                success = self.deployment_model.create_deployment(deployment_data)
                if not success:
                    self.logger.error("ä¿å­˜éƒ¨ç½²è®°å½•å¤±è´¥")
                    return jsonify({"success": False, "message": "ä¿å­˜éƒ¨ç½²è®°å½•å¤±è´¥"}), 500
                    
                # åˆ›å»ºéƒ¨ç½²ä¿¡æ¯æ–‡ä»¶ï¼Œè®°å½•æ€»åˆ†ç‰‡æ•°å’Œå½“å‰è¿›åº¦
                info_file_path = os.path.join(deploy_dir, 'deploy_info.json')
                info_data = {
                    'deploy_id': deploy_id,
                    'total_parts': total_parts,
                    'received_parts': 1,
                    'api_key_id': api_key_id,
                    'status': 'uploading'
                }
                with open(info_file_path, 'w') as f:
                    json.dump(info_data, f)
                
                return jsonify({
                    "success": True,
                    "message": "éƒ¨ç½²åˆå§‹åŒ–æˆåŠŸ",
                    "deploy_id": deploy_id
                })
            except Exception as db_error:
                self.logger.error(f"ä¿å­˜éƒ¨ç½²è®°å½•åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {str(db_error)}")
                return jsonify({"success": False, "message": f"ä¿å­˜éƒ¨ç½²è®°å½•åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {str(db_error)}"}), 500
            
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–Terraforméƒ¨ç½²æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "åˆå§‹åŒ–éƒ¨ç½²æ—¶å‡ºé”™",
                "message": str(e)
            }), 500
    
    def deploy_terraform_part(self):
        """æ¥æ”¶Terraforméƒ¨ç½²ä»£ç ç‰‡æ®µ"""
        try:
            # è·å–è¯·æ±‚æ•°æ®
            self.logger.info("å¼€å§‹å¤„ç†Terraformä»£ç ç‰‡æ®µä¸Šä¼ è¯·æ±‚")
            data = request.get_json()
            if not data:
                self.logger.error("è¯·æ±‚æ•°æ®ä¸ºç©º")
                return jsonify({"success": False, "message": "è¯·æ±‚æ•°æ®ä¸ºç©º"}), 400
            
            # è·å–å¿…è¦å‚æ•°
            deploy_id = data.get('deploy_id')
            if not deploy_id:
                self.logger.error("æœªæä¾›éƒ¨ç½²ID")
                return jsonify({"success": False, "message": "æœªæä¾›éƒ¨ç½²ID"}), 400
                
            terraform_code_part = data.get('terraform_code_part', '')
            if not terraform_code_part:
                self.logger.error("Terraformä»£ç ç‰‡æ®µä¸ºç©º")
                return jsonify({"success": False, "message": "Terraformä»£ç ç‰‡æ®µä¸ºç©º"}), 400
                
            part_index = data.get('part_index', 0)
            
            # éªŒè¯éƒ¨ç½²å­˜åœ¨
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            if not os.path.exists(deploy_dir):
                self.logger.error(f"éƒ¨ç½²ç›®å½•ä¸å­˜åœ¨: {deploy_dir}")
                return jsonify({"success": False, "message": f"éƒ¨ç½²ä¸å­˜åœ¨: {deploy_id}"}), 404
                
            # æ£€æŸ¥éƒ¨ç½²ä¿¡æ¯æ–‡ä»¶
            info_file_path = os.path.join(deploy_dir, 'deploy_info.json')
            if not os.path.exists(info_file_path):
                self.logger.error(f"éƒ¨ç½²ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {info_file_path}")
                return jsonify({"success": False, "message": f"éƒ¨ç½²ä¿¡æ¯ä¸å­˜åœ¨: {deploy_id}"}), 404
                
            # è¯»å–éƒ¨ç½²ä¿¡æ¯
            with open(info_file_path, 'r') as f:
                info_data = json.load(f)
                
            # éªŒè¯éƒ¨ç½²çŠ¶æ€
            if info_data.get('status') != 'uploading':
                self.logger.error(f"éƒ¨ç½²çŠ¶æ€ä¸æ­£ç¡®: {info_data.get('status')}")
                return jsonify({"success": False, "message": f"éƒ¨ç½²çŠ¶æ€ä¸æ­£ç¡®: {info_data.get('status')}"}), 400
                
            # ä¿å­˜ä»£ç ç‰‡æ®µ
            parts_dir = os.path.join(deploy_dir, 'parts')
            part_file_path = os.path.join(parts_dir, f"part_{part_index:03d}.tf")
            with open(part_file_path, 'w') as f:
                f.write(terraform_code_part)
                
            # æ›´æ–°éƒ¨ç½²ä¿¡æ¯
            info_data['received_parts'] += 1
            with open(info_file_path, 'w') as f:
                json.dump(info_data, f)
                
            self.logger.info(f"æˆåŠŸæ¥æ”¶ä»£ç ç‰‡æ®µ: {deploy_id}, ç‰‡æ®µç´¢å¼•: {part_index}, å·²æ¥æ”¶: {info_data['received_parts']}/{info_data['total_parts']}")
                
            return jsonify({
                "success": True,
                "message": f"æˆåŠŸæ¥æ”¶ä»£ç ç‰‡æ®µ: {part_index}",
                "deploy_id": deploy_id,
                "received_parts": info_data['received_parts'],
                "total_parts": info_data['total_parts']
            })
            
        except Exception as e:
            self.logger.error(f"æ¥æ”¶Terraformä»£ç ç‰‡æ®µæ—¶å‡ºé”™: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "æ¥æ”¶ä»£ç ç‰‡æ®µæ—¶å‡ºé”™",
                "message": str(e)
            }), 500
    
    def deploy_terraform_complete(self):
        """å®ŒæˆTerraforméƒ¨ç½²ä»£ç ä¸Šä¼ å¹¶å¼€å§‹éƒ¨ç½²"""
        try:
            # è·å–è¯·æ±‚æ•°æ®
            self.logger.info("å¼€å§‹å¤„ç†Terraforméƒ¨ç½²å®Œæˆè¯·æ±‚")
            data = request.get_json()
            if not data:
                self.logger.error("è¯·æ±‚æ•°æ®ä¸ºç©º")
                return jsonify({"success": False, "message": "è¯·æ±‚æ•°æ®ä¸ºç©º"}), 400
            
            # è·å–éƒ¨ç½²ID
            deploy_id = data.get('deploy_id')
            if not deploy_id:
                self.logger.error("æœªæä¾›éƒ¨ç½²ID")
                return jsonify({"success": False, "message": "æœªæä¾›éƒ¨ç½²ID"}), 400
                
            # éªŒè¯éƒ¨ç½²å­˜åœ¨
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            if not os.path.exists(deploy_dir):
                self.logger.error(f"éƒ¨ç½²ç›®å½•ä¸å­˜åœ¨: {deploy_dir}")
                return jsonify({"success": False, "message": f"éƒ¨ç½²ä¸å­˜åœ¨: {deploy_id}"}), 404
                
            # æ£€æŸ¥éƒ¨ç½²ä¿¡æ¯æ–‡ä»¶
            info_file_path = os.path.join(deploy_dir, 'deploy_info.json')
            if not os.path.exists(info_file_path):
                self.logger.error(f"éƒ¨ç½²ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {info_file_path}")
                return jsonify({"success": False, "message": f"éƒ¨ç½²ä¿¡æ¯ä¸å­˜åœ¨: {deploy_id}"}), 404
                
            # è¯»å–éƒ¨ç½²ä¿¡æ¯
            with open(info_file_path, 'r') as f:
                info_data = json.load(f)
                
            # éªŒè¯éƒ¨ç½²çŠ¶æ€
            if info_data.get('status') != 'uploading':
                self.logger.error(f"éƒ¨ç½²çŠ¶æ€ä¸æ­£ç¡®: {info_data.get('status')}")
                return jsonify({"success": False, "message": f"éƒ¨ç½²çŠ¶æ€ä¸æ­£ç¡®: {info_data.get('status')}"}), 400
                
            # éªŒè¯æ‰€æœ‰ç‰‡æ®µæ˜¯å¦éƒ½å·²æ¥æ”¶
            if info_data.get('received_parts', 0) < info_data.get('total_parts', 0):
                self.logger.error(f"å°šæœªæ¥æ”¶æ‰€æœ‰ä»£ç ç‰‡æ®µ: {info_data.get('received_parts')}/{info_data.get('total_parts')}")
                return jsonify({
                    "success": False, 
                    "message": f"å°šæœªæ¥æ”¶æ‰€æœ‰ä»£ç ç‰‡æ®µ: {info_data.get('received_parts')}/{info_data.get('total_parts')}"
                }), 400
                
            # åˆå¹¶æ‰€æœ‰ä»£ç ç‰‡æ®µ
            parts_dir = os.path.join(deploy_dir, 'parts')
            terraform_code = ""
            for i in range(info_data.get('total_parts', 0)):
                part_file_path = os.path.join(parts_dir, f"part_{i:03d}.tf")
                if not os.path.exists(part_file_path):
                    self.logger.error(f"æ‰¾ä¸åˆ°ä»£ç ç‰‡æ®µæ–‡ä»¶: {part_file_path}")
                    return jsonify({"success": False, "message": f"æ‰¾ä¸åˆ°ä»£ç ç‰‡æ®µ: {i}"}), 404
                    
                with open(part_file_path, 'r') as f:
                    terraform_code += f.read()
            
            # è·å–APIå¯†é’¥ID
            api_key_id = info_data.get('api_key_id')
            if not api_key_id:
                self.logger.error("æœªæ‰¾åˆ°APIå¯†é’¥ID")
                return jsonify({"success": False, "message": "æœªæ‰¾åˆ°APIå¯†é’¥ID"}), 400
                
            # è·å–APIå¯†é’¥è¯¦æƒ…
            try:
                from controllers.apikey_controller import ApiKeyController
                apikey_controller = ApiKeyController(self.config)
                api_key = apikey_controller.get_api_key_by_id(api_key_id)
                
                if not api_key:
                    self.logger.error(f"æ‰¾ä¸åˆ°æŒ‡å®šçš„APIå¯†é’¥: {api_key_id}")
                    return jsonify({"success": False, "message": "æ‰¾ä¸åˆ°æŒ‡å®šçš„APIå¯†é’¥"}), 404
                    
                # è·å–AKå’ŒSK
                ak = api_key.get('ak', '')
                sk = api_key.get('sk', '')
                
                if not ak or not sk:
                    self.logger.error("APIå¯†é’¥ç¼ºå°‘AKæˆ–SK")
                    return jsonify({"success": False, "message": "APIå¯†é’¥ç¼ºå°‘AKæˆ–SK"}), 400
                    
                self.logger.info(f"æˆåŠŸè·å–APIå¯†é’¥ {api_key.get('apikey_name')}")
            except Exception as apikey_error:
                self.logger.error(f"è·å–APIå¯†é’¥æ—¶å‡ºé”™: {str(apikey_error)}")
                return jsonify({"success": False, "message": f"è·å–APIå¯†é’¥æ—¶å‡ºé”™: {str(apikey_error)}"}), 500
            
            # ä¿®æ”¹Terraformä»£ç ï¼Œæ™ºèƒ½æ·»åŠ äº‘å¹³å°å‡­è¯
            try:
                # æ ¹æ®ä»£ç ä¸­çš„äº‘å¹³å°ç±»å‹æ™ºèƒ½æ·»åŠ å‡­è¯
                terraform_code = self._add_cloud_credentials_to_code(terraform_code, ak, sk)
            except Exception as code_error:
                self.logger.error(f"æ·»åŠ äº‘å¹³å°å‡­è¯åˆ°Terraformä»£ç æ—¶å‡ºé”™: {str(code_error)}")
                return jsonify({"success": False, "message": f"æ·»åŠ äº‘å¹³å°å‡­è¯åˆ°Terraformä»£ç æ—¶å‡ºé”™: {str(code_error)}"}), 500
            
            # å†™å…¥å®Œæ•´çš„Terraformä»£ç åˆ°main.tfæ–‡ä»¶
            tf_file_path = os.path.join(deploy_dir, 'main.tf')
            with open(tf_file_path, 'w') as f:
                f.write(terraform_code)
                
            # æ›´æ–°éƒ¨ç½²ä¿¡æ¯
            info_data['status'] = 'ready'
            with open(info_file_path, 'w') as f:
                json.dump(info_data, f)
                
            # æ›´æ–°éƒ¨ç½²è®°å½•
            try:
                self.deployment_model.update_deployment_status(
                    deploy_id, 
                    'pending',
                    error_message=None,
                    deployment_summary=None
                )
                
                # æ›´æ–°Terraformä»£ç 
                self.logger.info(f"æ›´æ–°éƒ¨ç½²è®°å½•çš„Terraformä»£ç : {deploy_id}")
                deployment = self.deployment_model.get_deployment(deploy_id)
                if deployment:
                    conn = get_db()
                    cursor = conn.cursor()
                    cursor.execute(
                        f"UPDATE aideployments SET terraform_code = %s WHERE id = %s",
                        (terraform_code, deploy_id)
                    )
                    conn.commit()
                    cursor.close()
                    conn.close()
            except Exception as update_error:
                self.logger.error(f"æ›´æ–°éƒ¨ç½²è®°å½•æ—¶å‡ºé”™: {str(update_error)}")
                return jsonify({"success": False, "message": f"æ›´æ–°éƒ¨ç½²è®°å½•æ—¶å‡ºé”™: {str(update_error)}"}), 500
            
            # å¯åŠ¨å¼‚æ­¥éƒ¨ç½²ä»»åŠ¡
            try:
                # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
                current_user = get_current_user(request)
                user_id = current_user.get('user_id') if current_user else None
                
                # å¯åŠ¨åå°éƒ¨ç½²ä»»åŠ¡
                self.logger.info(f"å¯åŠ¨åå°éƒ¨ç½²ä»»åŠ¡: {deploy_id}")
                import threading
                deploy_thread = threading.Thread(
                    target=self._run_terraform_deployment,
                    args=(deploy_id, deploy_dir, user_id)
                )
                deploy_thread.daemon = True
                deploy_thread.start()
                
                return jsonify({
                    "success": True,
                    "message": "éƒ¨ç½²ä»»åŠ¡å·²å¯åŠ¨",
                    "deploy_id": deploy_id
                })
            except Exception as thread_error:
                self.logger.error(f"å¯åŠ¨åå°éƒ¨ç½²ä»»åŠ¡æ—¶å‡ºé”™: {str(thread_error)}")
                return jsonify({"success": False, "message": f"å¯åŠ¨åå°éƒ¨ç½²ä»»åŠ¡æ—¶å‡ºé”™: {str(thread_error)}"}), 500
            
        except Exception as e:
            self.logger.error(f"å®ŒæˆTerraforméƒ¨ç½²æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "å®Œæˆéƒ¨ç½²æ—¶å‡ºé”™",
                "message": str(e)
            }), 500
    
    def list_deployments(self):
        """åˆ—å‡ºç”¨æˆ·çš„AIéƒ¨ç½²"""
        try:
            # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
            current_user = get_current_user(request)
            if not current_user:
                return jsonify({"success": False, "message": "æœªæ‰¾åˆ°ç”¨æˆ·ä¿¡æ¯"}), 401
                
            user_id = current_user.get('user_id')
            
            # è·å–åˆ†é¡µå‚æ•°
            page = request.args.get('page', 1, type=int)
            page_size = request.args.get('page_size', 10, type=int)
            
            # è·å–éƒ¨ç½²åˆ—è¡¨
            deployments, total = self.deployment_model.list_deployments(
                user_id=user_id,
                page=page,
                page_size=page_size
            )
            
            return jsonify({
                "success": True,
                "deployments": deployments,
                "total": total,
                "page": page,
                "page_size": page_size
            })
            
        except Exception as e:
            self.logger.error(f"è·å–éƒ¨ç½²åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
            return jsonify({
                "success": False,
                "error": "è·å–éƒ¨ç½²åˆ—è¡¨æ—¶å‡ºé”™",
                "message": str(e)
            }), 500 
    
    def get_ai_deployment_details(self, deploy_id=None):
        """è·å–AIéƒ¨ç½²çš„è¯¦æƒ…ï¼ŒåŒ…æ‹¬æ‹“æ‰‘å›¾ä¿¡æ¯"""
        try:
            # å¦‚æœæœªæä¾›deploy_idï¼Œåˆ™ä»è¯·æ±‚å‚æ•°ä¸­è·å–
            if not deploy_id:
                deploy_id = request.args.get('deploy_id')
            
            if not deploy_id:
                return jsonify({"success": False, "message": "æœªæä¾›éƒ¨ç½²ID"}), 400
            
            # è·å–éƒ¨ç½²è¯¦æƒ…
            deployment = self.deployment_model.get_deployment(deploy_id)
            if not deployment:
                return jsonify({"success": False, "message": "æœªæ‰¾åˆ°éƒ¨ç½²ä¿¡æ¯"}), 404
            
            # è·å–æ‹“æ‰‘å›¾è·¯å¾„ï¼ˆåªç”¨äºæ£€æŸ¥æ˜¯å¦å­˜åœ¨ï¼‰
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            topology_image_path = os.path.join(deploy_dir, 'graph.png')
            topology_exists = os.path.exists(topology_image_path)
            
            # å¦‚æœæ‹“æ‰‘å›¾ä¸å­˜åœ¨ä¸”éƒ¨ç½²å·²å®Œæˆï¼Œå°è¯•ç”Ÿæˆæ‹“æ‰‘å›¾
            if not topology_exists and deployment.get('status') == 'completed':
                try:
                    # ç¡®ä¿åœ¨éƒ¨ç½²ç›®å½•ä¸­æ‰§è¡Œå‘½ä»¤
                    if os.path.exists(deploy_dir):
                        # å°è¯•ç”Ÿæˆæ‹“æ‰‘å›¾
                        result = subprocess.run(
                            'terraform graph -type=plan | dot -Tpng > graph.png',
                            shell=True,
                            cwd=deploy_dir,
                            stderr=subprocess.PIPE,
                            stdout=subprocess.PIPE,
                            text=True
                        )
                        
                        if result.returncode == 0:
                            topology_exists = os.path.exists(topology_image_path)
                            self.logger.info(f"å·²ä¸ºéƒ¨ç½² {deploy_id} ç”Ÿæˆæ‹“æ‰‘å›¾")
                        else:
                            self.logger.warning(f"æ— æ³•ç”Ÿæˆæ‹“æ‰‘å›¾: {result.stderr}")
                except Exception as gen_error:
                    self.logger.error(f"ç”Ÿæˆæ‹“æ‰‘å›¾æ—¶å‡ºé”™: {str(gen_error)}")
            
            # æ„å»ºèµ„æºæ–‡ä»¶åˆ—è¡¨ - è¿™é‡Œä»éœ€è¦æ„å»ºç”¨äºè¿”å›APIï¼Œä½†ä¸ä¼šåœ¨HTMLä¸­æ˜¾ç¤º
            files = []
            if os.path.exists(deploy_dir):
                # ä»…åˆ—å‡ºé‡è¦çš„æ–‡ä»¶ç±»å‹
                for file in os.listdir(deploy_dir):
                    if file.endswith(".tf") or file.endswith(".log") or file == "graph.png":
                        file_path = os.path.join(deploy_dir, file)
                        if os.path.isfile(file_path):
                            file_size = os.path.getsize(file_path)
                            files.append({
                                "name": file,
                                "path": f"/api/terraform/file?deploy_id={deploy_id}&file={file}",
                                "size": file_size,
                                "type": file.split('.')[-1]
                            })
            
            # ç”Ÿæˆéƒ¨ç½²æ‘˜è¦HTMLè¡¨æ ¼
            table_html = "<div class='deployment-summary card shadow-sm'>\n"
            table_html += f"<div class='card-header bg-primary text-white'><h3 class='mb-0'><i class='fas fa-brain mr-2'></i>AIéƒ¨ç½²è¯¦æƒ…: {deploy_id}</h3></div>\n"
            
            # åŸºæœ¬ä¿¡æ¯
            table_html += "<div class='card-body'>\n"
            table_html += "<table class='table table-striped table-bordered table-hover'>\n"
            table_html += "<tbody>\n"
            table_html += "<tr><th colspan='2' class='bg-light'>åŸºæœ¬ä¿¡æ¯</th></tr>\n"
            table_html += f"<tr><th width='30%'>éƒ¨ç½²ID</th><td><code>{deployment.get('id', '')}</code></td></tr>\n"
            table_html += f"<tr><th>åç§°</th><td><strong>{deployment.get('name', '')}</strong></td></tr>\n"
            table_html += f"<tr><th>åˆ›å»ºæ—¶é—´</th><td>{deployment.get('created_at', '')}</td></tr>\n"
            table_html += f"<tr><th>æ›´æ–°æ—¶é—´</th><td>{deployment.get('updated_at', '')}</td></tr>\n"
            
            # æ˜¾ç¤ºçŠ¶æ€å¹¶æ ¹æ®çŠ¶æ€æ·»åŠ ä¸åŒçš„æ ·å¼
            status = deployment.get('status', '')
            status_badge = self._get_status_badge(status)
            table_html += f"<tr><th>çŠ¶æ€</th><td>{status_badge}</td></tr>\n"
            
            # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯
            if deployment.get('error_message'):
                table_html += f"<tr><th>é”™è¯¯ä¿¡æ¯</th><td class='text-danger'><i class='fas fa-exclamation-circle mr-1'></i>{deployment.get('error_message', '')}</td></tr>\n"
            
            table_html += "</tbody>\n"
            table_html += "</table>\n"
            
            # å¦‚æœæœ‰éƒ¨ç½²æ‘˜è¦
            if deployment.get('deployment_summary'):
                table_html += "<h4 class='mt-4 mb-2'><i class='fas fa-list-alt mr-2'></i>éƒ¨ç½²æ‘˜è¦</h4>\n"
                
                summary = deployment.get('deployment_summary')
                if isinstance(summary, dict):
                    # ä½¿ç”¨å¯æŠ˜å é¢æ¿æ˜¾ç¤ºå¤æ‚çš„JSONè¾“å‡º
                    formatted_summary = self._format_json_output(summary)
                    table_html += formatted_summary
                else:
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
                    try:
                        summary_dict = json.loads(summary)
                        formatted_summary = self._format_json_output(summary_dict)
                        table_html += formatted_summary
                    except:
                        # å¦‚æœè§£æå¤±è´¥ï¼Œä½œä¸ºæ™®é€šæ–‡æœ¬æ˜¾ç¤º
                        table_html += "<div class='alert alert-info'>\n"
                        table_html += f"<p>{summary}</p>\n"
                        table_html += "</div>\n"
            
            # ç§»é™¤æ–‡ä»¶åˆ—è¡¨å’Œæ‹“æ‰‘å›¾æ˜¾ç¤ºéƒ¨åˆ†
            
            table_html += "</div>\n"
            table_html += "</div>"
            
            return jsonify({
                "success": True,
                "deployment": deployment,
                "topology_exists": topology_exists,
                "topology_url": f"/api/terraform/topology?deploy_id={deploy_id}" if topology_exists else None,
                "files": files,
                "table": table_html
            })
            
        except Exception as e:
            self.logger.error(f"è·å–AIéƒ¨ç½²è¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "è·å–éƒ¨ç½²è¯¦æƒ…æ—¶å‡ºé”™",
                "message": str(e)
            }), 500
    
    def get_ai_deployment_file(self):
        """è·å–AIéƒ¨ç½²ç›¸å…³çš„æ–‡ä»¶å†…å®¹"""
        try:
            # ä»è¯·æ±‚å‚æ•°ä¸­è·å–éƒ¨ç½²IDå’Œæ–‡ä»¶å
            deploy_id = request.args.get('deploy_id')
            file_name = request.args.get('file')
            
            if not deploy_id or not file_name:
                return jsonify({"success": False, "message": "æœªæä¾›éƒ¨ç½²IDæˆ–æ–‡ä»¶å"}), 400
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            file_path = os.path.join(deploy_dir, file_name)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path) or not os.path.isfile(file_path):
                return jsonify({"success": False, "message": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404
            
            # ç¡®å®šMIMEç±»å‹
            mime_type = self._get_mime_type(file_path)
            
            # ç›´æ¥è¿”å›æ–‡ä»¶ï¼Œä¸ç®¡æ˜¯ä»€ä¹ˆç±»å‹
            return send_file(
                file_path,
                mimetype=mime_type,
                as_attachment=True,
                download_name=file_name
            )
                
        except Exception as e:
            self.logger.error(f"è·å–AIéƒ¨ç½²æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return jsonify({
                "success": False,
                "error": "è·å–æ–‡ä»¶å†…å®¹æ—¶å‡ºé”™",
                "message": str(e)
            }), 500
    
    def get_ai_deployment_topology(self):
        """è·å–AIéƒ¨ç½²çš„æ‹“æ‰‘å›¾"""
        try:
            # ä»è¯·æ±‚å‚æ•°ä¸­è·å–éƒ¨ç½²ID
            deploy_id = request.args.get('deploy_id')
            
            if not deploy_id:
                return jsonify({"success": False, "message": "æœªæä¾›éƒ¨ç½²ID"}), 400
            
            # æ„å»ºæ‹“æ‰‘å›¾æ–‡ä»¶è·¯å¾„
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            topology_path = os.path.join(deploy_dir, 'graph.png')
            
            # æ£€æŸ¥æ‹“æ‰‘å›¾æ˜¯å¦å­˜åœ¨
            if not os.path.exists(topology_path):
                # å°è¯•ç”Ÿæˆæ‹“æ‰‘å›¾
                try:
                    # ç¡®ä¿åœ¨éƒ¨ç½²ç›®å½•ä¸­æ‰§è¡Œå‘½ä»¤
                    if os.path.exists(deploy_dir):
                        # å°è¯•ç”Ÿæˆæ‹“æ‰‘å›¾
                        result = subprocess.run(
                            'terraform graph -type=plan | dot -Tpng > graph.png',
                            shell=True,
                            cwd=deploy_dir,
                            stderr=subprocess.PIPE,
                            stdout=subprocess.PIPE,
                            text=True
                        )
                        
                        if result.returncode == 0 and os.path.exists(topology_path):
                            self.logger.info(f"å·²ä¸ºéƒ¨ç½² {deploy_id} ç”Ÿæˆæ‹“æ‰‘å›¾")
                        else:
                            return jsonify({"success": False, "message": f"æ— æ³•ç”Ÿæˆæ‹“æ‰‘å›¾: {result.stderr}"}), 404
                except Exception as gen_error:
                    return jsonify({"success": False, "message": f"ç”Ÿæˆæ‹“æ‰‘å›¾æ—¶å‡ºé”™: {str(gen_error)}"}), 500
            
            # è¿”å›æ‹“æ‰‘å›¾æ–‡ä»¶
            return send_file(
                topology_path,
                mimetype='image/png',
                as_attachment=False,
                download_name=f"topology_{deploy_id}.png"
            )
                
        except Exception as e:
            self.logger.error(f"è·å–AIéƒ¨ç½²æ‹“æ‰‘å›¾æ—¶å‡ºé”™: {str(e)}")
            return jsonify({
                "success": False,
                "error": "è·å–æ‹“æ‰‘å›¾æ—¶å‡ºé”™",
                "message": str(e)
            }), 500
    
    def _get_status_badge(self, status: str) -> str:
        """ç”ŸæˆçŠ¶æ€çš„Bootstrapå¾½ç« HTML"""
        status_lower = status.lower()
        
        if status_lower == 'completed' or status_lower == 'success':
            return '<span class="badge badge-success"><i class="fas fa-check mr-1"></i>å·²å®Œæˆ</span>'
        elif status_lower == 'failed' or status_lower == 'error':
            return '<span class="badge badge-danger"><i class="fas fa-times mr-1"></i>å¤±è´¥</span>'
        elif status_lower == 'in_progress' or status_lower == 'running':
            return '<span class="badge badge-warning"><i class="fas fa-spinner fa-spin mr-1"></i>è¿›è¡Œä¸­</span>'
        elif status_lower == 'pending':
            return '<span class="badge badge-info"><i class="fas fa-hourglass-half mr-1"></i>å‡†å¤‡ä¸­</span>'
        else:
            return f'<span class="badge badge-secondary">{status}</span>'
            
    def _format_json_output(self, json_data):
        """å°†JSONæ•°æ®æ ¼å¼åŒ–ä¸ºè¡¨æ ¼å½¢å¼è€Œä¸æ˜¯ä»£ç å—"""
        html = ""
        
        # å¦‚æœæ˜¯å­—å…¸ç±»å‹çš„è¾“å‡º
        if isinstance(json_data, dict):
            # æ£€æŸ¥æ˜¯å¦æœ‰outputså­—æ®µï¼Œè¿™éœ€è¦ç‰¹æ®Šå¤„ç†
            if 'outputs' in json_data and isinstance(json_data['outputs'], dict):
                html += "<div class='card mb-3'>\n"
                html += "<div class='card-header bg-light font-weight-bold'>èµ„æºè¾“å‡ºå˜é‡</div>\n"
                html += "<div class='card-body p-0'>\n"
                html += "<table class='table table-sm table-striped mb-0'>\n"
                html += "<thead class='thead-light'>\n"
                html += "<tr><th>è¾“å‡ºåç§°</th><th>å€¼</th></tr>\n"
                html += "</thead>\n"
                html += "<tbody>\n"
                
                for key, value in json_data['outputs'].items():
                    output_value = value.get('value', '') if isinstance(value, dict) else value
                    # å¦‚æœè¾“å‡ºå€¼æ˜¯å¤æ‚å¯¹è±¡ï¼Œè½¬æ¢ä¸ºè¡¨æ ¼è€ŒéJSONä»£ç 
                    if isinstance(output_value, dict):
                        output_formatted = self._format_dict_as_table(output_value)
                    elif isinstance(output_value, list):
                        output_formatted = self._format_list_as_table(output_value)
                    else:
                        output_formatted = f"<code>{output_value}</code>"
                    
                    html += f"<tr><td><strong>{key}</strong></td><td>{output_formatted}</td></tr>\n"
                
                html += "</tbody>\n"
                html += "</table>\n"
                html += "</div>\n"
                html += "</div>\n"
                
                # ä»å­—å…¸ä¸­ç§»é™¤å·²å¤„ç†çš„outputs
                json_data = {k: v for k, v in json_data.items() if k != 'outputs'}
            
            # å¤„ç†å…¶ä»–å­—æ®µï¼Œæ’é™¤è¿‡é•¿çš„apply_output
            other_fields = {k: v for k, v in json_data.items() if k not in ['apply_output']}
            
            if other_fields:
                # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤ºå…¶ä»–ç®€å•å­—æ®µ
                for key, value in other_fields.items():
                    # æ’é™¤ç©ºå€¼å’Œå¤æ‚å¯¹è±¡
                    if value is None:
                        continue
                        
                    html += f"<div class='card mb-3'>\n"
                    html += f"<div class='card-header bg-light font-weight-bold'>{key}</div>\n"
                    html += f"<div class='card-body p-0'>\n"
                    
                    if isinstance(value, dict):
                        html += self._format_dict_as_table(value)
                    elif isinstance(value, list):
                        html += self._format_list_as_table(value)
                    else:
                        html += f"<div class='p-3'>{value}</div>\n"
                    
                    html += f"</div>\n"
                    html += f"</div>\n"
        
        # å¦‚æœæ˜¯åˆ—è¡¨ç±»å‹çš„è¾“å‡º
        elif isinstance(json_data, list):
            html += "<div class='card mb-3'>\n"
            html += "<div class='card-header bg-light font-weight-bold'>æ•°æ®åˆ—è¡¨</div>\n"
            html += "<div class='card-body p-0'>\n"
            html += self._format_list_as_table(json_data)
            html += "</div>\n"
            html += "</div>\n"
        
        # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼ˆå­—ç¬¦ä¸²ã€æ•°å­—ç­‰ï¼‰
        else:
            html += "<div class='card mb-3'>\n"
            html += "<div class='card-header bg-light font-weight-bold'>å€¼</div>\n"
            html += "<div class='card-body'>\n"
            html += f"<div>{json_data}</div>\n"
            html += "</div>\n"
            html += "</div>\n"
        
        return html
    
    def _format_dict_as_table(self, data):
        """å°†å­—å…¸æ ¼å¼åŒ–ä¸ºHTMLè¡¨æ ¼"""
        html = "<table class='table table-sm table-striped mb-0'>\n"
        html += "<tbody>\n"
        
        for key, value in data.items():
            if isinstance(value, dict):
                # ç®€åŒ–åµŒå¥—å­—å…¸æ˜¾ç¤º
                nested_table = "<table class='table table-sm table-bordered mb-0'>\n<tbody>\n"
                for k, v in value.items():
                    if isinstance(v, (dict, list)):
                        v_text = "å¤æ‚å¯¹è±¡" 
                    else:
                        v_text = str(v)
                    nested_table += f"<tr><td><small>{k}</small></td><td><small>{v_text}</small></td></tr>\n"
                nested_table += "</tbody>\n</table>"
                html += f"<tr><td width='30%'><strong>{key}</strong></td><td>{nested_table}</td></tr>\n"
            elif isinstance(value, list):
                if len(value) > 0 and isinstance(value[0], dict):
                    # ç®€åŒ–åˆ—è¡¨æ˜¾ç¤º
                    html += f"<tr><td width='30%'><strong>{key}</strong></td><td>åˆ—è¡¨åŒ…å« {len(value)} é¡¹</td></tr>\n"
                else:
                    # ç®€å•åˆ—è¡¨å€¼æ˜¾ç¤º
                    list_text = ", ".join([str(item) for item in value[:5]])
                    if len(value) > 5:
                        list_text += "..."
                    html += f"<tr><td width='30%'><strong>{key}</strong></td><td>{list_text}</td></tr>\n"
            else:
                # ç®€å•å€¼ç›´æ¥æ˜¾ç¤º
                html += f"<tr><td width='30%'><strong>{key}</strong></td><td>{value}</td></tr>\n"
                
        html += "</tbody>\n"
        html += "</table>\n"
        return html
    
    def _format_list_as_table(self, data):
        """å°†åˆ—è¡¨æ ¼å¼åŒ–ä¸ºHTMLè¡¨æ ¼"""
        if not data:
            return "<div class='p-3'>ç©ºåˆ—è¡¨</div>"
            
        # æ£€æŸ¥åˆ—è¡¨é¡¹æ˜¯å¦ä¸ºå­—å…¸
        if all(isinstance(item, dict) for item in data):
            # ä½¿ç”¨å­—å…¸çš„é”®ä½œä¸ºåˆ—å¤´
            all_keys = set()
            for item in data:
                all_keys.update(item.keys())
            all_keys = sorted(list(all_keys))
            
            html = "<table class='table table-sm table-striped mb-0'>\n"
            html += "<thead class='thead-light'>\n<tr>\n"
            
            for key in all_keys:
                html += f"<th>{key}</th>\n"
            
            html += "</tr>\n</thead>\n<tbody>\n"
            
            for item in data:
                html += "<tr>\n"
                for key in all_keys:
                    value = item.get(key, "")
                    if isinstance(value, (dict, list)):
                        html += "<td>å¤æ‚å¯¹è±¡</td>\n"
                    else:
                        html += f"<td>{value}</td>\n"
                html += "</tr>\n"
                
            html += "</tbody>\n</table>\n"
        else:
            # ç®€å•åˆ—è¡¨ä½¿ç”¨åºå·æ˜¾ç¤º
            html = "<table class='table table-sm table-striped mb-0'>\n"
            html += "<thead class='thead-light'>\n<tr>\n"
            html += "<th>#</th><th>å€¼</th>\n"
            html += "</tr>\n</thead>\n<tbody>\n"
            
            for i, item in enumerate(data):
                html += f"<tr><td>{i+1}</td><td>"
                if isinstance(item, dict):
                    html += "å­—å…¸å¯¹è±¡"
                elif isinstance(item, list):
                    html += f"åˆ—è¡¨ ({len(item)} é¡¹)"
                else:
                    html += f"{item}"
                html += "</td></tr>\n"
                
            html += "</tbody>\n</table>\n"
            
        return html
    
    def _get_mime_type(self, file_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šMIMEç±»å‹
        
        Args:
            file_path (str): æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: MIMEç±»å‹
        """
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šMIMEç±»å‹
        extension = os.path.splitext(file_path)[1].lower()
        
        mime_types = {
            '.txt': 'text/plain',
            '.log': 'text/plain',
            '.tf': 'text/plain',
            '.json': 'application/json',
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.gif': 'image/gif',
            '.svg': 'image/svg+xml',
            '.pdf': 'application/pdf',
            '.zip': 'application/zip',
            '.tfstate': 'application/json',
        }
        
        return mime_types.get(extension, 'application/octet-stream')
    
    def _build_fix_prompt(self, original_code, error_lines, is_volcengine=False):
        """æ„å»ºä¿®å¤Terraformä»£ç çš„æç¤º"""
        system_prompt = """
        You are a Terraform expert specializing in fixing infrastructure-as-code errors.
        Your task is to analyze the error message and fix the Terraform code.
        
        CRITICAL REQUIREMENTS:
        1. Only return the complete, corrected Terraform code
        2. Do NOT include any explanations, markdown formatting, or code blocks
        3. Fix the specific errors mentioned in the error message
        4. Preserve all existing resource configurations and credentials
        5. Ensure the code follows Terraform best practices
        6. Keep all comments and structure intact
        
        Common fixes:
        - Fix resource type typos (e.g., aws_vpcaaa -> aws_vpc)
        - Correct argument names and syntax
        - Add missing required arguments
        - Fix provider configuration issues
        """
        
        user_prompt = f"""
        Original Terraform code:
        {original_code}
        
        Error messages:
        {chr(10).join(error_lines)}
        
        Please fix the errors and return the corrected Terraform code.
        """
        
        if is_volcengine:
            system_prompt += """
            
            VOLCENGINE SPECIFIC:
            - Use volcengine provider resources
            - Ensure proper volcengine resource naming
            - Maintain volcengine-specific configurations
            """
        
        return {
            'system': system_prompt,
            'user': user_prompt
        }
    
    def _preserve_credentials(self, original_code, fixed_code, is_volcengine=False, fix_log_path=None):
        """ä¿ç•™åŸå§‹ä»£ç ä¸­çš„å‡­è¯ä¿¡æ¯"""
        try:
            import re
            
            # æå–åŸå§‹ä»£ç ä¸­çš„å‡­è¯
            if is_volcengine:
                # ç«å±±å¼•æ“å‡­è¯
                ak_match = re.search(r'access_key\s*=\s*"([^"]*)"', original_code)
                sk_match = re.search(r'secret_key\s*=\s*"([^"]*)"', original_code)
                region_match = re.search(r'region\s*=\s*"([^"]*)"', original_code)
                
                if ak_match and sk_match:
                    ak = ak_match.group(1)
                    sk = sk_match.group(1)
                    region = region_match.group(1) if region_match else "cn-beijing"
                    
                    # åœ¨ä¿®å¤åçš„ä»£ç ä¸­æ›¿æ¢å‡­è¯
                    fixed_code = re.sub(r'access_key\s*=\s*"[^"]*"', f'access_key = "{ak}"', fixed_code)
                    fixed_code = re.sub(r'secret_key\s*=\s*"[^"]*"', f'secret_key = "{sk}"', fixed_code)
                    fixed_code = re.sub(r'region\s*=\s*"[^"]*"', f'region = "{region}"', fixed_code)
            else:
                # AWSå‡­è¯
                ak_match = re.search(r'access_key\s*=\s*"([^"]*)"', original_code)
                sk_match = re.search(r'secret_key\s*=\s*"([^"]*)"', original_code)
                region_match = re.search(r'region\s*=\s*"([^"]*)"', original_code)
                
                if ak_match and sk_match:
                    ak = ak_match.group(1)
                    sk = sk_match.group(1)
                    region = region_match.group(1) if region_match else "us-east-1"
                    
                    # åœ¨ä¿®å¤åçš„ä»£ç ä¸­æ›¿æ¢å‡­è¯
                    fixed_code = re.sub(r'access_key\s*=\s*"[^"]*"', f'access_key = "{ak}"', fixed_code)
                    fixed_code = re.sub(r'secret_key\s*=\s*"[^"]*"', f'secret_key = "{sk}"', fixed_code)
                    fixed_code = re.sub(r'region\s*=\s*"[^"]*"', f'region = "{region}"', fixed_code)
            
            if fix_log_path:
                with open(fix_log_path, 'a') as log_file:
                    log_file.write("å‡­è¯ä¿¡æ¯å·²ä¿ç•™åœ¨ä¿®å¤åçš„ä»£ç ä¸­\n")
            
            return fixed_code
            
        except Exception as e:
            if fix_log_path:
                with open(fix_log_path, 'a') as log_file:
                    log_file.write(f"ä¿ç•™å‡­è¯æ—¶å‡ºé”™: {str(e)}\n")
            return fixed_code

    def stop_deployment(self, deploy_id):
        """åœæ­¢æŒ‡å®šçš„éƒ¨ç½²ä»»åŠ¡"""
        try:
            self.logger.info(f"æ”¶åˆ°åœæ­¢éƒ¨ç½²è¯·æ±‚: {deploy_id}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„éƒ¨ç½²
            if deploy_id not in self.active_deployments:
                self.logger.warning(f"æ²¡æœ‰æ‰¾åˆ°æ­£åœ¨è¿è¡Œçš„éƒ¨ç½²: {deploy_id}")
                return {
                    'success': False,
                    'message': 'æ²¡æœ‰æ‰¾åˆ°æ­£åœ¨è¿è¡Œçš„éƒ¨ç½²ä»»åŠ¡'
                }
            
            deployment_info = self.active_deployments[deploy_id]
            deploy_dir = deployment_info.get('deploy_dir')
            
            # åˆ›å»ºåœæ­¢ä¿¡å·æ–‡ä»¶
            if deploy_dir and os.path.exists(deploy_dir):
                stop_file = os.path.join(deploy_dir, '.stop_deployment')
                with open(stop_file, 'w') as f:
                    f.write(f"åœæ­¢æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write("åŸå› : ç”¨æˆ·æ‰‹åŠ¨åœæ­¢éƒ¨ç½²\n")
                self.logger.info(f"å·²åˆ›å»ºåœæ­¢ä¿¡å·æ–‡ä»¶: {stop_file}")
            
            # æ¸…ç†æ´»è·ƒéƒ¨ç½²è®°å½•
            if deploy_id in self.active_deployments:
                del self.active_deployments[deploy_id]
            
            self.logger.info(f"éƒ¨ç½²åœæ­¢è¯·æ±‚å·²å‘é€: {deploy_id}")
            return {
                'success': True,
                'message': 'éƒ¨ç½²åœæ­¢ä¿¡å·å·²å‘é€ï¼Œéƒ¨ç½²å°†åœ¨ä¸‹ä¸ªæ£€æŸ¥ç‚¹åœæ­¢'
            }
            
        except Exception as e:
            self.logger.error(f"åœæ­¢éƒ¨ç½²æ—¶å‡ºé”™: {str(e)}")
            return {
                'success': False,
                'message': f'åœæ­¢éƒ¨ç½²æ—¶å‡ºé”™: {str(e)}'
            }

    def _add_cloud_credentials_to_code(self, terraform_code, ak, sk):
        """æ™ºèƒ½æ£€æµ‹äº‘å¹³å°å¹¶æ·»åŠ ç›¸åº”å‡­è¯"""
        # æ£€æµ‹Terraformä»£ç ä¸­çš„äº‘å¹³å°ç±»å‹
        detected_cloud = self._detect_cloud_provider_from_code(terraform_code)
        
        self.logger.info(f"ä»Terraformä»£ç ä¸­æ£€æµ‹åˆ°äº‘å¹³å°: {detected_cloud}")
        
        # æ ¹æ®æ£€æµ‹åˆ°çš„äº‘å¹³å°æ·»åŠ ç›¸åº”å‡­è¯
        if detected_cloud == "volcengine":
            return self._add_volcengine_credentials_to_code(terraform_code, ak, sk)
        elif detected_cloud == "aws":
            return self._add_aws_credentials_to_code(terraform_code, ak, sk)
        elif detected_cloud == "huaweicloud":
            return self._add_huaweicloud_credentials_to_code(terraform_code, ak, sk)
        elif detected_cloud == "alicloud":
            return self._add_alicloud_credentials_to_code(terraform_code, ak, sk)
        elif detected_cloud == "tencentcloud":
            return self._add_tencentcloud_credentials_to_code(terraform_code, ak, sk)
        elif detected_cloud == "baiducloud":
            return self._add_baiducloud_credentials_to_code(terraform_code, ak, sk)
        elif detected_cloud == "azurerm":
            return self._add_azure_credentials_to_code(terraform_code, ak, sk)
        else:
            self.logger.warning(f"æœªè¯†åˆ«çš„äº‘å¹³å°: {detected_cloud}ï¼Œè·³è¿‡å‡­è¯æ·»åŠ ")
            return terraform_code

    def _detect_cloud_provider_from_code(self, terraform_code):
        """ä»Terraformä»£ç ä¸­æ£€æµ‹äº‘å¹³å°ç±»å‹"""
        code_lower = terraform_code.lower()
        
        # å®šä¹‰äº‘å¹³å°æ£€æµ‹è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        cloud_patterns = [
            ("volcengine", ["provider \"volcengine\"", "volcengine_", "volcengine/"]),
            ("huaweicloud", ["provider \"huaweicloud\"", "huaweicloud_", "huaweicloud/"]),
            ("alicloud", ["provider \"alicloud\"", "alicloud_", "aliyun/alicloud"]),
            ("tencentcloud", ["provider \"tencentcloud\"", "tencentcloud_", "tencentcloudstack/"]),
            ("baiducloud", ["provider \"baiducloud\"", "baiducloud_", "baidubce/"]),
            ("azurerm", ["provider \"azurerm\"", "azurerm_", "hashicorp/azurerm"]),
            ("aws", ["provider \"aws\"", "aws_", "hashicorp/aws"])
        ]
        
        # æ£€æµ‹äº‘å¹³å°
        for cloud_name, patterns in cloud_patterns:
            for pattern in patterns:
                if pattern in code_lower:
                    return cloud_name
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•äº‘å¹³å°ï¼Œè¿”å›unknown
        return "unknown"

    def _add_huaweicloud_credentials_to_code(self, terraform_code, ak, sk):
        """å‘Terraformä»£ç ä¸­æ·»åŠ åä¸ºäº‘å‡­è¯"""
        self.logger.info("æ·»åŠ åä¸ºäº‘å‡­è¯åˆ°Terraformä»£ç ")
        
        lines = terraform_code.split('\n')
        providers = []
        
        # å¯»æ‰¾åä¸ºäº‘provider
        for i, line in enumerate(lines):
            if re.match(r'\s*provider\s+"huaweicloud"\s+{', line):
                provider_start = i
                provider_end = -1
                
                # æ‰¾åˆ°providerå—çš„ç»“æŸ
                for j in range(provider_start + 1, len(lines)):
                    if re.match(r'\s*}', lines[j]):
                        provider_end = j
                        break
                
                if provider_end > 0:
                    providers.append({
                        'start': provider_start,
                        'end': provider_end
                    })
        
        # ä¸ºæ¯ä¸ªåä¸ºäº‘provideræ·»åŠ å‡­è¯
        offset = 0
        for provider in providers:
            start = provider['start'] + offset
            end = provider['end'] + offset
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰å‡­è¯
            has_credentials = False
            for i in range(start, end):
                if re.search(r'access_key\s*=\s*".+?"', lines[i]) and re.search(r'secret_key\s*=\s*".+?"', lines[i]):
                    has_credentials = True
                    break
            
            # å¦‚æœæ²¡æœ‰å‡­è¯ï¼Œæ·»åŠ å‡­è¯
            if not has_credentials:
                credentials = [
                    f"  access_key = \"{ak}\"",
                    f"  secret_key = \"{sk}\""
                ]
                
                lines.insert(end, credentials[1])
                lines.insert(end, credentials[0])
                offset += 2
        
        return '\n'.join(lines)

    def _add_alicloud_credentials_to_code(self, terraform_code, ak, sk):
        """å‘Terraformä»£ç ä¸­æ·»åŠ é˜¿é‡Œäº‘å‡­è¯"""
        self.logger.info("æ·»åŠ é˜¿é‡Œäº‘å‡­è¯åˆ°Terraformä»£ç ")
        
        lines = terraform_code.split('\n')
        providers = []
        
        # å¯»æ‰¾é˜¿é‡Œäº‘provider
        for i, line in enumerate(lines):
            if re.match(r'\s*provider\s+"alicloud"\s+{', line):
                provider_start = i
                provider_end = -1
                
                for j in range(provider_start + 1, len(lines)):
                    if re.match(r'\s*}', lines[j]):
                        provider_end = j
                        break
                
                if provider_end > 0:
                    providers.append({
                        'start': provider_start,
                        'end': provider_end
                    })
        
        # ä¸ºæ¯ä¸ªé˜¿é‡Œäº‘provideræ·»åŠ å‡­è¯
        offset = 0
        for provider in providers:
            start = provider['start'] + offset
            end = provider['end'] + offset
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰å‡­è¯
            has_credentials = False
            for i in range(start, end):
                if re.search(r'access_key\s*=\s*".+?"', lines[i]) and re.search(r'secret_key\s*=\s*".+?"', lines[i]):
                    has_credentials = True
                    break
            
            if not has_credentials:
                credentials = [
                    f"  access_key = \"{ak}\"",
                    f"  secret_key = \"{sk}\""
                ]
                
                lines.insert(end, credentials[1])
                lines.insert(end, credentials[0])
                offset += 2
        
        return '\n'.join(lines)

    def _add_tencentcloud_credentials_to_code(self, terraform_code, ak, sk):
        """å‘Terraformä»£ç ä¸­æ·»åŠ è…¾è®¯äº‘å‡­è¯"""
        self.logger.info("æ·»åŠ è…¾è®¯äº‘å‡­è¯åˆ°Terraformä»£ç ")
        
        lines = terraform_code.split('\n')
        providers = []
        
        # å¯»æ‰¾è…¾è®¯äº‘provider
        for i, line in enumerate(lines):
            if re.match(r'\s*provider\s+"tencentcloud"\s+{', line):
                provider_start = i
                provider_end = -1
                
                for j in range(provider_start + 1, len(lines)):
                    if re.match(r'\s*}', lines[j]):
                        provider_end = j
                        break
                
                if provider_end > 0:
                    providers.append({
                        'start': provider_start,
                        'end': provider_end
                    })
        
        # ä¸ºæ¯ä¸ªè…¾è®¯äº‘provideræ·»åŠ å‡­è¯
        offset = 0
        for provider in providers:
            start = provider['start'] + offset
            end = provider['end'] + offset
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰å‡­è¯
            has_credentials = False
            for i in range(start, end):
                if re.search(r'secret_id\s*=\s*".+?"', lines[i]) and re.search(r'secret_key\s*=\s*".+?"', lines[i]):
                    has_credentials = True
                    break
            
            if not has_credentials:
                credentials = [
                    f"  secret_id = \"{ak}\"",  # è…¾è®¯äº‘ä½¿ç”¨secret_id
                    f"  secret_key = \"{sk}\""
                ]
                
                lines.insert(end, credentials[1])
                lines.insert(end, credentials[0])
                offset += 2
        
        return '\n'.join(lines)

    def _add_baiducloud_credentials_to_code(self, terraform_code, ak, sk):
        """å‘Terraformä»£ç ä¸­æ·»åŠ ç™¾åº¦äº‘å‡­è¯"""
        self.logger.info("æ·»åŠ ç™¾åº¦äº‘å‡­è¯åˆ°Terraformä»£ç ")
        
        lines = terraform_code.split('\n')
        providers = []
        
        # å¯»æ‰¾ç™¾åº¦äº‘provider
        for i, line in enumerate(lines):
            if re.match(r'\s*provider\s+"baiducloud"\s+{', line):
                provider_start = i
                provider_end = -1
                
                for j in range(provider_start + 1, len(lines)):
                    if re.match(r'\s*}', lines[j]):
                        provider_end = j
                        break
                
                if provider_end > 0:
                    providers.append({
                        'start': provider_start,
                        'end': provider_end
                    })
        
        # ä¸ºæ¯ä¸ªç™¾åº¦äº‘provideræ·»åŠ å‡­è¯
        offset = 0
        for provider in providers:
            start = provider['start'] + offset
            end = provider['end'] + offset
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰å‡­è¯
            has_credentials = False
            for i in range(start, end):
                if re.search(r'access_key\s*=\s*".+?"', lines[i]) and re.search(r'secret_key\s*=\s*".+?"', lines[i]):
                    has_credentials = True
                    break
            
            if not has_credentials:
                credentials = [
                    f"  access_key = \"{ak}\"",
                    f"  secret_key = \"{sk}\""
                ]
                
                lines.insert(end, credentials[1])
                lines.insert(end, credentials[0])
                offset += 2
        
        return '\n'.join(lines)

    def _add_azure_credentials_to_code(self, terraform_code, ak, sk):
        """å‘Terraformä»£ç ä¸­æ·»åŠ Azureå‡­è¯"""
        self.logger.info("æ·»åŠ Azureå‡­è¯åˆ°Terraformä»£ç ")
        
        lines = terraform_code.split('\n')
        providers = []
        
        # å¯»æ‰¾Azure provider
        for i, line in enumerate(lines):
            if re.match(r'\s*provider\s+"azurerm"\s+{', line):
                provider_start = i
                provider_end = -1
                
                for j in range(provider_start + 1, len(lines)):
                    if re.match(r'\s*}', lines[j]):
                        provider_end = j
                        break
                
                if provider_end > 0:
                    providers.append({
                        'start': provider_start,
                        'end': provider_end
                    })
        
        # ä¸ºæ¯ä¸ªAzure provideræ·»åŠ å‡­è¯
        offset = 0
        for provider in providers:
            start = provider['start'] + offset
            end = provider['end'] + offset
            
            # æ£€æŸ¥providerå—ä¸­å·²æœ‰çš„é…ç½®
            has_client_id = False
            has_client_secret = False
            has_tenant_id = False
            has_subscription_id = False
            has_use_cli = False
            
            for i in range(start, end):
                line = lines[i]
                if re.search(r'client_id\s*=', line):
                    has_client_id = True
                elif re.search(r'client_secret\s*=', line):
                    has_client_secret = True
                elif re.search(r'tenant_id\s*=', line):
                    has_tenant_id = True
                elif re.search(r'subscription_id\s*=', line):
                    has_subscription_id = True
                elif re.search(r'use_cli\s*=', line):
                    has_use_cli = True
            
            # æ„å»ºéœ€è¦æ·»åŠ çš„å‡­è¯åˆ—è¡¨
            credentials_to_add = []
            
            if not has_client_id:
                credentials_to_add.append(f"  client_id = \"{ak}\"")  # AKå¯¹åº”client_id
            if not has_client_secret:
                credentials_to_add.append(f"  client_secret = \"{sk}\"")  # SKå¯¹åº”client_secret
            if not has_tenant_id:
                credentials_to_add.append(f"  tenant_id = var.tenant_id")
            if not has_subscription_id:
                credentials_to_add.append(f"  subscription_id = var.subscription_id")
            if not has_use_cli:
                credentials_to_add.append(f"  use_cli = false")
            
            # åªæ·»åŠ ç¼ºå¤±çš„é…ç½®
            if credentials_to_add:
                self.logger.info(f"æ·»åŠ ç¼ºå¤±çš„Azureå‡­è¯é…ç½®: {credentials_to_add}")
                for cred in reversed(credentials_to_add):
                    lines.insert(end, cred)
                offset += len(credentials_to_add)
            else:
                self.logger.info("Azure provideré…ç½®å·²å®Œæ•´ï¼Œæ— éœ€æ·»åŠ å‡­è¯")
        
        return '\n'.join(lines)