import os
import logging
import traceback
import json
import requests
import uuid
import re
import subprocess
import shutil
import time
import threading
from datetime import datetime
from flask import request, jsonify, current_app, send_file
from flask_socketio import emit
from config.config import Config
from models.aideployment_model import AIDeploymentModel
from utils.auth import get_current_user
import openai
import io

# 可能的部署状态
DEPLOYMENT_STATES = {
    'draft': '草稿',
    'pending': '等待部署',
    'initializing': '初始化中',
    'planning': '规划中',
    'applying': '部署中',
    'cleaning': '清理资源中',
    'completed': '部署完成',
    'failed': '部署失败'
}

class TerraformController:
    def __init__(self, config=None):
        """初始化Terraform控制器"""
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.openai_api_key = os.environ.get('OPENAI_API_KEY', '')
        self.deployment_model = AIDeploymentModel()
        
        # 确保部署目录存在
        self.base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.deployments_dir = os.path.join(self.base_dir, 'aideployments')
        os.makedirs(self.deployments_dir, exist_ok=True)
        self.logger.info(f"确保部署目录存在: {self.deployments_dir}")
        
    def generate_terraform_code(self, user_description, mermaid_code):
        """从用户描述和Mermaid图表生成Terraform代码"""
        try:
            self.logger.info(f"开始生成Terraform代码，Mermaid代码长度: {len(mermaid_code)}")
            
            # 获取当前用户信息
            current_user = request.current_user
            user_id = None
            username = None
            
            if current_user:
                user_id = current_user.get('user_id')
                username = current_user.get('username')
                
            self.logger.info(f"用户 {username} (ID: {user_id}) 请求生成Terraform代码")
            
            # 检查用户描述中是否包含"amazon_linux"
            needs_amazon_linux_ami = 'amazon_linux' in user_description.lower()
            if needs_amazon_linux_ami:
                self.logger.info("检测到用户需要Amazon Linux AMI，将添加相应数据块")
            
            # 构建系统提示
            system_prompt = """
            You are an AI assistant specialized in creating Terraform configurations from architecture diagrams.
            
            Your task is to analyze the user's description and the Mermaid diagram, then generate an appropriate
            Terraform configuration that would create the infrastructure shown in the diagram.
            
            Follow these guidelines:
            1. Include appropriate providers (AWS, Azure, GCP, etc.) based on the diagram
            2. Create all resources shown in the diagram with sensible defaults
            3. Use proper Terraform syntax and best practices
            4. Add helpful comments to explain complex sections
            5. Include variable definitions for customizable parameters
            6. Create outputs for important resource attributes
            7. Structure your code in a logical way
            
            CLOUD PROVIDER SPECIFIC REQUIREMENTS:
            1. For non-AWS cloud providers (like Azure, GCP, Volcengine, etc.), DO NOT include Internet Gateway (IGW) resources or internet_gateway components, as these are AWS-specific concepts and not required in other cloud platforms.
            2. For non-AWS cloud providers, instances with public IP addresses can access the internet without configuring default routes. No additional routing configuration is needed for internet access when public IPs are assigned.
            
            Only return the Terraform code (HCL format) without any additional explanation.
            """
            
            # 如果需要Amazon Linux AMI，添加额外提示
            if needs_amazon_linux_ami:
                system_prompt += """
            
            IMPORTANT: For EC2 instances, use a data source for the Amazon Linux 2 AMI with the following pattern:
            
            ```hcl
            data "aws_ami" "amazon_linux" {
              most_recent = true
              owners      = ["amazon"]
            
              filter {
                name   = "name"
                values = ["amzn2-ami-hvm-*-x86_64-gp2"]
              }
            }
            ```
            
            Then, in all EC2 instance resources, reference this data source using:
            ami = data.aws_ami.amazon_linux.id
            """
            
            # 获取API密钥，优先使用环境变量，否则使用配置
            api_key = self.openai_api_key
            if not api_key and self.config:
                api_key = getattr(self.config, 'openai_api_key', '')
            
            if not api_key:
                return jsonify({
                    "success": False,
                    "error": "未配置OpenAI API密钥",
                    "message": "请在环境变量或配置文件中设置OPENAI_API_KEY"
                }), 500
            
            # 准备用户提示，包含描述和图表
            user_prompt = f"""
            Here's my infrastructure requirement:
            {user_description}
            
            Here's the Mermaid diagram representing this infrastructure:
            ```mermaid
            {mermaid_code}
            ```
            
            Please generate complete Terraform code (HCL format) to provision this infrastructure.
            """
            
            # 如果需要Amazon Linux AMI，在用户提示中也强调
            if needs_amazon_linux_ami:
                user_prompt += """
            
            IMPORTANT: Make sure to use the Amazon Linux 2 AMI data source for any EC2 instances as follows:
            
            ```
            data "aws_ami" "amazon_linux" {
              most_recent = true
              owners      = ["amazon"]
            
              filter {
                name   = "name"
                values = ["amzn2-ami-hvm-*-x86_64-gp2"]
              }
            }
            ```
            
            Then use it in EC2 instances with: ami = data.aws_ami.amazon_linux.id
            """
            
            # 调用OpenAI API生成Terraform代码
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            payload = {
                "model": "gpt-4o",  # 使用强大的模型来处理复杂的Terraform生成
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.1  # 较低的温度以确保一致性
            }
            
            self.logger.info("调用OpenAI API生成Terraform代码")
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload
            )
            
            if response.status_code != 200:
                self.logger.error(f"OpenAI API返回错误: {response.status_code}")
                self.logger.error(f"错误详情: {response.text}")
                return jsonify({
                    "success": False,
                    "error": "生成Terraform代码失败",
                    "message": f"OpenAI API返回错误: {response.status_code}"
                }), 500
            
            # 解析响应
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            # 提取Terraform代码（移除可能的代码块标记）
            terraform_code = self._clean_terraform_code(content)
            
            # 如果需要Amazon Linux AMI，但生成的代码中没有包含，则手动添加
            if needs_amazon_linux_ami:
                # 检查生成的代码中是否已经包含AMI数据块
                if 'data "aws_ami" "amazon_linux"' not in terraform_code:
                    self.logger.info("生成的代码中未包含Amazon Linux AMI数据块，手动添加")
                    
                    # 准备AMI数据块
                    ami_data_block = '''
# Amazon Linux 2 AMI
data "aws_ami" "amazon_linux" {
  most_recent = true
  owners      = ["amazon"]

  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }
}
'''
                    # 添加到代码的适当位置（在provider后面，资源前面）
                    if 'provider "aws"' in terraform_code:
                        # 如果有provider块，添加在其后
                        provider_end_index = terraform_code.find('provider "aws"')
                        provider_end_index = terraform_code.find('}', provider_end_index) + 1
                        
                        # 添加一个空行和数据块
                        terraform_code = terraform_code[:provider_end_index] + '\n' + ami_data_block + terraform_code[provider_end_index:]
                    else:
                        # 如果没有provider块，添加在开头
                        terraform_code = ami_data_block + terraform_code
                
                # 检查EC2实例是否使用了AMI数据块引用
                if 'resource "aws_instance"' in terraform_code and 'ami = data.aws_ami.amazon_linux.id' not in terraform_code:
                    self.logger.info("检测到EC2实例但未使用AMI数据引用，尝试修改")
                    
                    # 正则表达式，匹配EC2实例中的ami行
                    ami_pattern = r'(resource\s+"aws_instance"\s+".+?"\s+{.*?)(ami\s+=\s+".+?")(.*?})' 
                    terraform_code = re.sub(ami_pattern, r'\1ami = data.aws_ami.amazon_linux.id\3', terraform_code, flags=re.DOTALL)
            
            # 构建响应
            result = {
                "success": True,
                "terraform_code": terraform_code,
                "message": "Terraform代码生成成功"
            }
            
            self.logger.info("Terraform代码生成成功")
            return jsonify(result), 200
            
        except Exception as e:
            self.logger.error(f"生成Terraform代码时出错: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "生成Terraform代码时出错",
                "message": str(e)
            }), 500
    
    def _clean_terraform_code(self, content):
        """清理从OpenAI获得的Terraform代码，移除可能的Markdown代码块标记"""
        # 移除可能的Markdown代码块标记
        if '```terraform' in content or '```hcl' in content:
            # 使用正则表达式提取代码块内容
            pattern = r'```(?:terraform|hcl)\s*([\s\S]*?)```'
            matches = re.findall(pattern, content)
            if matches:
                return matches[0].strip()
            
        # 如果没有找到特定的代码块标记，尝试匹配任何代码块
        if '```' in content:
            pattern = r'```\s*([\s\S]*?)```'
            matches = re.findall(pattern, content)
            if matches:
                return matches[0].strip()
        
        # 如果没有代码块标记，直接返回整个内容
        return content.strip()
    
    def deploy_terraform(self):
        """处理Terraform部署请求"""
        try:
            # 获取请求数据
            data = request.get_json()
            if not data:
                return jsonify({"error": "请求数据无效"}), 400
            
            # 验证必需参数
            if 'code' not in data:
                return jsonify({"error": "缺少Terraform代码"}), 400
            
            # 获取用户ID
            user = getattr(request, 'current_user', None)
            user_id = user.get('user_id', 0) if user else 0
            
            # 获取项目ID和云平台ID
            project_id = data.get('project_id', 0)
            project_name = data.get('project_name', '未命名项目')
            cloud_id = data.get('cloud_id', 0)
            cloud_name = data.get('cloud_name', '未知云平台')
            
            # 获取API密钥ID或直接的凭证
            api_key_id = data.get('api_key_id')
            ak = data.get('ak', '')
            sk = data.get('sk', '')
            
            # 如果提供了API密钥ID，尝试查找对应的凭证
            if api_key_id and (not ak or not sk):
                try:
                    from controllers.apikey_controller import ApiKeyController
                    apikey_controller = ApiKeyController(self.config)
                    api_key = apikey_controller.get_api_key_by_id(api_key_id)
                    
                    if not api_key:
                        self.logger.error(f"找不到指定的API密钥: {api_key_id}")
                        return jsonify({"error": "找不到指定的API密钥"}), 404
                    
                    # 获取AK和SK
                    ak = api_key.get('ak', '')
                    sk = api_key.get('sk', '')
                    
                    self.logger.info(f"成功通过ID获取API密钥: {api_key.get('apikey_name')}")
                except Exception as apikey_error:
                    self.logger.error(f"获取API密钥时出错: {str(apikey_error)}")
                    return jsonify({"error": f"获取API密钥时出错: {str(apikey_error)}"}), 500
            
            # 检查是否提供了凭证
            if not ak or not sk:
                return jsonify({"error": "请提供有效的访问凭证"}), 400
            
            # 获取原始Terraform代码
            original_code = data.get('code', '')
            
            # 检查代码是否为空
            if not original_code.strip():
                return jsonify({"error": "不能部署空的Terraform代码"}), 400
            
            # 如果包含火山云相关关键词，使用火山云凭证，否则使用AWS凭证
            if "volcengine" in original_code.lower() or "火山" in original_code:
                terraform_code = self._add_volcengine_credentials_to_code(original_code, ak, sk)
                self.logger.info("检测到火山引擎代码，已添加火山引擎凭证")
            else:
                terraform_code = self._add_aws_credentials_to_code(original_code, ak, sk)
            
            # 生成部署ID (AIDP前缀+23位随机数)
            deploy_id = f"AIDP{uuid.uuid4().hex[:19]}".upper()
            
            # 创建部署目录
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            os.makedirs(deploy_dir, exist_ok=True)
            
            # 创建main.tf文件
            tf_file_path = os.path.join(deploy_dir, 'main.tf')
            with open(tf_file_path, 'w') as f:
                f.write(terraform_code)
            
            # 保存原始代码，用于对比和恢复（使用.bak扩展名避免Terraform读取）
            original_code_path = os.path.join(deploy_dir, 'original.tf.bak')
            with open(original_code_path, 'w') as f:
                f.write(original_code)
            
            # 创建部署记录
            deploy_data = {
                'id': deploy_id,
                'user_id': user_id,
                'username': user.get('username', 'unknown'),
                'name': project_name,
                'description': f"云平台: {cloud_name}, 项目ID: {project_id}",
                'status': 'pending',
                'terraform_code': terraform_code,
                'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # 保存部署记录
            self.deployment_model.create_deployment(deploy_data)
            
            # 启动后台任务
            threading.Thread(
                target=self._run_terraform_deployment,
                args=(deploy_id, deploy_dir, user_id)
            ).start()
            
            return jsonify({
                "success": True,
                "deploy_id": deploy_id,
                "message": "部署任务已提交，正在后台执行"
            })
            
        except Exception as e:
            self.logger.error(f"部署Terraform时出错: {str(e)}")
            traceback_str = traceback.format_exc()
            self.logger.error(f"详细错误: {traceback_str}")
            return jsonify({"error": f"部署Terraform时出错: {str(e)}"}), 500
    
    def _add_aws_credentials_to_code(self, terraform_code, ak, sk):
        """向Terraform代码中添加AWS凭证"""
        # 检查代码中的AWS provider
        providers = []
        lines = terraform_code.split('\n')
        
        # 寻找已有的AWS provider并记录
        for i, line in enumerate(lines):
            if re.match(r'\s*provider\s+"aws"\s+{', line):
                provider_start = i
                provider_end = -1
                
                # 找到provider块的结束
                for j in range(provider_start + 1, len(lines)):
                    if re.match(r'\s*}', lines[j]):
                        provider_end = j
                        break
                
                if provider_end > 0:
                    provider_lines = lines[provider_start:provider_end+1]
                    # 获取provider别名（如果有）
                    alias = None
                    for provider_line in provider_lines:
                        alias_match = re.search(r'alias\s+=\s+"([^"]+)"', provider_line)
                        if alias_match:
                            alias = alias_match.group(1)
                            break
                    
                    providers.append({
                        'start': provider_start,
                        'end': provider_end,
                        'alias': alias
                    })
        
        # 为每个provider添加凭证
        offset = 0  # 行偏移量（添加行会改变后续行号）
        
        for provider in providers:
            # 获取provider内容
            start = provider['start'] + offset
            end = provider['end'] + offset
            
            # 检查provider中是否已有access_key和secret_key
            has_credentials = False
            has_access_key = False
            has_secret_key = False
            
            for i in range(start, end):
                # 检查是否有非空的access_key设置（不包括注释和空值）
                if re.search(r'access_key\s*=\s*".+?"', lines[i]) or re.search(r"access_key\s*=\s*'.+?'", lines[i]):
                    if not re.search(r'access_key\s*=\s*["\']\s*["\']', lines[i]):  # 跳过空值
                        has_access_key = True
                        
                # 检查是否有非空的secret_key设置（不包括注释和空值）
                if re.search(r'secret_key\s*=\s*".+?"', lines[i]) or re.search(r"secret_key\s*=\s*'.+?'", lines[i]):
                    if not re.search(r'secret_key\s*=\s*["\']\s*["\']', lines[i]):  # 跳过空值
                        has_secret_key = True
                        
                # 只有两者都存在才视为有效凭证
                if has_access_key and has_secret_key:
                    has_credentials = True
                    self.logger.info("检测到火山引擎provider已包含有效的AK/SK")
                    break
            
            # 如果没有凭证，则添加
            if not has_credentials:
                # 在provider块结束前添加凭证
                credentials = [
                    f"  access_key = \"{ak}\"",
                    f"  secret_key = \"{sk}\""
                ]
                
                # 插入凭证到provider块结束前
                lines.insert(end, credentials[1])
                lines.insert(end, credentials[0])
                
                # 更新偏移量
                offset += 2
        
        # 如果没有找到provider，则添加一个默认provider
        if not providers:
            default_provider = [
                "provider \"aws\" {",
                f"  access_key = \"{ak}\"",
                f"  secret_key = \"{sk}\"",
                "  region = \"us-east-1\"",
                "}"
            ]
            
            # 在代码开头添加默认provider
            lines = default_provider + [''] + lines
        
        return '\n'.join(lines)
    
    def _add_volcengine_credentials_to_code(self, terraform_code, ak, sk):
        """向Terraform代码中添加火山引擎凭证"""
        self.logger.info("添加火山引擎凭证到Terraform代码")
        
        # 检查代码中是否有火山引擎provider
        providers = []
        lines = terraform_code.split('\n')
        
        # 寻找已有的火山引擎provider并记录
        for i, line in enumerate(lines):
            if re.match(r'\s*provider\s+"volcengine"\s+{', line):
                provider_start = i
                provider_end = -1
                
                # 找到provider块的结束
                for j in range(provider_start + 1, len(lines)):
                    if re.match(r'\s*}', lines[j]):
                        provider_end = j
                        break
                
                if provider_end > 0:
                    providers.append({
                        'start': provider_start,
                        'end': provider_end
                    })
        
        # 为每个provider添加凭证
        offset = 0  # 行偏移量（添加行会改变后续行号）
        
        for provider in providers:
            # 获取provider内容
            start = provider['start'] + offset
            end = provider['end'] + offset
            
            # 检查provider中是否已有access_key和secret_key
            has_credentials = False
            has_access_key = False
            has_secret_key = False
            
            for i in range(start, end):
                # 检查是否有非空的access_key设置（不包括注释和空值）
                if re.search(r'access_key\s*=\s*".+?"', lines[i]) or re.search(r"access_key\s*=\s*'.+?'", lines[i]):
                    if not re.search(r'access_key\s*=\s*["\']\s*["\']', lines[i]):  # 跳过空值
                        has_access_key = True
                        
                # 检查是否有非空的secret_key设置（不包括注释和空值）
                if re.search(r'secret_key\s*=\s*".+?"', lines[i]) or re.search(r"secret_key\s*=\s*'.+?'", lines[i]):
                    if not re.search(r'secret_key\s*=\s*["\']\s*["\']', lines[i]):  # 跳过空值
                        has_secret_key = True
                        
                # 只有两者都存在才视为有效凭证
                if has_access_key and has_secret_key:
                    has_credentials = True
                    self.logger.info("检测到火山引擎provider已包含有效的AK/SK")
                    break
            
            # 如果没有凭证，则添加
            if not has_credentials:
                if has_access_key and not has_secret_key:
                    self.logger.info("火山引擎provider中只有access_key但缺少secret_key，添加凭证")
                elif has_secret_key and not has_access_key:
                    self.logger.info("火山引擎provider中只有secret_key但缺少access_key，添加凭证")
                else:
                    self.logger.info("火山引擎provider中缺少完整的AK/SK凭证，添加凭证")
                
                # 在provider块结束前添加凭证
                credentials = [
                    f"  access_key = \"{ak}\"",
                    f"  secret_key = \"{sk}\""
                ]
                
                # 插入凭证到provider块结束前
                lines.insert(end, credentials[1])
                lines.insert(end, credentials[0])
                
                # 更新偏移量
                offset += 2
        
        # 如果没有找到provider，则添加一个默认provider
        if not providers:
            # 检查代码中是否已经包含了required_providers块
            has_required_providers = False
            for line in lines:
                if "required_providers" in line:
                    has_required_providers = True
                    break
            
            # 准备添加的代码块
            provider_blocks = []
            
            # 如果没有required_providers块，添加一个
            if not has_required_providers:
                provider_blocks.extend([
                    "terraform {",
                    "  required_providers {",
                    "    volcengine = {",
                    "      source = \"volcengine/volcengine\"",
                    "      version = \"0.0.167\"",
                    "    }",
                    "  }",
                    "}",
                    ""
                ])
            
            # 添加provider块
            provider_blocks.extend([
                "provider \"volcengine\" {",
                "  region = \"cn-beijing\"",
                f"  access_key = \"{ak}\"",
                f"  secret_key = \"{sk}\"",
                "}",
                ""
            ])
            
            # 在代码开头添加provider块
            lines = provider_blocks + lines
            
            self.logger.info("找不到火山引擎provider，已添加默认provider配置")
        
        return '\n'.join(lines)
    
    def _run_terraform_deployment(self, deploy_id, deploy_dir, user_id):
        """在后台运行Terraform部署过程"""
        # 记录执行过程中的所有重要信息，用于创建摘要日志
        deployment_logs = {
            'deploy_id': deploy_id,
            'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'status': 'pending',
            'init_output': '',
            'plan_output': '',
            'apply_output': '',
            'init_error': '',
            'plan_error': '',
            'apply_error': '',
            'retry_count': 0,
            'error_message': '',
            'outputs': {}
        }
        
        # 创建或更新部署摘要日志的辅助函数
        def create_deployment_summary(is_success=True):
            deploy_summary_log = os.path.join(deploy_dir, 'deployment_summary.log')
            with open(deploy_summary_log, 'w') as summary_file:
                summary_file.write(f"部署ID: {deploy_id}\n")
                summary_file.write(f"开始时间: {deployment_logs['start_time']}\n")
                summary_file.write(f"完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                summary_file.write(f"总重试次数: {deployment_logs['retry_count']}\n")
                summary_file.write(f"部署状态: {'成功' if is_success else '失败'}\n")
                if not is_success:
                    summary_file.write(f"失败原因: {deployment_logs['error_message']}\n")
                summary_file.write("\n")
                
                # 添加初始化信息
                if deployment_logs['init_output']:
                    summary_file.write("Terraform初始化输出:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['init_output']}\n\n")
                if deployment_logs['init_error']:
                    summary_file.write("Terraform初始化错误:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['init_error']}\n\n")
                
                # 添加规划信息
                if deployment_logs['plan_output']:
                    summary_file.write("Terraform规划输出:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['plan_output']}\n\n")
                if deployment_logs['plan_error']:
                    summary_file.write("Terraform规划错误:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['plan_error']}\n\n")
                
                # 添加应用信息
                if deployment_logs['apply_output']:
                    summary_file.write("Terraform应用输出:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['apply_output']}\n\n")
                if deployment_logs['apply_error']:
                    summary_file.write("Terraform应用错误:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{deployment_logs['apply_error']}\n\n")
                
                # 添加修复历史
                if deployment_logs['retry_count'] > 0:
                    summary_file.write("修复历史:\n")
                    summary_file.write("-" * 80 + "\n")
                    fix_log_path = os.path.join(deploy_dir, 'fix_attempts.log')
                    if os.path.exists(fix_log_path):
                        with open(fix_log_path, 'r') as fix_log:
                            summary_file.write(fix_log.read())
                    summary_file.write("\n")
                
                # 添加输出变量
                if is_success and deployment_logs['outputs']:
                    summary_file.write("输出变量:\n")
                    summary_file.write("-" * 80 + "\n")
                    summary_file.write(f"{json.dumps(deployment_logs['outputs'], indent=2)}\n\n")
        
        try:
            self.logger.info(f"开始执行Terraform部署: {deploy_id}, 目录: {deploy_dir}")
            
            # 检查terraform命令是否存在
            try:
                terraform_version = subprocess.run(
                    ['terraform', '--version'],
                    capture_output=True,
                    text=True
                )
                self.logger.info(f"Terraform版本: {terraform_version.stdout.strip()}")
            except FileNotFoundError:
                error_msg = "未找到Terraform命令，请确保已安装Terraform并添加到PATH"
                self.logger.error(error_msg)
                deployment_logs['error_message'] = error_msg
                deployment_logs['status'] = 'failed'
                create_deployment_summary(is_success=False)
                self.deployment_model.update_deployment_status(
                    deploy_id, 
                    'failed', 
                    error_message=error_msg
                )
                return
            
            # 检查部署目录是否存在
            if not os.path.exists(deploy_dir):
                error_msg = f"部署目录不存在: {deploy_dir}"
                self.logger.error(error_msg)
                deployment_logs['error_message'] = error_msg
                deployment_logs['status'] = 'failed'
                create_deployment_summary(is_success=False)
                self.deployment_model.update_deployment_status(
                    deploy_id, 
                    'failed', 
                    error_message=error_msg
                )
                return
            
            # 检查main.tf文件是否存在
            tf_file_path = os.path.join(deploy_dir, 'main.tf')
            if not os.path.exists(tf_file_path):
                error_msg = f"Terraform配置文件不存在: {tf_file_path}"
                self.logger.error(error_msg)
                deployment_logs['error_message'] = error_msg
                deployment_logs['status'] = 'failed'
                create_deployment_summary(is_success=False)
                self.deployment_model.update_deployment_status(
                    deploy_id, 
                    'failed', 
                    error_message=error_msg
                )
                return
            
            # 最大重试次数
            max_retries = 20
            retry_count = 0
            
            # 开始部署循环，带重试和自动修复机制
            while retry_count <= max_retries:
                # 如果不是第一次尝试，更新状态为重试中
                if retry_count > 0:
                    self.logger.info(f"第{retry_count}次重试部署: {deploy_id}")
                    self.deployment_model.update_deployment_status(
                        deploy_id, 
                        'planning', 
                        error_message=f"第{retry_count}次重试，正在重新生成Terraform代码"
                    )
                    deployment_logs['retry_count'] = retry_count
                
                # 更新部署状态为"initializing"
                self.logger.info(f"更新部署状态为initializing: {deploy_id}")
                self.deployment_model.update_deployment_status(deploy_id, 'initializing')
                
                # 运行terraform init
                self.logger.info(f"开始初始化Terraform: {deploy_id}")
                try:
                    init_result = subprocess.run(
                        ['terraform', 'init'],
                        cwd=deploy_dir,
                        capture_output=True,
                        text=True
                    )
                    
                    # 记录输出
                    deployment_logs['init_output'] = init_result.stdout
                    
                    if init_result.returncode != 0:
                        deployment_logs['init_error'] = init_result.stderr
                        if retry_count < max_retries:
                            self.logger.error(f"Terraform初始化失败，尝试修复: {init_result.stderr}")
                            
                            # 如果存在之前的部署，先执行terraform destroy清理
                            if os.path.exists(os.path.join(deploy_dir, '.terraform')):
                                self.logger.info(f"执行terraform destroy清理之前可能存在的资源: {deploy_id}")
                                try:
                                    # 更新部署状态
                                    self.deployment_model.update_deployment_status(
                                        deploy_id, 
                                        'cleaning', 
                                        error_message=f"清理之前可能部署的资源，准备重新部署"
                                    )
                                    
                                    # 执行terraform destroy
                                    destroy_result = subprocess.run(
                                        ['terraform', 'destroy', '-auto-approve'],
                                        cwd=deploy_dir,
                                        capture_output=True,
                                        text=True
                                    )
                                    
                                    # 记录清理结果
                                    cleanup_log_path = os.path.join(deploy_dir, 'cleanup_attempts.log')
                                    with open(cleanup_log_path, 'a') as cleanup_file:
                                        cleanup_file.write(f"\n\n{'='*80}\n")
                                        cleanup_file.write(f"初始化错误清理 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                        cleanup_file.write(f"{'='*80}\n\n")
                                        cleanup_file.write("清理输出:\n```\n")
                                        cleanup_file.write(destroy_result.stdout)
                                        cleanup_file.write("\n```\n\n")
                                except Exception as destroy_error:
                                    self.logger.error(f"执行terraform destroy时出错: {str(destroy_error)}")
                            
                            # 读取原始Terraform代码
                            with open(tf_file_path, 'r') as f:
                                original_tf = f.read()
                            
                            # 尝试修复代码
                            fixed_tf = self._fix_terraform_code(original_tf, init_result.stderr, tf_file_path)
                            if fixed_tf:
                                self.logger.info("成功修复Terraform代码，准备重新部署")
                                # 保存修复后的代码
                                with open(tf_file_path, 'w') as f:
                                    f.write(fixed_tf)
                                
                                # 创建对比日志，记录修改前后的差异
                                diff_log_path = os.path.join(deploy_dir, 'code_diff.log')
                                with open(diff_log_path, 'a') as diff_file:
                                    diff_file.write(f"\n\n{'='*80}\n")
                                    diff_file.write(f"第{retry_count+1}次修复 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    diff_file.write(f"{'='*80}\n\n")
                                    diff_file.write("修复前:\n```terraform\n")
                                    diff_file.write(original_tf)
                                    diff_file.write("\n```\n\n修复后:\n```terraform\n")
                                    diff_file.write(fixed_tf)
                                    diff_file.write("\n```\n")
                                
                                retry_count += 1
                                # 更新部署状态，告知用户正在修复
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'planning', 
                                    error_message=f"检测到Terraform初始化错误，已自动修复并重试 ({retry_count}/{max_retries})"
                                )
                                deployment_logs['retry_count'] = retry_count
                                self.logger.info(f"开始第{retry_count}次重试部署")
                                continue
                            else:
                                self.logger.warning("无法自动修复Terraform代码")
                        
                        self.logger.error(f"Terraform初始化失败: {init_result.stderr}")
                        error_msg = f"初始化失败: {init_result.stderr}"
                        deployment_logs['error_message'] = error_msg
                        deployment_logs['status'] = 'failed'
                        create_deployment_summary(is_success=False)
                        
                                                self.logger.error(f"Terraform初始化失败: {init_result.stderr}")                        error_msg = f"初始化失败: {init_result.stderr}"                        deployment_logs['error_message'] = error_msg                        deployment_logs['status'] = 'failed'                        create_deployment_summary(is_success=False)
                        
                        self.deployment_model.update_deployment_status(
                            deploy_id, 
                            'failed', 
                            error_message=error_msg
                        )
                        return
                        
                    self.logger.info(f"Terraform初始化成功: {init_result.stdout}")
                except Exception as init_error:
                    error_msg = f"执行terraform init时出错: {str(init_error)}"
                    self.logger.error(error_msg)
                    deployment_logs['error_message'] = error_msg
                    deployment_logs['status'] = 'failed'
                    create_deployment_summary(is_success=False)
                    
                    # 尝试清理可能已部署的资源
                    if os.path.exists(os.path.join(deploy_dir, '.terraform')):
                        self.logger.info(f"正在清理初始化异常后的资源: {deploy_id}")
                        try:
                            # 更新部署状态
                            self.deployment_model.update_deployment_status(
                                deploy_id, 
                                'cleaning', 
                                error_message=f"初始化异常，正在清理可能存在的资源"
                            )
                            
                            # 执行terraform destroy
                            destroy_result = subprocess.run(
                                ['terraform', 'destroy', '-auto-approve'],
                                cwd=deploy_dir,
                                capture_output=True,
                                text=True
                            )
                            
                            # 记录清理结果
                            cleanup_log_path = os.path.join(deploy_dir, 'final_cleanup.log')
                            with open(cleanup_log_path, 'w') as cleanup_file:
                                cleanup_file.write(f"异常后资源清理 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                cleanup_file.write(f"{'='*80}\n\n")
                                cleanup_file.write("清理输出:\n```\n")
                                cleanup_file.write(destroy_result.stdout)
                                cleanup_file.write("\n```\n\n")
                                if destroy_result.stderr:
                                    cleanup_file.write("清理错误:\n```\n")
                                    cleanup_file.write(destroy_result.stderr)
                                    cleanup_file.write("\n```\n\n")
                            
                            # 更新错误信息
                            if destroy_result.returncode == 0:
                                error_msg += " (资源已自动清理)"
                            else:
                                error_msg += f" (资源清理失败: {destroy_result.stderr})"
                        except Exception as cleanup_error:
                            self.logger.error(f"执行资源清理时出错: {str(cleanup_error)}")
                            error_msg += f" (资源清理过程中出错: {str(cleanup_error)})"
                    
                    self.deployment_model.update_deployment_status(
                        deploy_id, 
                        'failed', 
                        error_message=error_msg
                    )
                    return
                
                # 更新部署状态为"planning"
                self.logger.info(f"更新部署状态为planning: {deploy_id}")
                self.deployment_model.update_deployment_status(deploy_id, 'planning')
                
                # 运行terraform plan
                self.logger.info(f"开始Terraform规划: {deploy_id}")
                try:
                    plan_result = subprocess.run(
                        ['terraform', 'plan', '-out=tfplan'],
                        cwd=deploy_dir,
                        capture_output=True,
                        text=True
                    )
                    
                    # 记录输出
                    deployment_logs['plan_output'] = plan_result.stdout
                    
                    if plan_result.returncode != 0:
                        deployment_logs['plan_error'] = plan_result.stderr
                        if retry_count < max_retries:
                            self.logger.error(f"Terraform规划失败，尝试修复: {plan_result.stderr}")
                            
                            # 如果存在之前的部署，先执行terraform destroy清理
                            if os.path.exists(os.path.join(deploy_dir, '.terraform')):
                                self.logger.info(f"执行terraform destroy清理之前可能存在的资源: {deploy_id}")
                                try:
                                    # 更新部署状态
                                    self.deployment_model.update_deployment_status(
                                        deploy_id, 
                                        'cleaning', 
                                        error_message=f"清理之前可能部署的资源，准备重新部署"
                                    )
                                    
                                    # 执行terraform destroy
                                    destroy_result = subprocess.run(
                                        ['terraform', 'destroy', '-auto-approve'],
                                        cwd=deploy_dir,
                                        capture_output=True,
                                        text=True
                                    )
                                    
                                    # 记录清理结果
                                    cleanup_log_path = os.path.join(deploy_dir, 'cleanup_attempts.log')
                                    with open(cleanup_log_path, 'a') as cleanup_file:
                                        cleanup_file.write(f"\n\n{'='*80}\n")
                                        cleanup_file.write(f"规划错误清理 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                        cleanup_file.write(f"{'='*80}\n\n")
                                        cleanup_file.write("清理输出:\n```\n")
                                        cleanup_file.write(destroy_result.stdout)
                                        cleanup_file.write("\n```\n\n")
                                except Exception as destroy_error:
                                    self.logger.error(f"执行terraform destroy时出错: {str(destroy_error)}")
                            
                            # 读取原始Terraform代码
                            with open(tf_file_path, 'r') as f:
                                original_tf = f.read()
                            
                            # 尝试修复代码
                            fixed_tf = self._fix_terraform_code(original_tf, plan_result.stderr, tf_file_path)
                            if fixed_tf:
                                self.logger.info("成功修复Terraform代码，准备重新部署")
                                # 保存修复后的代码
                                with open(tf_file_path, 'w') as f:
                                    f.write(fixed_tf)
                                
                                # 创建对比日志，记录修改前后的差异
                                diff_log_path = os.path.join(deploy_dir, 'code_diff.log')
                                with open(diff_log_path, 'a') as diff_file:
                                    diff_file.write(f"\n\n{'='*80}\n")
                                    diff_file.write(f"第{retry_count+1}次修复 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    diff_file.write(f"{'='*80}\n\n")
                                    diff_file.write("修复前:\n```terraform\n")
                                    diff_file.write(original_tf)
                                    diff_file.write("\n```\n\n修复后:\n```terraform\n")
                                    diff_file.write(fixed_tf)
                                    diff_file.write("\n```\n")
                                
                                retry_count += 1
                                # 更新部署状态，告知用户正在修复
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'planning', 
                                    error_message=f"检测到Terraform规划错误，已自动修复并重试 ({retry_count}/{max_retries})"
                                )
                                deployment_logs['retry_count'] = retry_count
                                self.logger.info(f"开始第{retry_count}次重试部署")
                                continue
                            else:
                                self.logger.warning("无法自动修复Terraform代码")
                        
                        self.logger.error(f"Terraform规划失败: {plan_result.stderr}")
                        error_msg = f"规划失败: {plan_result.stderr}"
                        deployment_logs['error_message'] = error_msg
                        deployment_logs['status'] = 'failed'
                        create_deployment_summary(is_success=False)
                        
                        # 尝试清理可能已部署的资源
                        if os.path.exists(os.path.join(deploy_dir, '.terraform')):
                            self.logger.info(f"正在清理规划失败后的资源: {deploy_id}")
                            try:
                                # 更新部署状态
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'cleaning', 
                                    error_message=f"规划失败，正在清理可能存在的资源"
                                )
                                
                                # 执行terraform destroy
                                destroy_result = subprocess.run(
                                    ['terraform', 'destroy', '-auto-approve'],
                                    cwd=deploy_dir,
                                    capture_output=True,
                                    text=True
                                )
                                
                                # 记录清理结果
                                cleanup_log_path = os.path.join(deploy_dir, 'final_cleanup.log')
                                with open(cleanup_log_path, 'w') as cleanup_file:
                                    cleanup_file.write(f"失败后资源清理 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    cleanup_file.write(f"{'='*80}\n\n")
                                    cleanup_file.write("清理输出:\n```\n")
                                    cleanup_file.write(destroy_result.stdout)
                                    cleanup_file.write("\n```\n\n")
                                    if destroy_result.stderr:
                                        cleanup_file.write("清理错误:\n```\n")
                                        cleanup_file.write(destroy_result.stderr)
                                        cleanup_file.write("\n```\n\n")
                                
                                # 更新错误信息
                                if destroy_result.returncode == 0:
                                    error_msg += " (资源已自动清理)"
                                else:
                                    error_msg += f" (资源清理失败: {destroy_result.stderr})"
                            except Exception as cleanup_error:
                                self.logger.error(f"执行资源清理时出错: {str(cleanup_error)}")
                                error_msg += f" (资源清理过程中出错: {str(cleanup_error)})"
                        
                        self.deployment_model.update_deployment_status(
                            deploy_id, 
                            'failed', 
                            error_message=error_msg
                        )
                        return
                        
                    self.logger.info(f"Terraform规划成功: {plan_result.stdout}")
                except Exception as plan_error:
                    error_msg = f"执行terraform plan时出错: {str(plan_error)}"
                    self.logger.error(error_msg)
                    deployment_logs['error_message'] = error_msg
                    deployment_logs['status'] = 'failed'
                    create_deployment_summary(is_success=False)
                    
                    # 尝试清理可能已部署的资源
                    if os.path.exists(os.path.join(deploy_dir, '.terraform')):
                        self.logger.info(f"正在清理规划异常后的资源: {deploy_id}")
                        try:
                            # 更新部署状态
                            self.deployment_model.update_deployment_status(
                                deploy_id, 
                                'cleaning', 
                                error_message=f"规划异常，正在清理可能存在的资源"
                            )
                            
                            # 执行terraform destroy
                            destroy_result = subprocess.run(
                                ['terraform', 'destroy', '-auto-approve'],
                                cwd=deploy_dir,
                                capture_output=True,
                                text=True
                            )
                            
                            # 记录清理结果
                            cleanup_log_path = os.path.join(deploy_dir, 'final_cleanup.log')
                            with open(cleanup_log_path, 'w') as cleanup_file:
                                cleanup_file.write(f"异常后资源清理 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                cleanup_file.write(f"{'='*80}\n\n")
                                cleanup_file.write("清理输出:\n```\n")
                                cleanup_file.write(destroy_result.stdout)
                                cleanup_file.write("\n```\n\n")
                                if destroy_result.stderr:
                                    cleanup_file.write("清理错误:\n```\n")
                                    cleanup_file.write(destroy_result.stderr)
                                    cleanup_file.write("\n```\n\n")
                            
                            # 更新错误信息
                            if destroy_result.returncode == 0:
                                error_msg += " (资源已自动清理)"
                            else:
                                error_msg += f" (资源清理失败: {destroy_result.stderr})"
                        except Exception as cleanup_error:
                            self.logger.error(f"执行资源清理时出错: {str(cleanup_error)}")
                            error_msg += f" (资源清理过程中出错: {str(cleanup_error)})"
                    
                    self.deployment_model.update_deployment_status(
                        deploy_id, 
                        'failed', 
                        error_message=error_msg
                    )
                    return
                
                # 更新部署状态为"applying"
                self.logger.info(f"更新部署状态为applying: {deploy_id}")
                self.deployment_model.update_deployment_status(deploy_id, 'applying')
                
                # 运行terraform apply
                self.logger.info(f"开始应用Terraform配置: {deploy_id}")
                try:
                    apply_result = subprocess.run(
                        ['terraform', 'apply', '-auto-approve', 'tfplan'],
                        cwd=deploy_dir,
                        capture_output=True,
                        text=True
                    )
                    
                    # 记录输出
                    deployment_logs['apply_output'] = apply_result.stdout
                    
                    if apply_result.returncode != 0:
                        deployment_logs['apply_error'] = apply_result.stderr
                        # 记录完整的错误消息到日志，便于诊断
                        self.logger.error(f"Terraform应用失败，完整错误: {apply_result.stderr}")
                        
                        if retry_count < max_retries:
                            self.logger.info(f"尝试修复Terraform应用错误，第{retry_count+1}次尝试")
                            
                            # 先执行terraform destroy清理之前部署的资源
                            self.logger.info(f"执行terraform destroy清理之前的部署资源: {deploy_id}")
                            try:
                                # 更新部署状态，告知用户正在清理资源
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'cleaning', 
                                    error_message=f"清理之前部署的资源，准备重新部署"
                                )
                                
                                # 执行terraform destroy
                                destroy_result = subprocess.run(
                                    ['terraform', 'destroy', '-auto-approve'],
                                    cwd=deploy_dir,
                                    capture_output=True,
                                    text=True
                                )
                                
                                if destroy_result.returncode != 0:
                                    self.logger.warning(f"Terraform资源清理失败，可能存在残留资源: {destroy_result.stderr}")
                                else:
                                    self.logger.info(f"Terraform资源清理成功: {destroy_result.stdout}")
                                    
                                # 记录清理结果到日志
                                cleanup_log_path = os.path.join(deploy_dir, 'cleanup_attempts.log')
                                with open(cleanup_log_path, 'a') as cleanup_file:
                                    cleanup_file.write(f"\n\n{'='*80}\n")
                                    cleanup_file.write(f"第{retry_count+1}次清理 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    cleanup_file.write(f"{'='*80}\n\n")
                                    cleanup_file.write("清理输出:\n```\n")
                                    cleanup_file.write(destroy_result.stdout)
                                    cleanup_file.write("\n```\n\n")
                                    if destroy_result.stderr:
                                        cleanup_file.write("清理错误:\n```\n")
                                        cleanup_file.write(destroy_result.stderr)
                                        cleanup_file.write("\n```\n\n")
                            except Exception as destroy_error:
                                self.logger.error(f"执行terraform destroy时出错: {str(destroy_error)}")
                            
                            # 读取原始Terraform代码
                            with open(tf_file_path, 'r') as f:
                                original_tf = f.read()
                            
                            # 尝试修复代码 - 直接传递完整错误消息
                            fixed_tf = self._fix_terraform_code(original_tf, apply_result.stderr, tf_file_path)
                            if fixed_tf:
                                self.logger.info("成功修复Terraform代码，准备重新部署")
                                # 保存修复后的代码
                                with open(tf_file_path, 'w') as f:
                                    f.write(fixed_tf)
                                
                                # 创建对比日志，记录修改前后的差异
                                diff_log_path = os.path.join(deploy_dir, 'code_diff.log')
                                with open(diff_log_path, 'a') as diff_file:
                                    diff_file.write(f"\n\n{'='*80}\n")
                                    diff_file.write(f"第{retry_count+1}次修复 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    diff_file.write(f"{'='*80}\n\n")
                                    diff_file.write("修复前:\n```terraform\n")
                                    diff_file.write(original_tf)
                                    diff_file.write("\n```\n\n修复后:\n```terraform\n")
                                    diff_file.write(fixed_tf)
                                    diff_file.write("\n```\n")
                                
                                retry_count += 1
                                # 更新部署状态，告知用户正在修复
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'planning', 
                                    error_message=f"检测到Terraform应用错误，已自动修复并重试 ({retry_count}/{max_retries})"
                                )
                                deployment_logs['retry_count'] = retry_count
                                self.logger.info(f"开始第{retry_count}次重试部署")
                                continue
                            else:
                                self.logger.warning("无法自动修复Terraform代码")
                        
                        self.logger.error(f"Terraform应用失败: {apply_result.stderr}")
                        error_msg = f"应用失败: {apply_result.stderr}"
                        deployment_logs['error_message'] = error_msg
                        deployment_logs['status'] = 'failed'
                        create_deployment_summary(is_success=False)
                        
                        # 尝试清理已部署的资源
                        if os.path.exists(os.path.join(deploy_dir, '.terraform')):
                            self.logger.info(f"正在清理应用失败后的资源: {deploy_id}")
                            try:
                                # 更新部署状态
                                self.deployment_model.update_deployment_status(
                                    deploy_id, 
                                    'cleaning', 
                                    error_message=f"应用失败，正在清理已部署的资源"
                                )
                                
                                # 执行terraform destroy
                                destroy_result = subprocess.run(
                                    ['terraform', 'destroy', '-auto-approve'],
                                    cwd=deploy_dir,
                                    capture_output=True,
                                    text=True
                                )
                                
                                # 记录清理结果
                                cleanup_log_path = os.path.join(deploy_dir, 'final_cleanup.log')
                                with open(cleanup_log_path, 'w') as cleanup_file:
                                    cleanup_file.write(f"失败后资源清理 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                    cleanup_file.write(f"{'='*80}\n\n")
                                    cleanup_file.write("清理输出:\n```\n")
                                    cleanup_file.write(destroy_result.stdout)
                                    cleanup_file.write("\n```\n\n")
                                    if destroy_result.stderr:
                                        cleanup_file.write("清理错误:\n```\n")
                                        cleanup_file.write(destroy_result.stderr)
                                        cleanup_file.write("\n```\n\n")
                                
                                # 更新错误信息
                                if destroy_result.returncode == 0:
                                    error_msg += " (资源已自动清理)"
                                    self.logger.info(f"成功清理应用失败后的资源: {deploy_id}")
                                else:
                                    error_msg += f" (资源清理失败: {destroy_result.stderr})"
                                    self.logger.error(f"清理应用失败后的资源时出错: {destroy_result.stderr}")
                            except Exception as cleanup_error:
                                self.logger.error(f"执行资源清理时出错: {str(cleanup_error)}")
                                error_msg += f" (资源清理过程中出错: {str(cleanup_error)})"
                        
                        self.deployment_model.update_deployment_status(
                            deploy_id, 
                            'failed', 
                            error_message=error_msg
                        )
                        return
                        
                    self.logger.info(f"Terraform应用成功: {apply_result.stdout}")
                    
                    # 部署成功，跳出重试循环
                    break
                except Exception as apply_error:
                    error_msg = f"执行terraform apply时出错: {str(apply_error)}"
                    self.logger.error(error_msg)
                    deployment_logs['error_message'] = error_msg
                    deployment_logs['status'] = 'failed'
                    create_deployment_summary(is_success=False)
                    
                    # 尝试清理已部署的资源
                    if os.path.exists(os.path.join(deploy_dir, '.terraform')):
                        self.logger.info(f"正在清理应用异常后的资源: {deploy_id}")
                        try:
                            # 更新部署状态
                            self.deployment_model.update_deployment_status(
                                deploy_id, 
                                'cleaning', 
                                error_message=f"应用异常，正在清理已部署的资源"
                            )
                            
                            # 执行terraform destroy
                            destroy_result = subprocess.run(
                                ['terraform', 'destroy', '-auto-approve'],
                                cwd=deploy_dir,
                                capture_output=True,
                                text=True
                            )
                            
                            # 记录清理结果
                            cleanup_log_path = os.path.join(deploy_dir, 'final_cleanup.log')
                            with open(cleanup_log_path, 'w') as cleanup_file:
                                cleanup_file.write(f"异常后资源清理 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                cleanup_file.write(f"{'='*80}\n\n")
                                cleanup_file.write("清理输出:\n```\n")
                                cleanup_file.write(destroy_result.stdout)
                                cleanup_file.write("\n```\n\n")
                                if destroy_result.stderr:
                                    cleanup_file.write("清理错误:\n```\n")
                                    cleanup_file.write(destroy_result.stderr)
                                    cleanup_file.write("\n```\n\n")
                            
                            # 更新错误信息
                            if destroy_result.returncode == 0:
                                error_msg += " (资源已自动清理)"
                                self.logger.info(f"成功清理应用异常后的资源: {deploy_id}")
                            else:
                                error_msg += f" (资源清理失败: {destroy_result.stderr})"
                                self.logger.error(f"清理应用异常后的资源时出错: {destroy_result.stderr}")
                        except Exception as cleanup_error:
                            self.logger.error(f"执行资源清理时出错: {str(cleanup_error)}")
                            error_msg += f" (资源清理过程中出错: {str(cleanup_error)})"
                    
                    self.deployment_model.update_deployment_status(
                        deploy_id, 
                        'failed', 
                        error_message=error_msg
                )
                return
            
                except Exception as e:            self.logger.error(f"Terraform部署过程中出错: {str(e)}")            self.logger.error(traceback.format_exc())                        # 更新部署状态为"failed"并创建失败摘要            error_msg = str(e)            deployment_logs['error_message'] = error_msg            deployment_logs['status'] = 'failed'            create_deployment_summary(is_success=False)                        # 尝试清理可能已部署的资源            if os.path.exists(os.path.join(deploy_dir, '.terraform')):                self.logger.info(f"正在清理出现异常后的资源: {deploy_id}")                try:                    # 更新部署状态                    self.deployment_model.update_deployment_status(                        deploy_id,                         'cleaning',                         error_message=f"部署异常，正在清理已部署的资源"                    )                                        # 执行terraform destroy                    destroy_result = subprocess.run(                        ['terraform', 'destroy', '-auto-approve'],                        cwd=deploy_dir,                        capture_output=True,                        text=True                    )                                        # 记录清理结果                    cleanup_log_path = os.path.join(deploy_dir, 'final_cleanup.log')                    with open(cleanup_log_path, 'w') as cleanup_file:                        cleanup_file.write(f"异常后资源清理 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")                        cleanup_file.write(f"{'='*80}\n\n")                        cleanup_file.write("清理输出:\n```\n")                        cleanup_file.write(destroy_result.stdout)                        cleanup_file.write("\n```\n\n")                        if destroy_result.stderr:                            cleanup_file.write("清理错误:\n```\n")                            cleanup_file.write(destroy_result.stderr)                            cleanup_file.write("\n```\n\n")                                        # 更新错误信息                    if destroy_result.returncode == 0:                        error_msg += " (资源已自动清理)"                        self.logger.info(f"成功清理异常后的资源: {deploy_id}")                    else:                        error_msg += f" (资源清理失败: {destroy_result.stderr})"                        self.logger.error(f"清理异常后的资源时出错: {destroy_result.stderr}")                except Exception as cleanup_error:                    self.logger.error(f"执行资源清理时出错: {str(cleanup_error)}")                    error_msg += f" (资源清理过程中出错: {str(cleanup_error)})"                        self.deployment_model.update_deployment_status(                deploy_id,                 'failed',                 error_message=error_msg            )
    
    def _fix_terraform_code(self, original_code, error_message, tf_file_path):
        """使用OpenAI API尝试修复Terraform代码"""
        try:
            self.logger.info("开始修复Terraform代码")
            
            # 创建修复日志文件
            fix_log_path = os.path.dirname(tf_file_path) + '/fix_attempts.log'
            with open(fix_log_path, 'a') as log_file:
                log_file.write(f"\n\n{'='*80}\n")
                log_file.write(f"修复尝试 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                log_file.write(f"{'='*80}\n\n")
                log_file.write("错误信息:\n")
                log_file.write(error_message)
                log_file.write("\n\n")
            
            # 获取API密钥
            api_key = self.openai_api_key
            if not api_key and self.config:
                api_key = getattr(self.config, 'openai_api_key', '')
                
            if not api_key:
                self.logger.error("未配置OpenAI API密钥，无法修复Terraform代码")
                with open(fix_log_path, 'a') as log_file:
                    log_file.write("未配置OpenAI API密钥，无法修复Terraform代码\n")
                return None
                
            # 设置OpenAI API密钥
            openai.api_key = api_key
            
            # 提取所有包含"Error:"的错误信息，无论前缀如何
            error_lines = []
            lines = error_message.split('\n')
            for i, line in enumerate(lines):
                if 'Error:' in line:
                    # 收集这一行以及后面的6行作为上下文（从3行增加到6行）
                    error_block = [line.strip()]
                    for j in range(1, 7):
                        if i + j < len(lines) and lines[i + j].strip():
                            error_block.append(lines[i + j].strip())
                    
                    error_lines.append('\n'.join(error_block))
            
            if not error_lines:
                self.logger.warning("未找到包含Error:的错误信息，无法修复")
                with open(fix_log_path, 'a') as log_file:
                    log_file.write("未找到Error:开头的错误信息，尝试使用完整错误消息\n")
                # 如果没有找到特定格式的错误，使用完整的错误消息
                error_lines = [error_message]
            
            # 检查是否为火山引擎代码
            is_volcengine = "volcengine" in original_code.lower() or "火山" in original_code
            
            # 构建提示
            system_prompt = """
            You are an AI assistant specialized in fixing Terraform code. 
            You will be provided with a Terraform script that has errors and the error messages generated during deployment.
            Your task is to analyze the errors and fix the code to make it functional.
            
            Follow these guidelines:
            1. Analyze each error carefully and make specific corrections to address it
            2. Maintain the original resources and structure as much as possible
            3. Only make changes necessary to fix the errors
            4. Return the complete, fixed Terraform configuration
            5. Make sure the fixed code follows Terraform best practices
            6. DO NOT change any credentials (access_key and secret_key values) if they already exist
            """
            
            # 针对火山引擎增加特殊提示
            if is_volcengine:
                system_prompt += """
            
            IMPORTANT FOR VOLCENGINE:
            - This code is using Volcengine (火山引擎) provider, not AWS
            - Make sure to preserve both the terraform and provider blocks:
              
              terraform {
                required_providers {
                  volcengine = {
                    source = "volcengine/volcengine"
                    version = "0.0.167"
                  }
                }
              }
              
              provider "volcengine" {
                region = "cn-beijing"
                access_key = "..."
                secret_key = "..."
              }
              
            - DO NOT add any AWS provider blocks
            - Use volcengine_* resources instead of aws_* resources
            """
            
            # 准备用户提示
            user_prompt = f"""
            Here's the Terraform code with errors:
            
            ```terraform
            {original_code}
            ```
            
            Here are the error messages:
            
            ```
            {'\\n\\n'.join(error_lines)}
            ```
            
            Please fix the Terraform code to resolve these errors. Make sure to:
            
            1. Ensure all resources have proper dependencies and configurations.
            2. Handle any resource conflicts appropriately.
            3. IMPORTANT: DO NOT change any provider credentials (access_key and secret_key values) if they already exist.
            """
            
            # 针对火山引擎添加特殊说明
            if is_volcengine:
                user_prompt += """
            4. Preserve the Volcengine provider configuration exactly as is.
            5. Do not add any AWS provider blocks.
            6. Make sure to use volcengine_* resources instead of aws_* resources.
            """
            else:
                user_prompt += """
            4. Add additional subnets in different Availability Zones for any AWS Load Balancer resources.
            5. Handle any subnet conflicts - either use different CIDR blocks or use data sources to reference existing subnets.
            """
            
            user_prompt += """
            Return ONLY the corrected code.
            """
            
            # 记录提示到日志
            with open(fix_log_path, 'a') as log_file:
                log_file.write("提交给AI的错误信息:\n")
                log_file.write('\\n\\n'.join(error_lines))
                log_file.write("\n\n")
            
            # 调用OpenAI API
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )
            
            # 提取修复后的代码
            fixed_code = response.choices[0].message.content
            
            # 提取修复后的代码（移除可能的代码块标记）
            fixed_code = self._clean_terraform_code(fixed_code)
            
            # 记录修复后的代码到日志
            with open(fix_log_path, 'a') as log_file:
                log_file.write("AI修复后的代码:\n")
                log_file.write(fixed_code)
                log_file.write("\n\n")
                
            # 提取原始代码中的AK和SK
            access_key_pattern = r'access_key\s*=\s*"([^"]*)"'
            secret_key_pattern = r'secret_key\s*=\s*"([^"]*)"'
            
            original_ak_match = re.search(access_key_pattern, original_code)
            original_sk_match = re.search(secret_key_pattern, original_code)
            
            # 如果原始代码中有AK和SK，确保修复后的代码保留这些值
            if original_ak_match and original_sk_match:
                original_ak = original_ak_match.group(1)
                original_sk = original_sk_match.group(1)
                
                # 只有当原始AK/SK有实际值时才进行处理
                if original_ak and original_sk:
                    provider_type = "火山引擎" if is_volcengine else "AWS"
                    self.logger.info(f"检测到原始代码中存在有效的{provider_type}凭证，确保在修复后的代码中保留")
                    
                    # 检查修复后的代码中是否变更了AK/SK
                    fixed_ak_match = re.search(access_key_pattern, fixed_code)
                    fixed_sk_match = re.search(secret_key_pattern, fixed_code)
                    
                    if fixed_ak_match and fixed_sk_match:
                        fixed_ak = fixed_ak_match.group(1)
                        fixed_sk = fixed_sk_match.group(1)
                        
                        # 如果修复后的代码更改了AK/SK，则恢复原始值
                        if fixed_ak != original_ak or fixed_sk != original_sk:
                            self.logger.info(f"{provider_type}凭证在修复过程中被更改，恢复原始凭证值")
                            
                            # 替换回原始值
                            fixed_code = re.sub(
                                access_key_pattern, 
                                f'access_key = "{original_ak}"', 
                                fixed_code
                            )
                            fixed_code = re.sub(
                                secret_key_pattern, 
                                f'secret_key = "{original_sk}"', 
                                fixed_code
                            )
                            
                            # 记录保留凭证的操作
                            with open(fix_log_path, 'a') as log_file:
                                log_file.write(f"检测到{provider_type}凭证被修改，已恢复原始值\n")
            
            return fixed_code
            
        except Exception as e:
            self.logger.error(f"修复Terraform代码时出错: {str(e)}")
            self.logger.error(traceback.format_exc())
            with open(fix_log_path, 'a') as log_file:
                log_file.write(f"修复过程中发生错误: {str(e)}\n")
                log_file.write(traceback.format_exc())
                log_file.write("\n")
            return None
    
    def get_deployment_status(self, deploy_id):
        """获取部署状态"""
        try:
            if not deploy_id:
                return jsonify({"success": False, "message": "部署ID为空"}), 400
                
            deployment = self.deployment_model.get_deployment(deploy_id)
            if not deployment:
                return jsonify({"success": False, "message": "未找到部署信息"}), 404
                
            return jsonify({
                "success": True,
                "deployment": deployment
            })
            
        except Exception as e:
            self.logger.error(f"获取部署状态时出错: {str(e)}")
            return jsonify({
                "success": False,
                "error": "获取部署状态时出错",
                "message": str(e)
            }), 500
    
    def deploy_terraform_init(self):
        """初始化大型Terraform部署（分批上传代码）"""
        try:
            # 获取请求数据
            self.logger.info("开始处理分批Terraform部署初始化请求")
            data = request.get_json()
            if not data:
                self.logger.error("请求数据为空")
                return jsonify({"success": False, "message": "请求数据为空"}), 400
            
            terraform_code_part = data.get('terraform_code_part', '')
            if not terraform_code_part:
                self.logger.error("Terraform代码片段为空")
                return jsonify({"success": False, "message": "Terraform代码片段为空"}), 400
                
            # 获取必要参数
            is_multipart = data.get('is_multipart', False)
            total_parts = data.get('total_parts', 1)
            part_index = data.get('part_index', 0)
            
            # 验证这是第一个片段
            if part_index != 0:
                self.logger.error("初始化请求必须是第一个片段")
                return jsonify({"success": False, "message": "初始化请求必须是第一个片段"}), 400
                
            # 获取API密钥ID
            api_key_id = data.get('api_key_id')
            if not api_key_id:
                self.logger.error("未提供API密钥ID")
                return jsonify({"success": False, "message": "请选择API密钥"}), 400
                
            # 获取描述和部署名称
            description = data.get('description', '通过AI生成的部署')
            deploy_name = data.get('deploy_name', '')
            
            self.logger.info(f"分批部署初始化: 部署名称: {deploy_name}, 描述长度: {len(description)}, 总分片: {total_parts}")
            
            # 获取当前用户信息
            try:
                current_user = get_current_user(request)
                if not current_user:
                    self.logger.error("未找到用户信息")
                    return jsonify({"success": False, "message": "未找到用户信息"}), 401
                    
                user_id = current_user.get('user_id')
                username = current_user.get('username')
                self.logger.info(f"用户ID: {user_id}, 用户名: {username}")
            except Exception as user_error:
                self.logger.error(f"获取用户信息出错: {str(user_error)}")
                return jsonify({"success": False, "message": f"获取用户信息出错: {str(user_error)}"}), 500
            
            # 生成唯一的部署ID
            deploy_id = f"AIDP{uuid.uuid4().hex[:19]}".upper()
            self.logger.info(f"生成部署ID: {deploy_id}")
            
            # 创建部署目录
            try:
                deploy_dir = os.path.join(self.deployments_dir, deploy_id)
                self.logger.info(f"创建部署目录: {deploy_dir}")
                os.makedirs(deploy_dir, exist_ok=True)
                
                # 创建临时代码片段存储目录
                parts_dir = os.path.join(deploy_dir, 'parts')
                os.makedirs(parts_dir, exist_ok=True)
                
                # 保存第一个代码片段
                part_file_path = os.path.join(parts_dir, f"part_{part_index:03d}.tf")
                with open(part_file_path, 'w') as f:
                    f.write(terraform_code_part)
            except Exception as dir_error:
                self.logger.error(f"创建部署目录时出错: {str(dir_error)}")
                return jsonify({"success": False, "message": f"创建部署目录时出错: {str(dir_error)}"}), 500
            
            # 创建部署记录，但标记为draft状态
            try:
                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                deployment_data = {
                    'id': deploy_id,
                    'user_id': user_id,
                    'username': username,
                    'name': deploy_name or description[:50],
                    'description': description,
                    'status': 'draft',  # 使用draft状态表示正在上传中
                    'created_at': current_time,
                    'updated_at': current_time,
                    'terraform_code': terraform_code_part  # 暂时只保存第一部分
                }
                
                # 保存部署记录到数据库
                self.logger.info(f"保存部署草稿记录到数据库: {deploy_id}")
                success = self.deployment_model.create_deployment(deployment_data)
                if not success:
                    self.logger.error("保存部署记录失败")
                    return jsonify({"success": False, "message": "保存部署记录失败"}), 500
                    
                # 创建部署信息文件，记录总分片数和当前进度
                info_file_path = os.path.join(deploy_dir, 'deploy_info.json')
                info_data = {
                    'deploy_id': deploy_id,
                    'total_parts': total_parts,
                    'received_parts': 1,
                    'api_key_id': api_key_id,
                    'status': 'uploading'
                }
                with open(info_file_path, 'w') as f:
                    json.dump(info_data, f)
                
                return jsonify({
                    "success": True,
                    "message": "部署初始化成功",
                    "deploy_id": deploy_id
                })
            except Exception as db_error:
                self.logger.error(f"保存部署记录到数据库时出错: {str(db_error)}")
                return jsonify({"success": False, "message": f"保存部署记录到数据库时出错: {str(db_error)}"}), 500
            
        except Exception as e:
            self.logger.error(f"初始化Terraform部署时出错: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "初始化部署时出错",
                "message": str(e)
            }), 500
    
    def deploy_terraform_part(self):
        """接收Terraform部署代码片段"""
        try:
            # 获取请求数据
            self.logger.info("开始处理Terraform代码片段上传请求")
            data = request.get_json()
            if not data:
                self.logger.error("请求数据为空")
                return jsonify({"success": False, "message": "请求数据为空"}), 400
            
            # 获取必要参数
            deploy_id = data.get('deploy_id')
            if not deploy_id:
                self.logger.error("未提供部署ID")
                return jsonify({"success": False, "message": "未提供部署ID"}), 400
                
            terraform_code_part = data.get('terraform_code_part', '')
            if not terraform_code_part:
                self.logger.error("Terraform代码片段为空")
                return jsonify({"success": False, "message": "Terraform代码片段为空"}), 400
                
            part_index = data.get('part_index', 0)
            
            # 验证部署存在
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            if not os.path.exists(deploy_dir):
                self.logger.error(f"部署目录不存在: {deploy_dir}")
                return jsonify({"success": False, "message": f"部署不存在: {deploy_id}"}), 404
                
            # 检查部署信息文件
            info_file_path = os.path.join(deploy_dir, 'deploy_info.json')
            if not os.path.exists(info_file_path):
                self.logger.error(f"部署信息文件不存在: {info_file_path}")
                return jsonify({"success": False, "message": f"部署信息不存在: {deploy_id}"}), 404
                
            # 读取部署信息
            with open(info_file_path, 'r') as f:
                info_data = json.load(f)
                
            # 验证部署状态
            if info_data.get('status') != 'uploading':
                self.logger.error(f"部署状态不正确: {info_data.get('status')}")
                return jsonify({"success": False, "message": f"部署状态不正确: {info_data.get('status')}"}), 400
                
            # 保存代码片段
            parts_dir = os.path.join(deploy_dir, 'parts')
            part_file_path = os.path.join(parts_dir, f"part_{part_index:03d}.tf")
            with open(part_file_path, 'w') as f:
                f.write(terraform_code_part)
                
            # 更新部署信息
            info_data['received_parts'] += 1
            with open(info_file_path, 'w') as f:
                json.dump(info_data, f)
                
            self.logger.info(f"成功接收代码片段: {deploy_id}, 片段索引: {part_index}, 已接收: {info_data['received_parts']}/{info_data['total_parts']}")
                
            return jsonify({
                "success": True,
                "message": f"成功接收代码片段: {part_index}",
                "deploy_id": deploy_id,
                "received_parts": info_data['received_parts'],
                "total_parts": info_data['total_parts']
            })
            
        except Exception as e:
            self.logger.error(f"接收Terraform代码片段时出错: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "接收代码片段时出错",
                "message": str(e)
            }), 500
    
    def deploy_terraform_complete(self):
        """完成Terraform部署代码上传并开始部署"""
        try:
            # 获取请求数据
            self.logger.info("开始处理Terraform部署完成请求")
            data = request.get_json()
            if not data:
                self.logger.error("请求数据为空")
                return jsonify({"success": False, "message": "请求数据为空"}), 400
            
            # 获取部署ID
            deploy_id = data.get('deploy_id')
            if not deploy_id:
                self.logger.error("未提供部署ID")
                return jsonify({"success": False, "message": "未提供部署ID"}), 400
                
            # 验证部署存在
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            if not os.path.exists(deploy_dir):
                self.logger.error(f"部署目录不存在: {deploy_dir}")
                return jsonify({"success": False, "message": f"部署不存在: {deploy_id}"}), 404
                
            # 检查部署信息文件
            info_file_path = os.path.join(deploy_dir, 'deploy_info.json')
            if not os.path.exists(info_file_path):
                self.logger.error(f"部署信息文件不存在: {info_file_path}")
                return jsonify({"success": False, "message": f"部署信息不存在: {deploy_id}"}), 404
                
            # 读取部署信息
            with open(info_file_path, 'r') as f:
                info_data = json.load(f)
                
            # 验证部署状态
            if info_data.get('status') != 'uploading':
                self.logger.error(f"部署状态不正确: {info_data.get('status')}")
                return jsonify({"success": False, "message": f"部署状态不正确: {info_data.get('status')}"}), 400
                
            # 验证所有片段是否都已接收
            if info_data.get('received_parts', 0) < info_data.get('total_parts', 0):
                self.logger.error(f"尚未接收所有代码片段: {info_data.get('received_parts')}/{info_data.get('total_parts')}")
                return jsonify({
                    "success": False, 
                    "message": f"尚未接收所有代码片段: {info_data.get('received_parts')}/{info_data.get('total_parts')}"
                }), 400
                
            # 合并所有代码片段
            parts_dir = os.path.join(deploy_dir, 'parts')
            terraform_code = ""
            for i in range(info_data.get('total_parts', 0)):
                part_file_path = os.path.join(parts_dir, f"part_{i:03d}.tf")
                if not os.path.exists(part_file_path):
                    self.logger.error(f"找不到代码片段文件: {part_file_path}")
                    return jsonify({"success": False, "message": f"找不到代码片段: {i}"}), 404
                    
                with open(part_file_path, 'r') as f:
                    terraform_code += f.read()
            
            # 获取API密钥ID
            api_key_id = info_data.get('api_key_id')
            if not api_key_id:
                self.logger.error("未找到API密钥ID")
                return jsonify({"success": False, "message": "未找到API密钥ID"}), 400
                
            # 获取API密钥详情
            try:
                from controllers.apikey_controller import ApiKeyController
                apikey_controller = ApiKeyController(self.config)
                api_key = apikey_controller.get_api_key_by_id(api_key_id)
                
                if not api_key:
                    self.logger.error(f"找不到指定的API密钥: {api_key_id}")
                    return jsonify({"success": False, "message": "找不到指定的API密钥"}), 404
                    
                # 获取AK和SK
                ak = api_key.get('ak', '')
                sk = api_key.get('sk', '')
                
                if not ak or not sk:
                    self.logger.error("API密钥缺少AK或SK")
                    return jsonify({"success": False, "message": "API密钥缺少AK或SK"}), 400
                    
                self.logger.info(f"成功获取API密钥 {api_key.get('apikey_name')}")
            except Exception as apikey_error:
                self.logger.error(f"获取API密钥时出错: {str(apikey_error)}")
                return jsonify({"success": False, "message": f"获取API密钥时出错: {str(apikey_error)}"}), 500
            
            # 修改Terraform代码，添加AWS凭证
            try:
                # 添加AWS凭证配置
                terraform_code = self._add_aws_credentials_to_code(terraform_code, ak, sk)
            except Exception as code_error:
                self.logger.error(f"添加AWS凭证到Terraform代码时出错: {str(code_error)}")
                return jsonify({"success": False, "message": f"添加AWS凭证到Terraform代码时出错: {str(code_error)}"}), 500
            
            # 写入完整的Terraform代码到main.tf文件
            tf_file_path = os.path.join(deploy_dir, 'main.tf')
            with open(tf_file_path, 'w') as f:
                f.write(terraform_code)
                
            # 更新部署信息
            info_data['status'] = 'ready'
            with open(info_file_path, 'w') as f:
                json.dump(info_data, f)
                
            # 更新部署记录
            try:
                self.deployment_model.update_deployment_status(
                    deploy_id, 
                    'pending',
                    error_message=None,
                    deployment_summary=None
                )
                
                # 更新Terraform代码
                self.logger.info(f"更新部署记录的Terraform代码: {deploy_id}")
                deployment = self.deployment_model.get_deployment(deploy_id)
                if deployment:
                    conn = get_db()
                    cursor = conn.cursor()
                    cursor.execute(
                        f"UPDATE aideployments SET terraform_code = %s WHERE id = %s",
                        (terraform_code, deploy_id)
                    )
                    conn.commit()
                    cursor.close()
                    conn.close()
            except Exception as update_error:
                self.logger.error(f"更新部署记录时出错: {str(update_error)}")
                return jsonify({"success": False, "message": f"更新部署记录时出错: {str(update_error)}"}), 500
            
            # 启动异步部署任务
            try:
                # 获取当前用户信息
                current_user = get_current_user(request)
                user_id = current_user.get('user_id') if current_user else None
                
                # 启动后台部署任务
                self.logger.info(f"启动后台部署任务: {deploy_id}")
                import threading
                deploy_thread = threading.Thread(
                    target=self._run_terraform_deployment,
                    args=(deploy_id, deploy_dir, user_id)
                )
                deploy_thread.daemon = True
                deploy_thread.start()
                
                return jsonify({
                    "success": True,
                    "message": "部署任务已启动",
                    "deploy_id": deploy_id
                })
            except Exception as thread_error:
                self.logger.error(f"启动后台部署任务时出错: {str(thread_error)}")
                return jsonify({"success": False, "message": f"启动后台部署任务时出错: {str(thread_error)}"}), 500
            
        except Exception as e:
            self.logger.error(f"完成Terraform部署时出错: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "完成部署时出错",
                "message": str(e)
            }), 500
    
    def list_deployments(self):
        """列出用户的AI部署"""
        try:
            # 获取当前用户信息
            current_user = get_current_user(request)
            if not current_user:
                return jsonify({"success": False, "message": "未找到用户信息"}), 401
                
            user_id = current_user.get('user_id')
            
            # 获取分页参数
            page = request.args.get('page', 1, type=int)
            page_size = request.args.get('page_size', 10, type=int)
            
            # 获取部署列表
            deployments, total = self.deployment_model.list_deployments(
                user_id=user_id,
                page=page,
                page_size=page_size
            )
            
            return jsonify({
                "success": True,
                "deployments": deployments,
                "total": total,
                "page": page,
                "page_size": page_size
            })
            
        except Exception as e:
            self.logger.error(f"获取部署列表时出错: {str(e)}")
            return jsonify({
                "success": False,
                "error": "获取部署列表时出错",
                "message": str(e)
            }), 500 
    
    def get_ai_deployment_details(self, deploy_id=None):
        """获取AI部署的详情，包括拓扑图信息"""
        try:
            # 如果未提供deploy_id，则从请求参数中获取
            if not deploy_id:
                deploy_id = request.args.get('deploy_id')
            
            if not deploy_id:
                return jsonify({"success": False, "message": "未提供部署ID"}), 400
            
            # 获取部署详情
            deployment = self.deployment_model.get_deployment(deploy_id)
            if not deployment:
                return jsonify({"success": False, "message": "未找到部署信息"}), 404
            
            # 获取拓扑图路径（只用于检查是否存在）
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            topology_image_path = os.path.join(deploy_dir, 'graph.png')
            topology_exists = os.path.exists(topology_image_path)
            
            # 如果拓扑图不存在且部署已完成，尝试生成拓扑图
            if not topology_exists and deployment.get('status') == 'completed':
                try:
                    # 确保在部署目录中执行命令
                    if os.path.exists(deploy_dir):
                        # 尝试生成拓扑图
                        result = subprocess.run(
                            'terraform graph -type=plan | dot -Tpng > graph.png',
                            shell=True,
                            cwd=deploy_dir,
                            stderr=subprocess.PIPE,
                            stdout=subprocess.PIPE,
                            text=True
                        )
                        
                        if result.returncode == 0:
                            topology_exists = os.path.exists(topology_image_path)
                            self.logger.info(f"已为部署 {deploy_id} 生成拓扑图")
                        else:
                            self.logger.warning(f"无法生成拓扑图: {result.stderr}")
                except Exception as gen_error:
                    self.logger.error(f"生成拓扑图时出错: {str(gen_error)}")
            
            # 构建资源文件列表 - 这里仍需要构建用于返回API，但不会在HTML中显示
            files = []
            if os.path.exists(deploy_dir):
                # 仅列出重要的文件类型
                for file in os.listdir(deploy_dir):
                    if file.endswith(".tf") or file.endswith(".log") or file == "graph.png":
                        file_path = os.path.join(deploy_dir, file)
                        if os.path.isfile(file_path):
                            file_size = os.path.getsize(file_path)
                            files.append({
                                "name": file,
                                "path": f"/api/terraform/file?deploy_id={deploy_id}&file={file}",
                                "size": file_size,
                                "type": file.split('.')[-1]
                            })
            
            # 生成部署摘要HTML表格
            table_html = "<div class='deployment-summary card shadow-sm'>\n"
            table_html += f"<div class='card-header bg-primary text-white'><h3 class='mb-0'><i class='fas fa-brain mr-2'></i>AI部署详情: {deploy_id}</h3></div>\n"
            
            # 基本信息
            table_html += "<div class='card-body'>\n"
            table_html += "<table class='table table-striped table-bordered table-hover'>\n"
            table_html += "<tbody>\n"
            table_html += "<tr><th colspan='2' class='bg-light'>基本信息</th></tr>\n"
            table_html += f"<tr><th width='30%'>部署ID</th><td><code>{deployment.get('id', '')}</code></td></tr>\n"
            table_html += f"<tr><th>名称</th><td><strong>{deployment.get('name', '')}</strong></td></tr>\n"
            table_html += f"<tr><th>创建时间</th><td>{deployment.get('created_at', '')}</td></tr>\n"
            table_html += f"<tr><th>更新时间</th><td>{deployment.get('updated_at', '')}</td></tr>\n"
            
            # 显示状态并根据状态添加不同的样式
            status = deployment.get('status', '')
            status_badge = self._get_status_badge(status)
            table_html += f"<tr><th>状态</th><td>{status_badge}</td></tr>\n"
            
            # 如果有错误信息
            if deployment.get('error_message'):
                table_html += f"<tr><th>错误信息</th><td class='text-danger'><i class='fas fa-exclamation-circle mr-1'></i>{deployment.get('error_message', '')}</td></tr>\n"
            
            table_html += "</tbody>\n"
            table_html += "</table>\n"
            
            # 如果有部署摘要
            if deployment.get('deployment_summary'):
                table_html += "<h4 class='mt-4 mb-2'><i class='fas fa-list-alt mr-2'></i>部署摘要</h4>\n"
                
                summary = deployment.get('deployment_summary')
                if isinstance(summary, dict):
                    # 使用可折叠面板显示复杂的JSON输出
                    formatted_summary = self._format_json_output(summary)
                    table_html += formatted_summary
                else:
                    # 如果是字符串，尝试解析为JSON
                    try:
                        summary_dict = json.loads(summary)
                        formatted_summary = self._format_json_output(summary_dict)
                        table_html += formatted_summary
                    except:
                        # 如果解析失败，作为普通文本显示
                        table_html += "<div class='alert alert-info'>\n"
                        table_html += f"<p>{summary}</p>\n"
                        table_html += "</div>\n"
            
            # 移除文件列表和拓扑图显示部分
            
            table_html += "</div>\n"
            table_html += "</div>"
            
            return jsonify({
                "success": True,
                "deployment": deployment,
                "topology_exists": topology_exists,
                "topology_url": f"/api/terraform/topology?deploy_id={deploy_id}" if topology_exists else None,
                "files": files,
                "table": table_html
            })
            
        except Exception as e:
            self.logger.error(f"获取AI部署详情时出错: {str(e)}")
            self.logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "获取部署详情时出错",
                "message": str(e)
            }), 500
    
    def get_ai_deployment_file(self):
        """获取AI部署相关的文件内容"""
        try:
            # 从请求参数中获取部署ID和文件名
            deploy_id = request.args.get('deploy_id')
            file_name = request.args.get('file')
            
            if not deploy_id or not file_name:
                return jsonify({"success": False, "message": "未提供部署ID或文件名"}), 400
            
            # 构建文件路径
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            file_path = os.path.join(deploy_dir, file_name)
            
            # 检查文件是否存在
            if not os.path.exists(file_path) or not os.path.isfile(file_path):
                return jsonify({"success": False, "message": "文件不存在"}), 404
            
            # 根据文件类型返回不同的响应
            if file_name.endswith('.png'):
                # 如果是图片，直接返回文件内容
                with open(file_path, 'rb') as f:
                    return send_file(
                        io.BytesIO(f.read()),
                        mimetype='image/png',
                        as_attachment=False,
                        download_name=file_name
                    )
            else:
                # 如果是文本文件，返回文件内容
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                return jsonify({
                    "success": True,
                    "content": content,
                    "file_name": file_name
                })
                
        except Exception as e:
            self.logger.error(f"获取AI部署文件时出错: {str(e)}")
            return jsonify({
                "success": False,
                "error": "获取文件内容时出错",
                "message": str(e)
            }), 500
            
    def get_ai_deployment_topology(self):
        """获取AI部署的拓扑图"""
        try:
            # 从请求参数中获取部署ID
            deploy_id = request.args.get('deploy_id')
            
            if not deploy_id:
                return jsonify({"success": False, "message": "未提供部署ID"}), 400
            
            # 构建拓扑图文件路径
            deploy_dir = os.path.join(self.deployments_dir, deploy_id)
            topology_path = os.path.join(deploy_dir, 'graph.png')
            
            # 检查拓扑图是否存在
            if not os.path.exists(topology_path):
                # 尝试生成拓扑图
                try:
                    # 确保在部署目录中执行命令
                    if os.path.exists(deploy_dir):
                        # 尝试生成拓扑图
                        result = subprocess.run(
                            'terraform graph -type=plan | dot -Tpng > graph.png',
                            shell=True,
                            cwd=deploy_dir,
                            stderr=subprocess.PIPE,
                            stdout=subprocess.PIPE,
                            text=True
                        )
                        
                        if result.returncode == 0 and os.path.exists(topology_path):
                            self.logger.info(f"已为部署 {deploy_id} 生成拓扑图")
                        else:
                            return jsonify({"success": False, "message": f"无法生成拓扑图: {result.stderr}"}), 404
                except Exception as gen_error:
                    return jsonify({"success": False, "message": f"生成拓扑图时出错: {str(gen_error)}"}), 500
            
            # 返回拓扑图文件
            return send_file(
                topology_path,
                mimetype='image/png',
                as_attachment=False,
                download_name=f"topology_{deploy_id}.png"
            )
                
        except Exception as e:
            self.logger.error(f"获取AI部署拓扑图时出错: {str(e)}")
            return jsonify({
                "success": False,
                "error": "获取拓扑图时出错",
                "message": str(e)
            }), 500
    
    def _get_status_badge(self, status: str) -> str:
        """生成状态的Bootstrap徽章HTML"""
        status_lower = status.lower()
        
        if status_lower == 'completed' or status_lower == 'success':
            return '<span class="badge badge-success"><i class="fas fa-check mr-1"></i>已完成</span>'
        elif status_lower == 'failed' or status_lower == 'error':
            return '<span class="badge badge-danger"><i class="fas fa-times mr-1"></i>失败</span>'
        elif status_lower == 'in_progress' or status_lower == 'running':
            return '<span class="badge badge-warning"><i class="fas fa-spinner fa-spin mr-1"></i>进行中</span>'
        elif status_lower == 'pending':
            return '<span class="badge badge-info"><i class="fas fa-hourglass-half mr-1"></i>准备中</span>'
        else:
            return f'<span class="badge badge-secondary">{status}</span>'
            
    def _format_json_output(self, json_data):
        """将JSON数据格式化为表格形式而不是代码块"""
        html = ""
        
        # 如果是字典类型的输出
        if isinstance(json_data, dict):
            # 检查是否有outputs字段，这需要特殊处理
            if 'outputs' in json_data and isinstance(json_data['outputs'], dict):
                html += "<div class='card mb-3'>\n"
                html += "<div class='card-header bg-light font-weight-bold'>资源输出变量</div>\n"
                html += "<div class='card-body p-0'>\n"
                html += "<table class='table table-sm table-striped mb-0'>\n"
                html += "<thead class='thead-light'>\n"
                html += "<tr><th>输出名称</th><th>值</th></tr>\n"
                html += "</thead>\n"
                html += "<tbody>\n"
                
                for key, value in json_data['outputs'].items():
                    output_value = value.get('value', '') if isinstance(value, dict) else value
                    # 如果输出值是复杂对象，转换为表格而非JSON代码
                    if isinstance(output_value, dict):
                        output_formatted = self._format_dict_as_table(output_value)
                    elif isinstance(output_value, list):
                        output_formatted = self._format_list_as_table(output_value)
                    else:
                        output_formatted = f"<code>{output_value}</code>"
                    
                    html += f"<tr><td><strong>{key}</strong></td><td>{output_formatted}</td></tr>\n"
                
                html += "</tbody>\n"
                html += "</table>\n"
                html += "</div>\n"
                html += "</div>\n"
                
                # 从字典中移除已处理的outputs
                json_data = {k: v for k, v in json_data.items() if k != 'outputs'}
            
            # 处理其他字段，排除过长的apply_output
            other_fields = {k: v for k, v in json_data.items() if k not in ['apply_output']}
            
            if other_fields:
                # 创建表格显示其他简单字段
                for key, value in other_fields.items():
                    # 排除空值和复杂对象
                    if value is None:
                        continue
                        
                    html += f"<div class='card mb-3'>\n"
                    html += f"<div class='card-header bg-light font-weight-bold'>{key}</div>\n"
                    html += f"<div class='card-body p-0'>\n"
                    
                    if isinstance(value, dict):
                        html += self._format_dict_as_table(value)
                    elif isinstance(value, list):
                        html += self._format_list_as_table(value)
                    else:
                        html += f"<div class='p-3'>{value}</div>\n"
                    
                    html += f"</div>\n"
                    html += f"</div>\n"
        
        # 如果是列表类型的输出
        elif isinstance(json_data, list):
            html += "<div class='card mb-3'>\n"
            html += "<div class='card-header bg-light font-weight-bold'>数据列表</div>\n"
            html += "<div class='card-body p-0'>\n"
            html += self._format_list_as_table(json_data)
            html += "</div>\n"
            html += "</div>\n"
        
        # 如果是其他类型（字符串、数字等）
        else:
            html += "<div class='card mb-3'>\n"
            html += "<div class='card-header bg-light font-weight-bold'>值</div>\n"
            html += "<div class='card-body'>\n"
            html += f"<div>{json_data}</div>\n"
            html += "</div>\n"
            html += "</div>\n"
        
        return html
    
    def _format_dict_as_table(self, data):
        """将字典格式化为HTML表格"""
        html = "<table class='table table-sm table-striped mb-0'>\n"
        html += "<tbody>\n"
        
        for key, value in data.items():
            if isinstance(value, dict):
                # 简化嵌套字典显示
                nested_table = "<table class='table table-sm table-bordered mb-0'>\n<tbody>\n"
                for k, v in value.items():
                    if isinstance(v, (dict, list)):
                        v_text = "复杂对象" 
                    else:
                        v_text = str(v)
                    nested_table += f"<tr><td><small>{k}</small></td><td><small>{v_text}</small></td></tr>\n"
                nested_table += "</tbody>\n</table>"
                html += f"<tr><td width='30%'><strong>{key}</strong></td><td>{nested_table}</td></tr>\n"
            elif isinstance(value, list):
                if len(value) > 0 and isinstance(value[0], dict):
                    # 简化列表显示
                    html += f"<tr><td width='30%'><strong>{key}</strong></td><td>列表包含 {len(value)} 项</td></tr>\n"
                else:
                    # 简单列表值显示
                    list_text = ", ".join([str(item) for item in value[:5]])
                    if len(value) > 5:
                        list_text += "..."
                    html += f"<tr><td width='30%'><strong>{key}</strong></td><td>{list_text}</td></tr>\n"
            else:
                # 简单值直接显示
                html += f"<tr><td width='30%'><strong>{key}</strong></td><td>{value}</td></tr>\n"
                
        html += "</tbody>\n"
        html += "</table>\n"
        return html
    
    def _format_list_as_table(self, data):
        """将列表格式化为HTML表格"""
        if not data:
            return "<div class='p-3'>空列表</div>"
            
        # 检查列表项是否为字典
        if all(isinstance(item, dict) for item in data):
            # 使用字典的键作为列头
            all_keys = set()
            for item in data:
                all_keys.update(item.keys())
            all_keys = sorted(list(all_keys))
            
            html = "<table class='table table-sm table-striped mb-0'>\n"
            html += "<thead class='thead-light'>\n<tr>\n"
            
            for key in all_keys:
                html += f"<th>{key}</th>\n"
            
            html += "</tr>\n</thead>\n<tbody>\n"
            
            for item in data:
                html += "<tr>\n"
                for key in all_keys:
                    value = item.get(key, "")
                    if isinstance(value, (dict, list)):
                        html += "<td>复杂对象</td>\n"
                    else:
                        html += f"<td>{value}</td>\n"
                html += "</tr>\n"
                
            html += "</tbody>\n</table>\n"
        else:
            # 简单列表使用序号显示
            html = "<table class='table table-sm table-striped mb-0'>\n"
            html += "<thead class='thead-light'>\n<tr>\n"
            html += "<th>#</th><th>值</th>\n"
            html += "</tr>\n</thead>\n<tbody>\n"
            
            for i, item in enumerate(data):
                html += f"<tr><td>{i+1}</td><td>"
                if isinstance(item, dict):
                    html += "字典对象"
                elif isinstance(item, list):
                    html += f"列表 ({len(item)} 项)"
                else:
                    html += f"{item}"
                html += "</td></tr>\n"
                
            html += "</tbody>\n</table>\n"
            
        return html